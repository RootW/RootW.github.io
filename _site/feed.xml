<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>吴斌</title>
    <description>欢迎来到我的技术博客~</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 11 Jan 2018 17:15:46 +0800</pubDate>
    <lastBuildDate>Thu, 11 Jan 2018 17:15:46 +0800</lastBuildDate>
    <generator>Jekyll v3.4.0</generator>
    
      <item>
        <title>进程管理之二：进程替换</title>
        <description>&lt;p&gt;  本篇讨论进程替换(exec)，计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是进程替换为什么需要它&quot;&gt;什么是进程替换？为什么需要它？&lt;/h3&gt;

&lt;p&gt;  进程替换是用新的代码和数据替换当前进程已有代码和数据，从而开始执行新的业务逻辑。&lt;/p&gt;

&lt;p&gt;  通过fork创建出来的进程是继承父进程的代码和数据，如果想要进程执行一些新的任务，那就得从磁盘程序中加载新的代码和数据并替换当前进程已有的代码和数据。&lt;/p&gt;

&lt;h3 id=&quot;如何实现进程替换&quot;&gt;如何实现进程替换？&lt;/h3&gt;

&lt;h4 id=&quot;1-exec用户态示例代码&quot;&gt;&lt;strong&gt;1. exec用户态示例代码&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  我们先来看看在用户态程序中是如何实现替换的：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;exec_test.c:

#include &amp;lt;stdio.h&amp;gt;  
#include &amp;lt;unistd.h&amp;gt;  

/*示例函数fork一个新进程并在其中执行ps命令*/
int main()  
{
    /*构造命令行参数ps_argv和环境变量ps_envp*/
    char *const ps_argv[] ={&quot;ps&quot;, &quot;-o&quot;, &quot;pid,ppid,pgrp,session,tpgid,comm&quot;, NULL};  
    char *const ps_envp[] ={&quot;PATH=/bin:/usr/bin&quot;, &quot;TERM=console&quot;, NULL};

    if(fork()==0){ 
        /*执行execve系统调用，第一个参数表示可执行文件的位置，第二个表示命令行参数，第三个表示环境变量。
          这里注意exec是一个函数簇，其有6种类似的系统调用：
          (1)6种调用的前4个字符相同，均是exec;
          (2)第5位有v和l两种，v表示向量表示法，l表示逐个列举;
          (3)第6位有e和p两种，e表示带环境变量，p表示可执行程序以文件名方式查找，而不是路径查找;*/
        if(execve(&quot;/bin/ps&quot;, ps_argv, ps_envp) &amp;lt; 0)  {  
            perror(&quot;execve error!&quot;);  
            return -1 ;  
        }  
    }  
    return 0 ;  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;2-elf可执行文件格式解析&quot;&gt;&lt;strong&gt;2. ELF可执行文件格式解析&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  通过上面的例子，我们看到应用程序通过调用execve系统调用实现执行程序的替换。Linux平台上主流的可执行文件格式是ELF(Executable and Linkable Format，类似Windows平台上的exe文件格式)，如果想深入分析execve调用功能，那我们就得了解ELF文件格式，详细规范说明&lt;a href=&quot;http://www.skyfree.org/linux/references/ELF_Format.pdf&quot;&gt;点此&lt;/a&gt;进入。&lt;/p&gt;

&lt;h5 id=&quot;21-示例程序&quot;&gt;&lt;strong&gt;2.1. 示例程序&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  真正理解ELF格式后，我们能够将C语言源文件与ELF二进制文件进行对应，这样可以提升对底层系统问题的定位能力。因此为方便大家入门，这里以一个简单的C语言程序为例，来逐一对应ELF中的各部分：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~/tmp_analyze_elf/main.c:

#include &amp;lt;stdio.h&amp;gt;

void say_hello(char *who)
{
    printf(&quot;hello, %s!\n&quot;, who);
}

char *my_name = &quot;wb&quot;;

int main()
{
    say_hello(my_name);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  我们将其编译生成名为app的可执行程序并运行：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;linux-XqAfQZ:~/tmp_analyze_elf # &lt;strong&gt;gcc -o&lt;/strong&gt; app main.c&lt;br /&gt;
linux-XqAfQZ:~/tmp_analyze_elf # &lt;strong&gt;./app&lt;/strong&gt;&lt;br /&gt;
hello, wb!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;22-elf整体布局&quot;&gt;&lt;strong&gt;2.2. ELF整体布局&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  ELF格式可以表达三种类型的二进制对象文件(object files)：可重定位文件(relocatable file，就是大家平常见到的.o文件)、可执行文件(executable file, 例上述示例代码生成的app文件)、共享库文件(shared object files，就是.so文件，用来做动态链接)。可重定位文件用在编译和链接阶段；可执行文件用在程序运行阶段；共享库则同时用在编译链接和运行阶段。在不同阶段，我们可以用不同视角来理解ELF文件，整体布局如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/process2_1.jpg&quot; height=&quot;300&quot; width=&quot;450&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  从上图可见，ELF格式文件整体可分为四大部分：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;ELF Header, ELF头部，定义全局性信息；&lt;/li&gt;
    &lt;li&gt;Program Header Table， 描述段(Segment)信息的数组，每个元素对应一个段；通常包含在可执行文件中，可重定文件中可选(通常不包含)；&lt;/li&gt;
    &lt;li&gt;Segment and Section，段(Segment)由若干区(Section)组成；段在运行时被加载到进程地址空间中，包含在可执行文件中；区是段的组成单元，包含在可执行文件和可重定位文件中；&lt;/li&gt;
    &lt;li&gt;Section Header Table，描述区(Section)信息的数组，每个元素对应一个区；通常包含在可重定位文件中，可执行文件中为可选(通常包含)；&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;23-elf-header实例解析&quot;&gt;&lt;strong&gt;2.3. ELF Header实例解析&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  ELF规范中对ELF Header中各字段的定义如下所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/process2_2.jpg&quot; height=&quot;300&quot; width=&quot;350&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  接下来我们通过readelf -h命令来看看示例程序app中的ELF Header内容，显示结果如下图：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-header.jpg&quot; height=&quot;380&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;e_ident&lt;/strong&gt;含前16个字节，又可细分成class、data、version等字段，具体含义不用太关心，只需知道前4个字节点包含”ELF”关键字，这样可以判断当前文件是否是ELF格式；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_type&lt;/strong&gt;表示具体ELF类型，可重定位文件/可执行文件/共享库文件，显然这里是一个可执行文件；&lt;strong&gt;e_machine&lt;/strong&gt;表示执行的机器平台，这里是x86_64；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_version&lt;/strong&gt;表示文件版本号，这里的1表示初始版本号；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_entry&lt;/strong&gt;对应”Entry point address”，程序入口函数地址，通过进程虚拟地址空间地址(0x400440)表达；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_phoff&lt;/strong&gt;对应“Start of program headers”，表示program header table在文件内的偏移位置，这里是从第64号字节(假设初始为0号字节)开始；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_shoff&lt;/strong&gt;对应”Start of section headers”，表示section header table在文件内的偏移位置，这里是从第4472号字节开始，靠近文件尾部；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_flags&lt;/strong&gt;表示与CPU处理器架构相关的信息，这里为零；&lt;strong&gt;e_ehsize&lt;/strong&gt;对应”Size of this header”，表示本ELF header自身的长度，这里为64个字节，回看前面的e_phoff为64，说明ELF header后紧跟着program header table；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_phentsize&lt;/strong&gt;对应“Size of program headers”，表示program header table中每个元素的大小，这里为56个字节；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_phnum&lt;/strong&gt;对应”Number of program headers”，表示program header table中元素个数，这里为9个；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_shentsize&lt;/strong&gt;对应”Size of section headers”，表示section header table中每个元素的大小，这里为64个字节；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;e_shnum&lt;/strong&gt;对应”Number of section headers”，表示section header table中元素的个数，这里为30个；&lt;/li&gt;
    &lt;li&gt;最后， &lt;strong&gt;e_shstrndx&lt;/strong&gt;对应”Section header string table index”，表示描述各section字符名称的string table在section header table中的下标，详见后文对string table的介绍。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;24-program-header-table实例解析&quot;&gt;&lt;strong&gt;2.4. Program Header Table实例解析&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  Program Header Table是一个数组，每个元素叫Program Header，规范对其结构定义如下：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/process2_3.jpg&quot; height=&quot;200&quot; width=&quot;300&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  同样我们用readelf -l命令查看示例程序的program header table：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-program-header1.jpg&quot; height=&quot;500&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  上图截取了readelf命令返回的上半部，我们重点看下前面几项：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;PHDR&lt;/strong&gt;，此类型header元素描述了program header table自身的信息。从这里的内容看出，示例程序的program header table在文件中的偏移(Offset)为0x40，即64号字节处；该段映射到进程空间的虚拟地址(VirtAddr)为0x400040；PhysAddr暂时不用，其保持和VirtAddr一致；该段占用的文件大小FileSiz为00x1f8；运行时占用进程空间内存大小MemSiz也为0x1f8；Flags标记表示该段的读写权限，这里”R E”表示可读可执行，说明本段属于代码段；Align对齐为8，表明本段按8字节对齐。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;INTERP&lt;/strong&gt;，此类型header元素描述了一个特殊内存段，该段内存记录了动态加载解析器的访问路径字符串。示例程序中，该段内存位于文件偏移0x238处，即紧跟program header table；映射的进程虚拟地址空间地址为0x400238；文件长度和内存映射长度均为0x1c，即28个字符，具体内容为”/lib64/ld-linux-x86-64.so.2”；段属性为只读，并按字节对齐；&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;LOAD&lt;/strong&gt;，此类型header元素描述了可加载到进程空间的代码段或数据段：第三项为代码段，文件内偏移为0，映射到进程地址0x400000处，代码段长度为0x764个字节，属性为只读可执行，段地址按2M边界对齐；第四段为数据段，文件内偏移为0xe10，映射到进程地址为0x600e10处(按2M对齐移动)，文件大小为0x230，内存大小为0x238(因为其内部包含了8字节的bss段，即未初始化数据段，该段内容不占文件空间，但在运行时需要为其分配空间并清零)，属性为读写，段地址也按2M边界对齐。&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;DYNAMIC&lt;/strong&gt;，此类型header元素描述了动态加载段，其内部通常包含了一个名为”.dynamic”的动态加载区；这也是一个数组，每个元素描述了与动态加载相关的各方面信息，我们将在动态加载中介绍。该段是从文件偏移0xe28处开始，长度为0x1d0，并映射到进程的0x600e28；可见该段和上一个数据段是有重叠的。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;  readelf命令返回内容的下半部分给出了各段(segment)和各区(section)之间的包含关系，如下图所示。INTERP段只包含了”.interp”区；代码段包含”.interp”、”.plt”、”.text”等区；数据段包含”.dynamic”、”.data”、”.bss”等区；DYNAMIC段包含”.dynamic”区。从这里可以看出，有些区被包含在多个段中。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-program-header2.jpg&quot; height=&quot;100&quot; width=&quot;800&quot; /&gt;  
&lt;/div&gt;

&lt;h5 id=&quot;25-section-header-table实例解析&quot;&gt;&lt;strong&gt;2.5. Section Header Table实例解析&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  针对各区的描述信息由Section Header Table提供，该数组中每个元素的定义如下：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/process2_4.jpg&quot; height=&quot;200&quot; width=&quot;300&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  下面我们再通过readelf -S命令看看示例程序中section header table的内容，如下图所示。示例程序共生成30个区，Name表示每个区的名字，Type表示每个区的功能，Address表示每个区的进程映射地址，Offset表示文件内偏移，Size表示区的大小，EntSize表示区中每个元素的大小(如果该区为一个数组的话，否则该值为0)，Flags表示每个区的属性(参见图中最后的说明)，Link和Info记录不同类型区的相关信息(不同类型含义不同，具体参见规范)，Align表示区的对齐单位。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-section-header1.jpg&quot; height=&quot;700&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-section-header2.jpg&quot; height=&quot;400&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;h5 id=&quot;26-string-table实例解析&quot;&gt;&lt;strong&gt;2.6. String Table实例解析&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  从上述Section Header Table示例中，我们看到有一种类型为STRTAB的区(在Section Header Table中的下标为6,27,29)。此类区叫做String Table，其作用是集中记录字符串信息，其它区在需要使用字符串的时候，只需要记录字符串起始地址在该String Table表中的偏移即可，而无需包含整个字符串内容。&lt;/p&gt;

&lt;p&gt;  我们使用readelf -x读出下标27区的详细内容观察：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-strtable1.jpg&quot; height=&quot;400&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  红框内为该区实际内容，左侧为区内偏移地址，后侧为对应内容的字符表示。我们可以发现，这里其实是一堆字符串，这些字符串对应的就是各个区的名字。因此section header table中每个元素的Name字段其实是这个string table的索引。再回头看看ELF header中的e_shstrndx，它的值正好就是27，指向了当前的string table。&lt;/p&gt;

&lt;p&gt;  同理再来看下29区的内容，如下图所示。这里我们看到了”main”、”say_hello”字符串，这些是我们在示例中源码中定义的符号，由此可以29区是应用自身的String Table，记录了应用使用的字符串。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-strtable2.jpg&quot; height=&quot;700&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;h5 id=&quot;27-symbol-table实例解析&quot;&gt;&lt;strong&gt;2.7. Symbol Table实例解析&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  Section Header Table中，还有一类SYMTAB(DYNSYM)区，该区叫符号表。符号表中的每个元素对应一个符号，记录了每个符号对应的实际数值信息，通常用在重定位过程中或问题定位过程中，进程执行阶段并不加载符号表。符号表中每个元素定义如下：name表示符号对应的源码字符串，为对应String Table中的索引；value表示符号对应的数值；size表示符号对应数值的空间占用大小；info表示符号的相关信息，如符号类型(变量符号、函数符号)；shndx表示与该符号相关的区的索引，例如函数符号与对应的代码区相关。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/process2_5.jpg&quot; height=&quot;160&quot; width=&quot;300&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  我们用readelf -s读出示例程序中的符号表，如下图所示。如红框中内容所示，我们示例程序定义的main函数符号对应的数值为0x400554，其类型为FUNC，大小为26字节，对应的代码区在Section Header Table中的索引为13；say_hello函数符号对应数值为0x400530，其类型为FUNC，大小为36字节，对应的代码区也为13。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-symtable1.jpg&quot; height=&quot;250&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-symtable2.jpg&quot; height=&quot;250&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;h5 id=&quot;28-代码段实例解析&quot;&gt;&lt;strong&gt;2.8. 代码段实例解析&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  在理解了String Table和Symbol Table的作用后，我们通过objdump反汇编来理解一下.text代码段：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/elf-main-code.jpg&quot; height=&quot;300&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  这里截取了与示例程序相关部分，我们看到0x400530和0x400554两处各定义一个函数，其符号分别为say_hello和main，这部分信息实际是通过符号表解析而来的；在涉及到内存地址的指令中，除了对数据段地址的引用是通过绝对地址进行的之外，对于代码段地址的引用都是以相对地址的方式进行的，这样做的好处是在二进制文件的重定位过程中，我们不用修改指令的访问地址(因为相对地址保持不变)；最后，我们看到对于库函数printf的访问指向了代码段地址0x400410，那么这个地址处放的是printf函数么？要回答这个问题就涉及动态链接，我们将在下文专题分析。&lt;/p&gt;

&lt;h5 id=&quot;29-动态链接dynamic-linking&quot;&gt;&lt;strong&gt;2.9. 动态链接(Dynamic Linking)&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;  基于模块化设计思路，我们在应用开发时会将基础的、共用的功能抽取出来，设计成可共享的库。应用程序在编译时只是建立了与共享库的联系，并不将其包含在内；运行时，由系统负责加载所需的共享库。这就是动态链接，如此一来，既可以节省磁盘和内存的空间占用(相同功能在磁盘和内存中均只存在一份)，也可以方便基础模块自身的优化改进。&lt;/p&gt;

&lt;p&gt;  要实现动态链接，需要解决两个大的问题：(1)共享库内部的函数的地址访问需要与加载地址无关，因为不同的程序可能将库加载到不同的地址处；回顾2.8中的代码分析，我们看到这个可以通过相对寻址的方式解决。(2)调用共享库的应用程序如何能够获知共享库的加载地址并准确对其进行调用？&lt;/p&gt;

&lt;p&gt;  ELF规范对问题2的解决方法给出明确思路：系统中需要有一个Program Interpreter配合内核完成进程执行上下文的准备。Program Interpreter可以是一个可执行程序，也可以是一个共享库；在Linux x86_64平台下，这个解析器就是/lib64/ld-ld-linux-x86-64.so.2，就是由INTERP段指明的。解析器和内核需要配合完成以下动作：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;加载可执行程序到进程空间；&lt;/li&gt;
    &lt;li&gt;加载共享库到进程空间；&lt;/li&gt;
    &lt;li&gt;进行重定位；&lt;/li&gt;
    &lt;li&gt;将控制权交给进程正常执行。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;3-深入内核sys_execve&quot;&gt;&lt;strong&gt;3. 深入内核sys_execve&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;说明mmap原理&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2018/01/进程替换/&quot;&gt;进程管理之二：进程替换&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 08 Jan 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/01/%E8%BF%9B%E7%A8%8B%E6%9B%BF%E6%8D%A2/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/01/%E8%BF%9B%E7%A8%8B%E6%9B%BF%E6%8D%A2/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>Rados Block Device</title>
        <description>&lt;p&gt;  ceph作为流行的SDS(Software Define Storage)开源实现备受业界关注，本篇博文从它提供块服务的视角对ceph进行一步步深入分析。&lt;/p&gt;

&lt;h3 id=&quot;什么是rados-block-device&quot;&gt;什么是Rados Block Device?&lt;/h3&gt;

&lt;h4 id=&quot;什么是ceph&quot;&gt;&lt;strong&gt;什么是ceph?&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  看一下官方的解释：“Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalability.” 这里说的是，ceph是一个&lt;strong&gt;统一&lt;/strong&gt;分布式存储系统(功能)；另外，它也具有极佳的性能、可靠性和扩展性。功能和DFx兼具，很完美。&lt;/p&gt;

&lt;p&gt;  之所以说ceph是一个统一存储，是因为用户从功能上看，会认为ceph同时支持对象、块和文件三种形态(如下图所示)。其中块设备形态，就是Rados Block Device，简称RBD。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/rbd_1.jpg&quot; height=&quot;200&quot; width=&quot;400&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;如何使用rados-block-device&quot;&gt;&lt;strong&gt;如何使用Rados Block Device?&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  为了使大家对ceph(RBD)有一个更直观的理解，下面我们来看看ceph(RBD)的实际使用方法：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.创建ceph集群&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;  ceph是一个分布式系统，内部包含许多计算、存储和网络节点，这里我们暂且把它当做一个黑盒，仅需了解使用ceph之前需要搭建这样一个集群。具体搭建方法我们会在深入分析时介绍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.创建pool&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;  pool是ceph中比较重要的一个概念，一个个对象(块、文件最终也转换成对象存储)均放在pool中，管理员针对不同的pool可以采用不同的配置策略。默认情况下，一个ceph集群搭建完成后，就会有一个名为”rbd”的pool，其中专门用来存放RDB对象。我们可以用ceph集群管理命令rados来查询当前已有的pools：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[root@ceph-client]# &lt;strong&gt;rados lspools&lt;/strong&gt;&lt;br /&gt;
rbd&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;  这里我们手动建一个新的pool，然后再查询结果：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[root@ceph-client]# &lt;strong&gt;rados mkpool&lt;/strong&gt; wbpool&lt;br /&gt;
successfully created pool wbpool&lt;br /&gt;
[root@ceph-client]# &lt;strong&gt;rados lspools&lt;/strong&gt;&lt;br /&gt;
rbd&lt;br /&gt;
wbpool&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;3.创建块设备&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;  接下来我们使用rbd命令在wbpool池中新建一个1G大小的块设备，取名wb：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[root@ceph-client]# &lt;strong&gt;rbd create&lt;/strong&gt; wb &lt;strong&gt;--pool&lt;/strong&gt; wbpool &lt;strong&gt;--size&lt;/strong&gt; 1G&lt;br /&gt;
[root@ceph-client]# &lt;strong&gt;rbd ls --pool&lt;/strong&gt; wbpool&lt;br /&gt;
wb&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;4.映射块设备&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;  创建完块设备之后，我们需要在使用RBD的主机上将它映射成一个可使用的设备：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[root@ceph-client]# &lt;strong&gt;rbd map&lt;/strong&gt; wb &lt;strong&gt;--pool&lt;/strong&gt; wbpool&lt;br /&gt;
/dev/rbd0&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;5.使用块设备&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;  通过映射，我们获知RBD设备的本地访问设备为/dev/rbd0，那么我们就可以像使用本地块设备一样使用RBD块设备，例如将其格式化成文件系统并挂载使用：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;[root@ceph-client]# &lt;strong&gt;mkfs.ext4&lt;/strong&gt; /dev/rbd0&lt;br /&gt;
[root@ceph-client]# &lt;strong&gt;mount&lt;/strong&gt; /dev/rbd0 /mnt&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;  &lt;/p&gt;

&lt;h3 id=&quot;为什么需要rados-block-device&quot;&gt;为什么需要Rados Block Device?&lt;/h3&gt;

&lt;p&gt;  ceph兼具对象、块、文件三种存储形态，支持PB级超大存储容量，同时具备较好的性能、可靠性和扩展性，因此非常适合企业级应用存储需求，公有云、私有云都有ceph成功部署的案例。Redhat将其收购后，更是进一步加速了它的应用和推广。&lt;/p&gt;

&lt;p&gt;  三种存储形态中，对象和块相对更稳定一些；块设备方式可以完全兼容已有应用，因此使用范围更为广泛。&lt;/p&gt;

&lt;h3 id=&quot;如何实现rados-block-device&quot;&gt;如何实现Rados Block Device?&lt;/h3&gt;

&lt;h4 id=&quot;ceph集群结构&quot;&gt;&lt;strong&gt;ceph集群结构&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  我们已经知道ceph是一个集群系统，那么从物理视角深入看，集群内部有哪些部件？他们又是如何相互协作对外提供服务的？下图是ceph官方给出的系统部署图：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/rbd_2.jpg&quot; height=&quot;250&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  从图中我们可以看到这些组件(简单地说，可见将组件视为部署了不同ceph程序的服务器)：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;Ceph Mon(Monitor)&lt;/strong&gt;，集群的管理者，负责维护集群状态图(如monitor map, OSD map, CRUSH map)，并对客户端提供管理服务(客户端通过Monitor获取全局存储信息并建立访问连接)；集群中通常有多个Monitor，以提升系统可靠性&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Ceph OSD(Object Storage Daemon)&lt;/strong&gt;，对象存储服务提供者，每个OSD提供数据存储空间、处理数据复制、恢复、均衡并通过彼此间的心跳机制为Monitor提供监控信息；一台配置了单独数据硬件的服务器即可视为一个OSD节点；系统中通常也有多个OSD节点&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Ceph MDS(MetaData Server)&lt;/strong&gt;，为文件服务提供元数据管理功能；可选组件，在RBD中不涉及&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Ceph Client(客户端)&lt;/strong&gt;，数据访问端点，其上部署了各种软件驱动(或库)，最终为应用提供对象、块、文件服务&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Public and Cluster Network&lt;/strong&gt;，集群内部网络平面，Public平面提供客户端到集群的数据访问通信，Cluster平面为OSD之间的心跳和数据复制提供通信，采用两个独立的网络平面可以避免相互影响，提升系统整体服务性能要&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;  通过组件的协作，正常的数据流大体如下：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;客户端通过驱动首先与Monitor建立网络连接，并完成认证，最后Monitor返回系统中所有的OSD状态图&lt;/li&gt;
    &lt;li&gt;客户端基于OSD状态图、访问对象和CRUSH算法计算出存放对象的主备OSD&lt;/li&gt;
    &lt;li&gt;客户端与主OSD建立连接并发起数据访问请求&lt;/li&gt;
    &lt;li&gt;主OSD执行客户端访问请求，对于写请求会将请求复制到其它备OSD，待其它OSD返回结果后再对客户端返回执行结果&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;ceph功能结构&quot;&gt;&lt;strong&gt;ceph功能结构&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  切换到功能视角，我们也可以看到ceph整体的软件栈架构：底部是由Monitor、MDS、OSD实现的Rados集群；客户端通过librados库为应用提供多语言的对象访问支持，或者通过RADOSGW实现兼客S3和Swift的对象服务，或者通过librbd为应用(如虚拟化程序)提供块服务，或者通过文件驱动为应用提供兼容posix标准的文件服务。注，RADOSGW和librbd基于librados构建，但内核块服务和文件服务直接在内核中实现，其中涵盖了librados的功能。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/rbd_3.jpg&quot; height=&quot;400&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;客户端内核rbd驱动分析&quot;&gt;&lt;strong&gt;客户端内核rbd驱动分析&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;通过分析客户端驱动，将服务端当作黑盒来理解ceph系统原理&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2018/01/RBD/&quot;&gt;Rados Block Device&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 05 Jan 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/01/RBD/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/01/RBD/</guid>
        
        <category>ceph</category>
        
        
      </item>
    
      <item>
        <title>进程管理之一：进程创建</title>
        <description>&lt;p&gt;  进程管理也是计算子系统(CPU&amp;amp;Memory)的核心功能，从本篇博文起，我们开始讨论进程管理。计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是进程什么是进程管理为什么需要进程管理&quot;&gt;什么是进程？什么是进程管理？为什么需要进程管理？&lt;/h3&gt;

&lt;p&gt;  从物理视角说上，进程是CPU上的一段逻辑过程，它的控制(代码段)和数据(数据段)存放于内存。回顾一下计算子系统开篇中描绘的系统结构图(如下图)，进程的执行要素包括CPU中的寄存器和内存段两个部分(虚拟内存段最终会映射到物理内存段)：寄存器代表进程的瞬时运行状态；代码段存储指令，控制进程执行逻辑；数据段存储进程的全局数据；堆栈段存储局部数据和动态数据。从功能视角说，进程是各种“功能”的实现实体，计算机为人们提供的诸如聊天、上网、看视频等各种功能都是通过进程实现的，因此进程有时也被叫作“任务“。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/cpu_low_level.jpg&quot; height=&quot;550&quot; width=&quot;400&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  进程管理是指与进程相关的一系列动作，如创建、替换、终止、调度、通信等等。进程管理使得一个CPU可以执行若干进程，各进程分时复用CPU的物理资源；内存管理使得多个进程可以共享物理内存；基于上述两个核心功能，计算机系统可以实现多任务并行，大大提升系统运行效率，方使客户使用(想象一下，如果你的计算机一个时刻只能运行一个任务，那将是一种多么糟糕体验)。&lt;/p&gt;

&lt;h3 id=&quot;如何创建进程&quot;&gt;如何创建进程？&lt;/h3&gt;

&lt;p&gt;  进程创建就是新建一个进程，这是进程管理最基本的功能，也是进程生命周期的起点。下面我们就来看看进程创建在Linux内核中是如何实现的。&lt;/p&gt;

&lt;h4 id=&quot;forkvfork和clone&quot;&gt;&lt;strong&gt;fork、vfork和clone&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  从应用程序开发的层次上，我们应该知道创建进程(或线程，即轻量级进程)有fork、vfork和clone三种&lt;a href=&quot;https://rootw.github.io/2017/02/系统调用/&quot;&gt;系统调用&lt;/a&gt;：fork是创建进程标准做法，父子进程共享代码段，但拥有独立数据、堆栈段；vfork是轻量级进程创建方法，父子进程共享代码、数据和堆栈段，子进程运行期间父进程是睡眠的，当子进程结束后父进程才继续运行；clone则提供了更灵活的进程创建方式，可以通过clone_flags来控制创建过程，libpthread库提供的相关API即是通过clone系统调用实现的。大家可以在网上找一些这三种方式的示例代码，动手实验一下以加深理解。到了内核态，这三个系统调用最终都通过do_fork函数来实现其核心功能：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/kernel/fork.c:

SYSCALL_DEFINE0(fork)
{
    return do_fork(SIGCHLD, 0, 0, NULL, NULL);
}

SYSCALL_DEFINE0(vfork)
{
    return do_fork(CLONE_VFORK | CLONE_VM | SIGCHLD, 0, 
        0, NULL, NULL);
}

SYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp,
                int __user *, parent_tidptr,
                int __user *, child_tidptr,
                int, tls_val)
{
    return do_fork(clone_flags, newsp, 0, parent_tidptr, child_tidptr);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;进程控制块struct-task_struct&quot;&gt;&lt;strong&gt;进程控制块：struct task_struct&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  在深入分析do_fork之前，我们首先要明白内核对进程需要有一个抽象的数据表达，基于这种数据表达才能实现各种管理功能。我们将内核中表达进程的数据结构叫做进程控制块，在linux中则是struct task_struct。这里我不打算对task_struct中的各个字段进行逐一描述，因为难以表述清楚，大家可以结合后续的代码流程来深入理解各字段的含义，下面是一幅整体结构图，供参考：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/process1_1.jpg&quot; height=&quot;500&quot; width=&quot;450&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  另外，在早期的linux版本中，进程控制块是包含进程的内核态栈的(通常是8KB大小)。什么是内核态栈？每个进程都有用户态空间和内核态空间两个执行空间，出于安全隔离的考虑，两个空间使用独立的栈，因此内核栈就被安排在了进程控制块中，栈底在高地址端，从高地址往低地址扩展，而进程控制块其它数据则被放置在8K的低地址起始位置处。随着内核的发展，各种功能不断被加入，进程控制块的数据结构也在不断变大，因此就存在挤占内核栈的风险。所以高版本内核将进程控制块和内核栈进行了分离：内核栈的低地址端只保留基本的进程信息，并通过指针对向真正的进程控制块结构，如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/process1_2.jpg&quot; height=&quot;300&quot; width=&quot;450&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;深入do_fork&quot;&gt;&lt;strong&gt;深入do_fork&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  do_fork在传入参数clone_flags的控制下，基于当前进程复制了一个新进程，其大体流程是：先复制当前进程产生新的进程控制块，然后再调度新进程进入运行态。代码框架如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/kernel/fork.c:

/*
 *  Ok, this is the main fork-routine.
 *
 * It copies the process, and if successful kick-starts
 * it and waits for it to finish using the VM if required.
 */
long do_fork(unsigned long clone_flags,
        unsigned long stack_start,
        unsigned long stack_size,
        int __user *parent_tidptr,
    int __user *child_tidptr)
{
    struct task_struct *p;
    long nr;

    ...

    /*基于当前进程的task_struct和clone_flags复制新进程*/
    p = copy_process(clone_flags, stack_start, stack_size,
                                child_tidptr, NULL, trace);
    /*
     * Do this prior waking up the new thread - the thread pointer
     * might get invalid after that point, if the thread exits quickly.
     */
    if (!IS_ERR(p)) {
        struct completion vfork;
        struct pid *pid;

        pid = get_task_pid(p, PIDTYPE_PID);
        nr = pid_vnr(pid);

        if (clone_flags &amp;amp; CLONE_PARENT_SETTID)
            put_user(nr, parent_tidptr);

        /*如果clone_flags中置了CLONE_VFORK标置，则需要初始化等待结构体*/
        if (clone_flags &amp;amp; CLONE_VFORK) {
            p-&amp;gt;vfork_done = &amp;amp;vfork;
            init_completion(&amp;amp;vfork);
            get_task_struct(p);
        }

        /*将新创建的进程加入调度队列*/
        wake_up_new_task(p);

        ...

        /*对于VFORK，当前进程(即父进程)需要等待子进程完成后才能继续运行*/
        if (clone_flags &amp;amp; CLONE_VFORK) {
            if (!wait_for_vfork_done(p, &amp;amp;vfork))
                ptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid);
            }

        put_pid(pid);
    } else {
        nr = PTR_ERR(p);
    }
    return nr;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  补充一下关于clone_flags标记的注释说明，建议大家在使用到的代码位置处仔细阅读，以加深理解：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/include/uapi/linux/sched.h:

/*
 * cloning flags:
 */
#define CSIGNAL		0x000000ff	/* signal mask to be sent at exit */
#define CLONE_VM	0x00000100	/* set if VM shared between processes */
#define CLONE_FS	0x00000200	/* set if fs info shared between processes */
#define CLONE_FILES	0x00000400	/* set if open files shared between processes */
#define CLONE_SIGHAND	0x00000800	/* set if signal handlers and blocked signals shared */
#define CLONE_PTRACE	0x00002000	/* set if we want to let tracing continue on the child too */
#define CLONE_VFORK	0x00004000	/* set if the parent wants the child to wake it up on mm_release */
#define CLONE_PARENT	0x00008000	/* set if we want to have the same parent as the cloner */
#define CLONE_THREAD	0x00010000	/* Same thread group? */
#define CLONE_NEWNS	0x00020000	/* New namespace group? */
#define CLONE_SYSVSEM	0x00040000	/* share system V SEM_UNDO semantics */
#define CLONE_SETTLS	0x00080000	/* create a new TLS for the child */
#define CLONE_PARENT_SETTID	0x00100000	/* set the TID in the parent */
#define CLONE_CHILD_CLEARTID	0x00200000	/* clear the TID in the child */
#define CLONE_DETACHED		0x00400000	/* Unused, ignored */
#define CLONE_UNTRACED		0x00800000	/* set if the tracing process can't force CLONE_PTRACE on this clone */
#define CLONE_CHILD_SETTID	0x01000000	/* set the TID in the child */
/* 0x02000000 was previously the unused CLONE_STOPPED (Start in stopped state)
and is now available for re-use. */
#define CLONE_NEWUTS		0x04000000	/* New utsname group? */
#define CLONE_NEWIPC		0x08000000	/* New ipcs */
#define CLONE_NEWUSER		0x10000000	/* New user namespace */
#define CLONE_NEWPID		0x20000000	/* New pid namespace */
#define CLONE_NEWNET		0x40000000	/* New network namespace */
#define CLONE_IO		0x80000000	/* Clone io context */

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  接下来深入看一下核心函数copy_process，它主要完成了页表和寄存器值的复制，这里我们略去cgroup和一些非重点代码：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/kernel/fork.c:

/*
 * This creates a new process as a copy of the old one,
 * but does not actually start it yet.
 *
 * It copies the registers, and all the appropriate
 * parts of the process environment (as per the clone
 * flags). The actual kick-off is left to the caller.
 */
static struct task_struct *copy_process(unsigned long clone_flags,
            unsigned long stack_start,
            unsigned long stack_size,
            int __user *child_tidptr,
            struct pid *pid,
            int trace)
{
    int retval;
    struct task_struct *p;
    
    ...
    /*分配task_struct结构内存和thread_info页，并将当前进程相关信息复制到对应内存字段*/
    retval = -ENOMEM;
    p = dup_task_struct(current);
    if (!p)
        goto fork_out;

    ...
    /* Perform scheduler related setup. Assign this task to a CPU. */
    sched_fork(p);

    ...
    /*新建并复制task_struct中files字段，它表示已打开文件；
      如果CLONE_FILES置位，则共享当前进程的files*/
    retval = copy_files(clone_flags, p);

    ...
    /*新建并复制task_struct中的fs字段，它表示当前目录；
      如果CLONE_FS置位，则共享当前进程的fs*/
    retval = copy_fs(clone_flags, p);

    ...
    /*复制信号及信号处理函数*/
    retval = copy_sighand(clone_flags, p);
    ...
    retval = copy_signal(clone_flags, p);

    ...
    /*新建并复制mm_struct，并完成页表复制；
      如果CLONE_VM置位，则共享当前进程的mm_struct*/
    retval = copy_mm(clone_flags, p);

    ...
    /*复制寄存器值*/
    retval = copy_thread(clone_flags, stack_start, stack_size, p);

    ...
    return p;
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static int copy_mm(unsigned long clone_flags, struct task_struct *tsk)
{
    struct mm_struct *mm, *oldmm;
    int retval;

    ...
    tsk-&amp;gt;mm = NULL;
    tsk-&amp;gt;active_mm = NULL;

    /*
     * Are we cloning a kernel thread?
     *
     * We need to steal a active VM for that..
     */
    oldmm = current-&amp;gt;mm;
    if (!oldmm)
        return 0;

    /*如果CLONE_VM置位，则共享当前进程mm_struct*/
    if (clone_flags &amp;amp; CLONE_VM) {
        atomic_inc(&amp;amp;oldmm-&amp;gt;mm_users);
        mm = oldmm;
        goto good_mm;
    }

    retval = -ENOMEM;
    mm = dup_mm(tsk);
    if (!mm)
        goto fail_nomem;

good_mm:
    tsk-&amp;gt;mm = mm;
    tsk-&amp;gt;active_mm = mm;
    return 0;

fail_nomem:
    return retval;
}

/*
 * Allocate a new mm structure and copy contents from the
 * mm structure of the passed in task structure.
 */
struct mm_struct *dup_mm(struct task_struct *tsk)
{
    struct mm_struct *mm, *oldmm = current-&amp;gt;mm;
    int err;

    if (!oldmm)
        return NULL;

    /*分配mm_struct内存*/
    mm = allocate_mm();
    if (!mm)
        goto fail_nomem;
    
    /*复制mm_struct内容，这里没有加锁保护，我理解是因为其中关键字段
      会在后续流程中重新赋值*/
    memcpy(mm, oldmm, sizeof(*mm));
    mm_init_cpumask(mm);

    ...
    /*重新初始化mm_struct中相关字段，这里会重新分配pgd表并将内核空间
      地址映射复制到其中*/
    if (!mm_init(mm, tsk))
        goto fail_nomem;

    if (init_new_context(tsk, mm))
        goto fail_nocontext;

    dup_mm_exe_file(oldmm, mm);

    /*复制用户态vma段和页表*/
    err = dup_mmap(mm, oldmm);
    if (err)
        goto free_pt;

    ...

    return mm;

    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int copy_thread(unsigned long clone_flags, unsigned long sp,
        unsigned long arg, struct task_struct *p)
{
    int err;
    struct pt_regs *childregs;
    struct task_struct *me = current;

    /*task_stack_page(p)，即p-&amp;gt;stack，为thread_info起始地址；加上THREAD_SIZE
      后为内核栈起始地址*/
    p-&amp;gt;thread.sp0 = (unsigned long)task_stack_page(p) + THREAD_SIZE;

    /*childregs指向内核栈中保留所有寄存器后的偏移位置*/
    childregs = task_pt_regs(p);
    p-&amp;gt;thread.sp = (unsigned long) childregs;

    /*复制当前进程的用户态栈指针*/
    p-&amp;gt;thread.usersp = me-&amp;gt;thread.usersp;

    /*设置TIF_FORK标记，fork系统调用返回时用来判断是否
      为新生成的进程*/
    set_tsk_thread_flag(p, TIF_FORK);
    ...

    /*对于内核进程，sp中保存的是入口函数指针*/
    if (unlikely(p-&amp;gt;flags &amp;amp; PF_KTHREAD)) {
        /* kernel thread */
        memset(childregs, 0, sizeof(struct pt_regs));
        childregs-&amp;gt;sp = (unsigned long)childregs;
        childregs-&amp;gt;ss = __KERNEL_DS;
        childregs-&amp;gt;bx = sp; /* function */
        childregs-&amp;gt;bp = arg;
        childregs-&amp;gt;orig_ax = -1;
        childregs-&amp;gt;cs = __KERNEL_CS | get_kernel_rpl();
        childregs-&amp;gt;flags = X86_EFLAGS_IF | X86_EFLAGS_FIXED;
        return 0;
    }
    
    /*复制当前进程在执行fork系统调用时保存的寄存器状态*/
    *childregs = *current_pt_regs();

    /*子进程的ax寄存器赋为零，该值即fork系统调用的返回值*/
    childregs-&amp;gt;ax = 0;

    /*如果传入sp指针，则更新fork返回后栈指针值*/
    if (sp)
        childregs-&amp;gt;sp = sp;

    ...
    return err;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;零号进程与一号进程&quot;&gt;&lt;strong&gt;零号进程与一号进程&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  系统中有两个比较特殊的进程，即零号和一号进程。零号进程是内核初始化过程中最早产生的进程，最终成为bsp(SMP系统中的启动CPU)上的idle进程(swapper)。零号进程会创建一号进程，由一号进程完成部分初始化动作并拉起shell进程。最终一号进程成为所有孤儿进程的回收进程而长期存在于系统之中。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2018/01/进程创建/&quot;&gt;进程管理之一：进程创建&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 03 Jan 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2018/01/%E8%BF%9B%E7%A8%8B%E5%88%9B%E5%BB%BA/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/01/%E8%BF%9B%E7%A8%8B%E5%88%9B%E5%BB%BA/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>内存管理之六：初始化</title>
        <description>&lt;p&gt;  初始化过程往往是比较冗长且乏味的，如果一接触就开始学习这块内容会让人烦闷。在了解内存管理几个核心功能模块后，我们再回头看看内存管理的初始化过程，相信大家会有新的收获。计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;低级阶段-汇编实现&quot;&gt;低级阶段-汇编实现&lt;/h3&gt;

&lt;p&gt;  我们可以把整个内存初始化过程大体分成低级阶段和高级阶段两个过程。低级阶段主要是用低级汇编语言实现的，又可细分成三步：&lt;/p&gt;

&lt;p&gt;  首先是BIOS，它在计算机启动的最初阶段检测了物理内存的分布情况，并在x86实模式的高端地址处(1M内存以下)记录了这些内存分布信息(称为e820表)。e820表是一个数组，每一项记录了一段连续内存信息，包含起始地址、结束地址和内存类型。内存类型分为普通内存(RAM)、保留内存(RESERVED，如BIOS内存)、ACPI表空间等。此外，对于NUMA结构系统，BIOS还将产生ACPI的SRAT表，用来记录每个numa节点的内存分布。&lt;/p&gt;

&lt;p&gt;  接着BIOS通过引导GRUB，再由GRUB将内核实模式部分和保护模式部分加载进内存。之后GRUB跳转到内核实模式部分执行，此时内核通过int指令获取e820表信息，由此得知物理内存分布。&lt;/p&gt;

&lt;p&gt;  在低级阶段的最后，内核进入保护模式，设置了高端虚拟地址到物理地址的线性映射，并将栈空间设定在了0号进程(BSP启动核对应的IDLE进程)的栈空间，随后就进入了高级阶段。&lt;/p&gt;

&lt;h3 id=&quot;高级阶段-c语言实现&quot;&gt;高级阶段-C语言实现&lt;/h3&gt;

&lt;p&gt;  高级阶段的入口函数是start_kernel，与内存管理相关的部分主要setup_arch中。&lt;/p&gt;

&lt;p&gt;  首先，我们会看到一些以memblock_打头的函数，这是干嘛的？我们应该知道，完整的内存初始化过程完成之前，正常的内存申请和释放功能是没法使用的。但是内核初始化过程中也需要动态分配内存，这就产生了矛盾。内核的做法是在初始化阶段使用一个简便的内存管理方法，这就是memblock。它从e820表中获知内存的分布情况，并以简单的连续分配方法来管理内存。所以在内核初始化阶段，它使用memblock来进行内存的申请和释放。&lt;/p&gt;

&lt;p&gt;  接着在init_mem_mapping中，内核将direct mapping区线性映射到整个物理空间。如此一来，内核便可访问所有物理内存了。大家可以回顾下Linux 3.10/Documentation/x86/x86_64/mm.txt。&lt;/p&gt;

&lt;p&gt;  再接着在initmem_init中，通过读取ACPI的SRAT表获知NUMA信息，并将这些信息更新到memblock中，此时内核就得知了完整的内存分布信息：有多少段内存，每段内存分别属于哪个NUMA节点。这里内核会为每个节点创建struct pglist_data结构，用来记录内存分布信息。&lt;/p&gt;

&lt;p&gt;  随后进入了和分页相关的初始化过程paging_init。这里又涉及内核的sparse_memory特性，这又是什么鬼？内核在管理内存时，是需要分配独立的内存页来记录内存信息的，比如struct page数组。早期的内核是按最大物理内存量固定分配，对于小内存场景，这种方法问题不大。然而当前系统内存越来越大(x86_64最大支持2^46)，而且内存可能动态增加(热插内存条)时，固定分配的方法就不适用了。sparse memory则以更灵活的方式来分配管理内存，如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory6_1.jpg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  内核将所有内存(最大2^46)划分成区(128M)，并通过一个数组mem_section来记录每个区的信息。对于数组mem_section，是按4K页为粒度来分配空间，本质可以视为一个两维数组。内核通过memblock记录的信息为可用内存动态分配管理空间，不可用的区间将置为空，或者将section_mem_map低位清零(代表对应的区不存在)。在此过程中，内核也会对struct page数组分配空间，并将地址记录到section_mem_map中。&lt;/p&gt;

&lt;p&gt;  完成sparse memory的初始化后，内核通过free_area_init_nodes来初始化内核NUMA节点的空闲内存信息。此时页管理系统没有任何空闲内存。那么空闲内存是怎么来的？这就回到start_kernel中，它先通过build_all_zonelists建立分配zone序列，再通过mem_init调用free_all_bootmem，这里会把memblock中的空闲内存释放到页管理系统中。此后，内核就可以使用正常的alloc_pages函数来分配页了。&lt;/p&gt;

&lt;p&gt;  在2017年的最后几天里，终于把内核中有关内存管理方面的基础内容分析完了，但整个内存管理涉及的知识面非常广，还包括：反向映射、大页内存管理、KSM、cgroup_memory等多个方面。要想真正精通内存管理，需要坚持长期学习，并不断总结与实践。2018，继续努力！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/12/内存初始化/&quot;&gt;内存管理之六：内存初始化&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 29 Dec 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/12/%E5%86%85%E5%AD%98%E5%88%9D%E5%A7%8B%E5%8C%96/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/12/%E5%86%85%E5%AD%98%E5%88%9D%E5%A7%8B%E5%8C%96/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>内存管理之五：内存压缩</title>
        <description>&lt;p&gt;  本节将讨论内存压缩，计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是内存压缩为什么需要它&quot;&gt;什么是内存压缩？为什么需要它？&lt;/h3&gt;

&lt;p&gt;  内存压缩(memory compaction)是指把应用程序正在使用的物理页内容迁移(migrate)到其它物理页中，以释放原有物理页，从而方便空闲页的合并以形成大段连续空闲内存，有效避免内存碎片的产生。&lt;/p&gt;

&lt;p&gt;  前文介绍优化型伙伴算法时，我们已经看到空闲内存被分成不可移动、可回收、可移动几个类别，应用程序从可移动类别中获取内存页。连续的内存分配和释放如果产生碎片无法满足当前内存分配请求时，内核进入慢速分配流程触发内存压缩，进行碎片整理，从而最大限度满足分配需求。&lt;/p&gt;

&lt;h3 id=&quot;如何实现&quot;&gt;如何实现？&lt;/h3&gt;

&lt;p&gt;  从整体流程上看，内存分配函数alloc_pages在快速流程get_page_from_freelist无法满足时，会进入慢速流程__alloc_pages_slowpath。慢速流程中进行一系列尝试后如果仍然无法满足分配需求，则进入compact_zone内存压缩流程。&lt;/p&gt;

&lt;p&gt;  内存压缩是通过迁移实现，迁移就涉及源端和目的端，那么内存压缩过程所要考虑的第一个问题就是源端页从哪来？目的端页又从哪来？Linux内核采用的策略是把低地址的页移动到高地址，从而在低地址端形成大段连续内存。因此内核从低往高扫描内存区(zone)，收集需要迁移的源端内存页；另一方面从高往低扫描，获取迁移目的端的空闲页。迁移源端页的收集在isolate_migratepage函数中实现，目的端页的收集在isolate_freepages函数中实现，有兴趣的读者可以深入进一步分析。&lt;/p&gt;

&lt;p&gt;  迁移源端和目的端确认后，下面要考虑的就是迁移动作该如何完成。粗略来说，需要将源端页内容拷贝到目的页、将文件映射关系中的源端页替换成目的端页、解除源端页在页表中的映射并重新映射目的页。&lt;/p&gt;

&lt;p&gt;  下图展示了使用中的物理页的映射关系：进程的虚拟地址段(vma)通过mmap被映射到文件段；文件内容读取到物理内存后以缓存页方式被组织成文件映射树；页表将虚拟地址映射到文件缓存页，供MMU使用实现地址转换。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory5_1.jpg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  基于上图，我们看看迁移过程：总体分两步，首先解映射源端页；其次是将映射树的源端页替换成目的页，包括内存页内容的拷贝。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory5_2.jpg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory5_3.jpg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  有的读者可能会问，怎么最后没有重新将虚拟地址映射到目的页呢？内核采用的是lazy的方式，当进程访问缺页时会完成重新映射。
详细代码在migrate_pages中：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/migrate.c:

/*
 * migrate_pages - migrate the pages specified in a list, to the free pages
 *		   supplied as the target for the page migration
 *
 * @from:		The list of pages to be migrated.
 * @get_new_page:	The function used to allocate free pages to be used
 *			as the target of the page migration.
 * @private:		Private data to be passed on to get_new_page()
 * @mode:		The migration mode that specifies the constraints for
 *			page migration, if any.
 * @reason:		The reason for page migration.
 *
 * The function returns after 10 attempts or if no pages are movable any more
 * because the list has become empty or no retryable pages exist any more.
 * The caller should call putback_lru_pages() to return pages to the LRU
 * or free list only if ret != 0.
 *
 * Returns the number of pages that were not migrated, or an error code.
 */
int migrate_pages(struct list_head *from, new_page_t get_new_page,
                unsigned long private, enum migrate_mode mode, int reason)
{
    int retry = 1;
    int nr_failed = 0;
    int nr_succeeded = 0;
    int pass = 0;
    struct page *page;
    struct page *page2;
    int swapwrite = current-&amp;gt;flags &amp;amp; PF_SWAPWRITE;
    int rc;

    if (!swapwrite)
        current-&amp;gt;flags |= PF_SWAPWRITE;

    for(pass = 0; pass &amp;lt; 10 &amp;amp;&amp;amp; retry; pass++) {
        retry = 0;

        list_for_each_entry_safe(page, page2, from, lru) {
            cond_resched();

            /*解映射页表并移动内存页，内部将调用__unmap_and_move*/
            rc = unmap_and_move(get_new_page, private, page, pass &amp;gt; 2, mode);

            switch(rc) {
            case -ENOMEM:
                goto out;
            case -EAGAIN:
                retry++;
                break;
            case MIGRATEPAGE_SUCCESS:
                nr_succeeded++;
                break;
            default:
                /* Permanent failure */
                nr_failed++;
                break;
            }
        }
    }
    rc = nr_failed + retry;
out:
    if (nr_succeeded)
        count_vm_events(PGMIGRATE_SUCCESS, nr_succeeded);
    if (nr_failed)
        count_vm_events(PGMIGRATE_FAIL, nr_failed);
    trace_mm_migrate_pages(nr_succeeded, nr_failed, mode, reason);

    if (!swapwrite)
        current-&amp;gt;flags &amp;amp;= ~PF_SWAPWRITE;

    return rc;
}

static int __unmap_and_move(struct page *page, struct page *newpage,
                                int force, enum migrate_mode mode)
{
    int rc = -EAGAIN;
    int remap_swapcache = 1;
    struct mem_cgroup *mem;
    struct anon_vma *anon_vma = NULL;

    /*锁定迁移源端页*/
    if (!trylock_page(page)) {
        ...
    }

    if (PageWriteback(page)) {
        /*跳过或等待writeback页回刷完成*/
        ...
    }
    ...

    /* Establish migration ptes or remove ptes */
    try_to_unmap(page, TTU_MIGRATION|TTU_IGNORE_MLOCK|TTU_IGNORE_ACCESS);

skip_unmap:
    if (!page_mapped(page))
        rc = move_to_new_page(newpage, page, remap_swapcache, mode);

    ...
out:
    return rc;
}

static int move_to_new_page(struct page *newpage, struct page *page,
                    int remap_swapcache, enum migrate_mode mode)
{
    struct address_space *mapping;
    int rc;

    /*
     * Block others from accessing the page when we get around to
     * establishing additional references. We are the only one
     * holding a reference to the new page at this point.
     */
    if (!trylock_page(newpage))
        BUG();

    /* Prepare mapping for the new page.*/
    newpage-&amp;gt;index = page-&amp;gt;index;
    newpage-&amp;gt;mapping = page-&amp;gt;mapping;
    if (PageSwapBacked(page))
        SetPageSwapBacked(newpage);
    
    mapping = page_mapping(page);
    /*调用底层文件系统接口实现页迁移*/
    if (!mapping)
        rc = migrate_page(mapping, newpage, page, mode);
    else if (mapping-&amp;gt;a_ops-&amp;gt;migratepage)
    /*
     * Most pages have a mapping and most filesystems provide a
     * migratepage callback. Anonymous pages are part of swap
     * space which also has its own migratepage callback. This
     * is the most common path for page migration.
     */
        rc = mapping-&amp;gt;a_ops-&amp;gt;migratepage(mapping, newpage, page, mode);
    else
        rc = fallback_migrate_page(mapping, newpage, page, mode);
    if (rc != MIGRATEPAGE_SUCCESS) {
        newpage-&amp;gt;mapping = NULL;
    } else {
        if (remap_swapcache)
            remove_migration_ptes(page, newpage);
        page-&amp;gt;mapping = NULL;
    }

    unlock_page(newpage);

    return rc;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  至此，慢速分配中的核心的内存压缩流程已分析完成，更底层的细节涉及具体文件系统实现，大家可以继续深入分析。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/12/内存压缩/&quot;&gt;内存管理之五：内存压缩&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 02 Dec 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/12/%E5%86%85%E5%AD%98%E5%8E%8B%E7%BC%A9/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/12/%E5%86%85%E5%AD%98%E5%8E%8B%E7%BC%A9/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>内存管理之四：内存交换</title>
        <description>&lt;p&gt;  本节将讨论内存交换，计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是内存交换为什么需要它&quot;&gt;什么是内存交换？为什么需要它？&lt;/h3&gt;

&lt;p&gt;  当系统内存使用压力较大时，内核会将访问率不好的匿名页暂时写到磁盘(换出)以释放这部分匿名页供系统使用；当换出的页再次被访问时，内核重新将其读入(换入)。&lt;/p&gt;

&lt;p&gt;  内存交换是回收匿名页的唯一手段。我们知道，应用程序使用的内存页分为文件映射页和匿名页两种。对于文件映射页，回收时可以将它的内容回刷到映射文件中。而对于匿名页(也包括私有的文件映射页)，默认情况下没有持久化文件和它对应。如果要回收这部分内存，必然要寻找可以暂时存放内容的存储对象。因此就出现了交换分区和内存交换的概念。&lt;/p&gt;

&lt;h3 id=&quot;如何实现&quot;&gt;如何实现？&lt;/h3&gt;

&lt;h4 id=&quot;交换分区&quot;&gt;&lt;strong&gt;交换分区&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  我们可以通过设置交换分区来打开内存交换功能，具体可参考swapon命令的使用方法。交换分区可以是一个物理磁盘分区，也可以是一个普通文件，在内核中只要是一个文件对象就可以。&lt;/p&gt;

&lt;p&gt;  交换分区以页为单位进行管理分配，内核通过一个引用数组记录交换分区中的每个页被进程的引用次数。每次换出同一页时，该页对应的引用数加一；换入时则相反，每换入一次就减一。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory4_0.jpg&quot; height=&quot;300&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;换出时机&quot;&gt;&lt;strong&gt;换出时机&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  在内存回收快速分配流程中，如果选择回收匿名页，或者在慢速流程中唤醒kswapd内核服务进程回收匿名页时，都会将匿名页换出。&lt;/p&gt;

&lt;h4 id=&quot;换出流程&quot;&gt;&lt;strong&gt;换出流程&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  在shrink_page_list函数中，我们关注其中和匿名页相关的部分就可以了解整个换出流程。代码片断参考&lt;a href=&quot;https://rootw.github.io/2017/10/内存回收/&quot;&gt;内存回收&lt;/a&gt;，更深入的细节需要进一步深入pageout函数进行分析。&lt;/p&gt;

&lt;p&gt;  整个过程可以参考下图：匿名页换出前(图a)，首先要把它加到交换分区文件对应的交换缓存(Swap Cache)中(图b)。交换缓存其实就是交换分区对应的文件缓存，和普通文件缓存一样，它也是通过一棵radix树进行数据组织。交换缓存把交换过程和文件系统关联了起来，我们可以通过文件系统抽象接口完成交换动作。另外，交换缓存也成为换出和换入过程需要使用的共享资源，通过锁机制可以有效达到同步效果。&lt;/p&gt;

&lt;p&gt;  接着内核便通过反向映射找到匿名页所有的映射页表，解除页表映射(图c)，并在页表中填入匿名页在交换分区中对应的位置信息。之所以在页表中填入匿名页在交换分区的存放位置，是便于在换入时重新读取页内容。&lt;/p&gt;

&lt;p&gt;  映射关系全部解除后，如果脏页内容已回刷完成，内核就可以将匿名页从缓存分区中移除并回收该页(图e)。图d表示解除页表映射后，进程B再次访问该匿名页的场景。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory4_1.jpg&quot; height=&quot;450&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;换入流程&quot;&gt;&lt;strong&gt;换入流程&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  换入发生在被换出的匿名页再次被访问时，此时首先会进入页异常处理过程。内核通过判断页表内容确认需要进行换入操作时，将调用do_swap_page完成换入动作。&lt;/p&gt;

&lt;p&gt;  该函数整体思路比较明确：先查找交换缓存看是否存在期望的匿名页，如果存在则重新映射并更新页表；否则就分配新页加到交换缓存中，在读取页内容完成后即可映射给页表。每次发生换入操作时，交换分区对应页的引用计数减一，当发现交换分区中对应页的引用为零时，表示没有进程引用该页，便可将交换分区中的页回收。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/memory.c:

static int do_swap_page(struct mm_struct *mm, struct vm_area_struct *vma,
                    unsigned long address, pte_t *page_table, pmd_t *pmd,
                    unsigned int flags, pte_t orig_pte)
{
    spinlock_t *ptl;
    struct page *page, *swapcache;
    swp_entry_t entry;
    pte_t pte;
    int locked;
    int exclusive = 0;
    int ret = 0;

    entry = pte_to_swp_entry(orig_pte); /*从页表项中找出换出页在交换分区中的位置*/
    
    ...

    page = lookup_swap_cache(entry); /*查找交换缓冲区*/
    if (!page) {
        /*如果交换缓冲区未缓存当前交换位置，则重新分配内存页并从交换分区中读入内容*/
        page = swapin_readahead(entry, GFP_HIGHUSER_MOVABLE, vma, address);
        ...
    } else if (PageHWPoison(page)) {
    ...
    }

    swapcache = page;
    locked = lock_page_or_retry(page, mm, flags);

    ...

    /*重新在页表中添加映射*/
    page_table = pte_offset_map_lock(mm, pmd, address, &amp;amp;ptl);
    ...
    pte = mk_pte(page, vma-&amp;gt;vm_page_prot);
    ...
    set_pte_at(mm, address, page_table, pte);
    if (page == swapcache)
        do_page_add_anon_rmap(page, vma, address, exclusive);
    else /* ksm created a completely new copy */
        page_add_new_anon_rmap(page, vma, address);
    ...
    swap_free(entry); /*减少当前交换位置的引用计数*/
    ...
    return ret;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  至此，快速分配流程中涉及的回收和交换过程已分析完毕，后续我们将分析慢速分配流程中的内存压缩(迁移)功能。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/11/内存交换/&quot;&gt;内存管理之四：内存交换&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 03 Nov 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/11/%E5%86%85%E5%AD%98%E4%BA%A4%E6%8D%A2/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/11/%E5%86%85%E5%AD%98%E4%BA%A4%E6%8D%A2/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>内存管理之三：内存回收</title>
        <description>&lt;p&gt;  本节将讨论内存回收，计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是内存回收为什么需要它&quot;&gt;什么是内存回收？为什么需要它？&lt;/h3&gt;

&lt;p&gt;  内存分配过程中如果发现剩余内存量低于预定的水位线(代表内存使用紧张)，就会强制回收一部分使用频度不高的已分配内存，供后续分配使用。如此一来，好的方面是可最大限度满足系统内应用程序的内存分配请求，提升系统可用性。坏的方面是被回收页所属的应用可能再次访问该页，需要通过缺页处理再次分配映射页，从而带来应用性能的下降。一个优秀的内存回收算法需要在系统整体可用性和应用性能之间寻找合适的平衡点。&lt;/p&gt;

&lt;h3 id=&quot;如何实现&quot;&gt;如何实现？&lt;/h3&gt;

&lt;h4 id=&quot;1-四大链表&quot;&gt;&lt;strong&gt;1. 四大链表&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  内存回收需要思考的第一个问题是关于回收对象，即回收谁？Linux内核只能回收动态分配给应用程序的内存页，内核自身直接分配使用的页是不参与回收的(通过slab分配的内存可回收，这里我们不做深入讨论)。应用程序使用的内存页要么是通过文件映射的(如代码段)，要么是匿名映射的(如堆栈段)。因此内核将分配给应用程序的内存页分为两大类，即文件页和匿名页；同时根据内存页使用的频度又分为活跃页和不活跃
页。这样，内核针对NUMA节点的每个zone将已分配页放到四个LRU链表中：非活跃匿名页链表、活跃匿名页链表、非活跃文件页链表、活跃文件页链表。触发内存回收后，内核会将活跃页链表中使用频度低的页淘汰到非活跃页链表中，再从非活跃页链表中取出频度低的页直接回收。每个zone的四大链表定义如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/include/linux/mmzone.h:

/*
 * We do arithmetic on the LRU lists in various places in the code,
 * so it is important to keep the active lists LRU_ACTIVE higher in
 * the array than the corresponding inactive lists, and to keep
 * the *_FILE lists LRU_FILE higher than the corresponding _ANON lists.
 *
 * This has to be kept in sync with the statistics in zone_stat_item
 * above and the descriptions in vmstat_text in mm/vmstat.c
 */
#define LRU_BASE 0
#define LRU_ACTIVE 1
#define LRU_FILE 2

enum lru_list {
    LRU_INACTIVE_ANON = LRU_BASE,
    LRU_ACTIVE_ANON = LRU_BASE + LRU_ACTIVE,
    LRU_INACTIVE_FILE = LRU_BASE + LRU_FILE,
    LRU_ACTIVE_FILE = LRU_BASE + LRU_FILE + LRU_ACTIVE,
    LRU_UNEVICTABLE,
    NR_LRU_LISTS
};
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  了解四大链表结构后，可以思考内核是如何感知内存页的活跃程度的？内核是通过mark_page_accessed函数显式标记页的活跃程度。初始分配的匿名页被放置到活跃链表中，而文件页被放置到非活跃链表中，并由内核在后续操作过程中显式标记活跃程度：连续两次被访问后，该页将被移动到活跃页链表中。相关函数如下:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/swap.c:

/*
 * Mark a page as having seen activity.
 *
 * inactive,unreferenced	-&amp;gt;	inactive,referenced
 * inactive,referenced		-&amp;gt;	active,unreferenced
 * active,unreferenced		-&amp;gt;	active,referenced
 */
void mark_page_accessed(struct page *page)
{
    if (!PageActive(page) &amp;amp;&amp;amp; !PageUnevictable(page) &amp;amp;&amp;amp;
            PageReferenced(page) &amp;amp;&amp;amp; PageLRU(page)) {
        activate_page(page);
        ClearPageReferenced(page);
    } else if (!PageReferenced(page)) {
        SetPageReferenced(page);
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;2-整体流程&quot;&gt;&lt;strong&gt;2. 整体流程&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  以下调用流程以页分配为出发点来跟踪内存回收shrink_zone：get_scan_count计算各个链表的回收比例，然后再通过shrink_list依次回收。下面我们进一步展开。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alloc_pages
    -&amp;gt;get_page_from_freelist
        -&amp;gt;zone_reclaim
            -&amp;gt;shrink_zone
                -&amp;gt;shrink_lruvec
                    -&amp;gt;get_scan_count
                    -&amp;gt;shrink_list
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;21-回收比例&quot;&gt;&lt;strong&gt;2.1 回收比例&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  内存回收时有四大链表供选择，每次回收时都需要扫描所有链表吗？不是这样的，内核通过get_scan_count计算每个链表的扫描比例，比例越高回收的页可能就越多。这个函数详细的代码就不分析了，有点复杂，我们只需要知道最终nr数组会记录每个链表的扫描页数。&lt;/p&gt;

&lt;h4 id=&quot;22-活跃链表回收&quot;&gt;&lt;strong&gt;2.2 活跃链表回收&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  通过下面shrink_list的代码，我们可以清楚看到，针对活跃链表，如果非活跃页偏少则通过shrink_active_list将部分活跃页移动到非活跃页中，此时并不进行回收动作。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/vmscan.c:

static unsigned long shrink_list(enum lru_list lru, unsigned long nr_to_scan,
                            struct lruvec *lruvec, struct scan_control *sc)
{
    if (is_active_lru(lru)) {
        if (inactive_list_is_low(lruvec, lru))
            shrink_active_list(nr_to_scan, lruvec, sc, lru);
        return 0;
    }

    return shrink_inactive_list(nr_to_scan, lruvec, sc, lru);
}

static void shrink_active_list(unsigned long nr_to_scan,
                        struct lruvec *lruvec,
                        struct scan_control *sc,
                        enum lru_list lru)
{
    unsigned long nr_taken;
    unsigned long nr_scanned;
    unsigned long vm_flags;
    LIST_HEAD(l_hold);	/* The pages which were snipped off */
    LIST_HEAD(l_active);
    LIST_HEAD(l_inactive);
    struct page *page;
    unsigned long nr_rotated = 0;
    isolate_mode_t isolate_mode = 0;
    int file = is_file_lru(lru);
    struct zone *zone = lruvec_zone(lruvec);

    ...

    spin_lock_irq(&amp;amp;zone-&amp;gt;lru_lock);
    /*从活跃链表lruvec[lru]中移动部分页到l_hold中，nr_scanned记录移动页数*/
    nr_taken = isolate_lru_pages(nr_to_scan, lruvec, &amp;amp;l_hold,
                        &amp;amp;nr_scanned, sc, isolate_mode, lru);
    ...
    spin_unlock_irq(&amp;amp;zone-&amp;gt;lru_lock);

    while (!list_empty(&amp;amp;l_hold)) {
        /*针对l_hold中的每一页，偿试将其移动到非活跃链表中*/
        cond_resched();
        page = lru_to_page(&amp;amp;l_hold);
        list_del(&amp;amp;page-&amp;gt;lru);

        ...

        /*判断当前页page是否被访问，涉及反向映射，大家感兴趣可以深入分析*/
        if (page_referenced(page, 0, sc-&amp;gt;target_mem_cgroup, &amp;amp;vm_flags)) {
            nr_rotated += hpage_nr_pages(page);
            /*
             * Identify referenced, file-backed active pages and
             * give them one more trip around the active list. So
             * that executable code get better chances to stay in
             * memory under moderate memory pressure.  Anon pages
             * are not likely to be evicted by use-once streaming
             * IO, plus JVM can create lots of anon VM_EXEC pages,
             * so we ignore them here.
             */
            /*针对JVM场景，保留VM_EXEC段的文件页在活跃链表中*/
            if ((vm_flags &amp;amp; VM_EXEC) &amp;amp;&amp;amp; page_is_file_cache(page)) {
                list_add(&amp;amp;page-&amp;gt;lru, &amp;amp;l_active);
                continue;
            }
        }
        
        /*清除当前页的活跃标记，并放入临时链表l_inactive中，为后续移动作准备*/
        ClearPageActive(page);	/* we are de-activating */
        list_add(&amp;amp;page-&amp;gt;lru, &amp;amp;l_inactive);
    }

    /*
     * Move pages back to the lru list.
     */
    spin_lock_irq(&amp;amp;zone-&amp;gt;lru_lock);
    ...
    move_active_pages_to_lru(lruvec, &amp;amp;l_active, &amp;amp;l_hold, lru); /*批量将l_active中的页移回活跃链表*/
    move_active_pages_to_lru(lruvec, &amp;amp;l_inactive, &amp;amp;l_hold, lru - LRU_ACTIVE); /*批量将l_inactive中的页移到非活跃链表中*/
    __mod_zone_page_state(zone, NR_ISOLATED_ANON + file, -nr_taken);
    spin_unlock_irq(&amp;amp;zone-&amp;gt;lru_lock);

    free_hot_cold_page_list(&amp;amp;l_hold, 1); /*l_hold保留移动过程中已被释放的内存页，这里将其正式释放*/
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;23-非活跃链表回收&quot;&gt;&lt;strong&gt;2.3 非活跃链表回收&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  非活跃链表中的页是重点回收对象，核心功能在shrink_page_list函数中实现。该函数对非活跃链表尾部的若干页依次进行扫描：首先对当前扫描页加锁，避免扫描期间同时存在其它页操作；接着通过writeback标记判断当前扫描页是否正在被回写，如果是则跳过当前页去扫描下一页；接着判断当前页是否被访问过，如果页表的accessed位被置位则说明页被访问过，清除标记后任跳过当前页；页未被访问情况下，为匿名页添加交换分区映射(文件页必然有文件与之相应)，之后正式解除当前扫描页的页表映射；页表映射解除成功后，开始回刷脏页，待脏页回刷完成后最后将当前页从文件缓存映射或匿名映射中移除，之后便可释放当前页。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/vmscan.c:

/*
 * shrink_page_list() returns the number of reclaimed pages
 */
static unsigned long shrink_page_list(struct list_head *page_list,
                                struct zone *zone,
                                struct scan_control *sc,
                                enum ttu_flags ttu_flags,
                                unsigned long *ret_nr_dirty,
                                unsigned long *ret_nr_writeback,
                                bool force_reclaim)
{
/*参数说明：page_list记录待回收的非活跃页；zone代表当前被回收的zone；sc为回收控制变量；
          ttu_flags表示unmap解除页表映射操作标志；ret_nr_dirty表示返回给外层的脏页数；
          ret_nr_writeback表示返回给外层的正在回写的页数；force_relcaim代表强制回收*/

    LIST_HEAD(ret_pages); /*保存不可回收的页*/
    LIST_HEAD(free_pages); /*保存可回收的页*/
    int pgactivate = 0;
    unsigned long nr_dirty = 0;
    unsigned long nr_congested = 0;
    unsigned long nr_reclaimed = 0;
    unsigned long nr_writeback = 0;

    
    while (!list_empty(page_list)) { /*对page_list中待回收页依次进行回收*/
        struct address_space *mapping;
        struct page *page;
        int may_enter_fs;
        enum page_references references = PAGEREF_RECLAIM_CLEAN;

        cond_resched();

        page = lru_to_page(page_list);
        list_del(&amp;amp;page-&amp;gt;lru);

        /*偿试锁定当前页，如果无法锁定则保留当前页*/
        if (!trylock_page(page))
            goto keep;

        ...

        /*处理writeback页，该标记表示内存页正在被回刷落盘，但IO操作有可能还未完成*/
        if (PageWriteback(page)) {

            if (global_reclaim(sc) || !PageReclaim(page) || !may_enter_fs) {
                /*对于全局回收等场景，不对writeback页作回收，将其放回链表*/
                SetPageReclaim(page);
                nr_writeback++;
                goto keep_locked;
            }
            wait_on_page_writeback(page); /*其它情况下将等待页面回刷完成*/
        }

        /*对于非强制回收场景，需要检查当前待回收页的访问情况，确定访问不频繁才可回收*/
        if (!force_reclaim)
            references = page_check_references(page, sc);

        switch (references) {
        case PAGEREF_ACTIVATE:
            goto activate_locked;
        case PAGEREF_KEEP:
            goto keep_locked;
        case PAGEREF_RECLAIM:
        case PAGEREF_RECLAIM_CLEAN:
            ;/* try to reclaim the page below */
        }

        /*如果执行到这里，说明当前页是一个可回收的非writeback页*/

        /*
         * Anonymous process memory has backing store?
         * Try to allocate it some swap space here.
         */
        if (PageAnon(page) &amp;amp;&amp;amp; !PageSwapCache(page)) {
            /*针对匿名页，如果不在交换缓冲区中(交换分区对应的内存页缓存)，需要将它加入其中*/
            if (!(sc-&amp;gt;gfp_mask &amp;amp; __GFP_IO))
                goto keep_locked;
            if (!add_to_swap(page, page_list))
                goto activate_locked;
                may_enter_fs = 1;
        }

        mapping = page_mapping(page);

        /*执行到这里，说明当前页已建立后端映射关系：文件页对应文件，匿名页对应交换分区*/

        /*
         * The page is mapped into the page tables of one or more
         * processes. Try to unmap it here.
         */
        if (page_mapped(page) &amp;amp;&amp;amp; mapping) {
            /*开始解除页表中的映射关系并刷新TLB表*/
            switch (try_to_unmap(page, ttu_flags)) {
            case SWAP_FAIL:
                goto activate_locked;
            case SWAP_AGAIN:
                goto keep_locked;
            case SWAP_MLOCK:
                goto cull_mlocked;
            case SWAP_SUCCESS:
                ; /* try to free the page below */
            }
        }

        if (PageDirty(page)) {
            /*对于脏页，开始执行回刷动作*/
            nr_dirty++;

            ...

            /* Page is dirty, try to write it out here */
            switch (pageout(page, mapping, sc)) { /*调用底层文件系统接口进行回刷*/
            case PAGE_KEEP:
                nr_congested++;
                goto keep_locked;
            case PAGE_ACTIVATE:
                goto activate_locked;
            case PAGE_SUCCESS:
                /*回刷动作触发成功后，如果页面处在writeback状态，则不在本轮进行回收*/
                if (PageWriteback(page))
                    goto keep;
                if (PageDirty(page))
                    goto keep;

                /*
                 * A synchronous write - probably a ramdisk.  Go
                 * ahead and try to reclaim the page.
                 */
                /*对于ramdisk这类场景，回刷触发立刻就完成了，不会置writeback，可继续进行回收*/
                if (!trylock_page(page))
                    goto keep;
                if (PageDirty(page) || PageWriteback(page))
                    goto keep_locked;
                mapping = page_mapping(page);
            case PAGE_CLEAN:
                ; /* try to free the page below */
            }
        }

        ...

        /*从文件缓存或交换缓存中将当前页移除，彻底解除当前页的映射关系*/
        if (!mapping || !__remove_mapping(mapping, page))
            goto keep_locked;

        __clear_page_locked(page);
free_it:
        nr_reclaimed++;

        /*
         * Is there need to periodically free_page_list? It would
         * appear not as the counts should be low
         */
        list_add(&amp;amp;page-&amp;gt;lru, &amp;amp;free_pages); /*将当前页加入到待回收链表中*/
        continue;

cull_mlocked:
        if (PageSwapCache(page))
            try_to_free_swap(page);
        unlock_page(page);
        putback_lru_page(page);
        continue;

activate_locked:
        /* Not a candidate for swapping, so reclaim swap space. */
        if (PageSwapCache(page) &amp;amp;&amp;amp; vm_swap_full())
            try_to_free_swap(page);
        VM_BUG_ON(PageActive(page));
        SetPageActive(page);
        pgactivate++;
keep_locked:
        unlock_page(page);
keep:
        list_add(&amp;amp;page-&amp;gt;lru, &amp;amp;ret_pages);
        VM_BUG_ON(PageLRU(page) || PageUnevictable(page));
    } // end of while

    free_hot_cold_page_list(&amp;amp;free_pages, 1); /*正式回收free_pages链表中的所有页*/

    ...
    return nr_reclaimed;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;  至此，内存回收过程已基本分析完成，其中对于匿名页，回收过程会触发内存交换，有关内存交换的详细内容我们将在后续博文中给出。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/10/内存回收/&quot;&gt;内存管理之三：内存回收&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 01 Oct 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/10/%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/10/%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>内存管理之二：内存分配</title>
        <description>&lt;p&gt;  本节将讨论内存分配，计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是内存分配为什么需要它有何技术难点&quot;&gt;什么是内存分配？为什么需要它？有何技术难点？&lt;/h3&gt;

&lt;p&gt;  前文分析页异常处理时，我们看到内核会为应用程序分配内存页，而应用程序本身不直接申请内存页(只会通过malloc在堆中动态申请内存)。此外，内核在处理系统调用或中断时，也有可能需要动态申请页。Linux内核实现内存页申请的接口是alloc_pages(gfp_mask, order)：其中，gfp_mask代表申请内存的方式(隐含内存用途)，控制内存分配的行为；order代表需要的连续内存页个数的阶；接口返回的是连续内存首页对应的struct page指针(还记得地址映射中介绍的virtual memory map么？)。&lt;/p&gt;

&lt;p&gt;  通过动态分配内存页，可以提升系统对内存资源的利用率。然而，在内存不断的申请和释放过程中，可以想象的一个问题就是碎片化，即剩余内存分布在各段非连续空间内，使得较大连续内存的申请无法得到满足。因此内存分配算法的主要目标就是避免碎片化。&lt;/p&gt;

&lt;p&gt;  有的同学可能会问，为什么一定需要连续的物理内存呢？页表机制可以把非连续的物理页映射到连续的虚拟地址空间，这样应用程序看到的不就是连续内存了吗？的确，对于应用程序来说，对连续内存页的需求不是很强烈，但是对于某些外设(例如DMA设备)来说，它们只能看到物理页，而不存在页表转换过程，此时内核只能分配连续物理页来满足设备的内存访问需求。所以连续的物理内存在内核看来是一种稀缺资源，内存分配时需要尽可能保证剩余内存的连续性。下面我们就来看看Linux内核中内存的分配算法。&lt;/p&gt;

&lt;h3 id=&quot;如何实现--优化型伙伴算法&quot;&gt;如何实现？- 优化型伙伴算法&lt;/h3&gt;

&lt;p&gt;  说到内存分配算法，不得不提一提耳熟能详、在各类教科书中不断被说明的伙伴算法(buddy algorithm)。连续内存被划分成各阶大小(1,2,4,8,…)的内存段，阶数相同且低地址段起始地址按阶对齐的相邻段被称为伙伴，如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory2_1.jpg&quot; height=&quot;300&quot; width=&quot;600&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  图中所示为连续八页内存中被分配出去一页时的状态：剩余内存被分为三段，分别为一个页、两个页和四个页。&lt;/p&gt;

&lt;p&gt;  伙伴算法的原理为：初始时，所有连续内存按最大阶(Linux中为10，代表最大连续页为1024页)划分成段。内存分配时按阶数从小到大的顺序寻找最先能满足当前分配大小的连续段，如果找到的段的阶大于分配需要的阶，则将找到的段拆分成低阶段，例如上图表示将从一个3阶内存段中分配一个0阶内存段(即一页)的情况。内存释放时，如果发现被释放页的伙伴页段均空闲，则将两个伙伴合并从一个大的连续段并继续尝试合并新段和它的伙伴，直到无法合并为止。因此只要相邻伙伴均被释放，内存总是能被合并成更大的页段，这就是伙伴算法名称的由来。&lt;/p&gt;

&lt;p&gt;  伙伴算法真的完美吗？它在分配内存页时确实在努力保证剩余内存的连续，即在小段连续内存能满足当前分配的情况下绝对不会去动用大段连续内存，这就防止了因分配不当产生碎片。然而，它却无法避免因连续分配和释放而产生的碎片，因为只有当相邻两个伙伴均空闲时才能进行合并，这意味着一个伙伴的占用将阻止内存合并的发生。&lt;/p&gt;

&lt;p&gt;  因伙伴页被长期占用而导致的碎片问题的确比分配产生的碎片要难处理得多。这不由让人联想到磁盘的“碎片整理”功能，也就是通过移动正在使用的空间来保证剩余空间的连续。那么我们是否可以将类似思路应用到内存管理中呢？&lt;/p&gt;

&lt;p&gt;  通过观察我们可以发现使用中的内存页也具有一定的移动性：对于分配给应用程序使用的页是可以移动的(movable)，因为通过页表的重映射可以在应用不感知的前提下实现页替换；对于分配给内核自身使用的页是不可移动的(unmovable)，因为内核以直接映射的方式访问该页；对于未被映射给应用的缓存页是可回收的(reclaimable)，因为回刷缓存后缓存页可直接释放。如果我们将不可移动或回收的页限定在一定的范围内，就可以保证剩余范围内的页是可移动的，那么我们就可以在剩余范围内通过移动内存页来实现“碎片整理”。Linux内核就是基于上述思路，将伙伴算法中的各阶空闲内存细分成不可移动、可回收和可移动三大类，分配时通过gfp_mask标志来控制从哪类内存中分配空间。对于可移动内存页，内核在内存不足时会进行内存压缩(compact)来尝试形成更大的连续内存。上述算法即是优化型伙伴算法。&lt;/p&gt;

&lt;p&gt;  下面我们结合代码来深入理解优化型伙伴算法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/page_alloc.c:

/*
 * This is the 'heart' of the zoned buddy allocator.
 */
struct page *
__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order,
                        struct zonelist *zonelist, nodemask_t *nodemask)
{
/*在开始分析代码之前，先要理解NUMA这个概念：Non Uniform Memory Access，即非统一内存访问。
  我们前文举例的i440fx并不属于NUMA架构，NUMA架构通常会有多个计算节点，每个节点都有独立的内
  存，且每个节点在访问本地内存时的性能优于远端节点。linux内核通过ACPI中的SRAT表获知详细的
  NUMA信息。当然，我们可以将i440fx简单理解成只有一个节点的NUMA系统。*/
/*此外，内核会将整体物理内存空间划分成不同的区段(zone)：DMA段－16M地址空间以下；DMA32段－
  4G地址空间以下；Normal段－4G以上内存。因此每个NUMA节点可能包含多个zone。linux内核针对
  zone进行内存分配管理(伙伴算法)。*/

/*参数zonelist是根据gfp_mask计算得出的，以GFP_KERNEL为例，zonelist指向的通常就是当前进
  程所在NUMA节点包含的所有zone(内存分配策略为node first)。nodemask表示内存分配时需要过滤
  哪些节点，NULL表示不过滤任何节点。*/

    enum zone_type high_zoneidx = gfp_zone(gfp_mask); /*根据gfp_mask计算可分配的最
                                    大zone(Normal &amp;gt; DMA32 &amp;gt; DMA)，zone越小表示内存
                                    资源越稀缺。以GFP_KERNEL为例，这里计算可得normal*/
    struct zone *preferred_zone;
    struct page *page = NULL;
    int migratetype = allocflags_to_migratetype(gfp_mask); /*根据GFP中的__GFP_MOVABLE
                                    和__GFP_RECLAIMABLE标志计算待分配页的迁移类型，以
                                    GFP_KERNEL为例，这里计算得出MIGRAGE_UNMOVABLE*/
    
    ...

    /*先进行快速内存分配策略，大部分分配动作将在该函数中成功返回。如果空闲内存不足，快速分配会
      偿试内存回收*/
    page = get_page_from_freelist(gfp_mask|__GFP_HARDWALL, nodemask, order,
            zonelist, high_zoneidx, alloc_flags, preferred_zone, migratetype);
    if (unlikely(!page)) {
        ...
        /*如果快速分配失败，再进行慢速分配*/
        page = __alloc_pages_slowpath(gfp_mask, order,
                zonelist, high_zoneidx, nodemask, preferred_zone, migratetype);
    }

    ...

    return page;
}


/*下面我们补充一些内存分配标记相关的内容：*/
linux/include/linux/gfp.h:

/*
 * Action modifiers - doesn't change the zoning
 *
 * __GFP_REPEAT: Try hard to allocate the memory, but the allocation attempt
 * _might_ fail.  This depends upon the particular VM implementation.
 *
 * __GFP_NOFAIL: The VM implementation _must_ retry infinitely: the caller
 * cannot handle allocation failures.  This modifier is deprecated and no new
 * users should be added.
 *
 * __GFP_NORETRY: The VM implementation must not retry indefinitely.
 *
 * __GFP_MOVABLE: Flag that this page will be movable by the page migration
 * mechanism or reclaimed
 */
#define __GFP_WAIT	((__force gfp_t)___GFP_WAIT)	/* Can wait and reschedule? */
#define __GFP_HIGH	((__force gfp_t)___GFP_HIGH)	/* Should access emergency pools? */
#define __GFP_IO	((__force gfp_t)___GFP_IO)	/* Can start physical IO? */
#define __GFP_FS	((__force gfp_t)___GFP_FS)	/* Can call down to low-level FS? */
#define __GFP_COLD	((__force gfp_t)___GFP_COLD)	/* Cache-cold page required */
#define __GFP_NOWARN	((__force gfp_t)___GFP_NOWARN)	/* Suppress page allocation failure warning */
#define __GFP_REPEAT	((__force gfp_t)___GFP_REPEAT)	/* See above */
#define __GFP_NOFAIL	((__force gfp_t)___GFP_NOFAIL)	/* See above */
#define __GFP_NORETRY	((__force gfp_t)___GFP_NORETRY) /* See above */
#define __GFP_MEMALLOC	((__force gfp_t)___GFP_MEMALLOC)/* Allow access to emergency reserves */
#define __GFP_COMP	((__force gfp_t)___GFP_COMP)	/* Add compound page metadata */
#define __GFP_ZERO	((__force gfp_t)___GFP_ZERO)	/* Return zeroed page on success */
#define __GFP_NOMEMALLOC ((__force gfp_t)___GFP_NOMEMALLOC) /* Don't use emergency reserves.
                                                             * This takes precedence over the
                                                             * __GFP_MEMALLOC flag if both are
                                                             * set
                                                             */
#define __GFP_HARDWALL   ((__force gfp_t)___GFP_HARDWALL) /* Enforce hardwall cpuset memory allocs */
#define __GFP_THISNODE	((__force gfp_t)___GFP_THISNODE)/* No fallback, no policies */
#define __GFP_RECLAIMABLE ((__force gfp_t)___GFP_RECLAIMABLE) /* Page is reclaimable */
#define __GFP_NOTRACK	((__force gfp_t)___GFP_NOTRACK)  /* Don't track with kmemcheck */

#define __GFP_NO_KSWAPD	((__force gfp_t)___GFP_NO_KSWAPD)
#define __GFP_OTHER_NODE ((__force gfp_t)___GFP_OTHER_NODE) /* On behalf of other node */
#define __GFP_KMEMCG	((__force gfp_t)___GFP_KMEMCG) /* Allocation comes from a memcg-accounted resource */
#define __GFP_WRITE	((__force gfp_t)___GFP_WRITE)	/* Allocator intends to dirty page */

/*
* This may seem redundant, but it's a way of annotating false positives vs.
* allocations that simply cannot be supported (e.g. page tables).
*/
#define __GFP_NOTRACK_FALSE_POSITIVE (__GFP_NOTRACK)

#define __GFP_BITS_SHIFT 25	/* Room for N __GFP_FOO bits */
#define __GFP_BITS_MASK ((__force gfp_t)((1 &amp;lt;&amp;lt; __GFP_BITS_SHIFT) - 1))

/* This equals 0, but use constants in case they ever change */
#define GFP_NOWAIT	(GFP_ATOMIC &amp;amp; ~__GFP_HIGH)
/* GFP_ATOMIC means both !wait (__GFP_WAIT not set) and use emergency pool */
#define GFP_ATOMIC	(__GFP_HIGH)
#define GFP_NOIO	(__GFP_WAIT)
#define GFP_NOFS	(__GFP_WAIT | __GFP_IO)
#define GFP_KERNEL	(__GFP_WAIT | __GFP_IO | __GFP_FS)
#define GFP_TEMPORARY	(__GFP_WAIT | __GFP_IO | __GFP_FS | \
                        __GFP_RECLAIMABLE)
#define GFP_USER	(__GFP_WAIT | __GFP_IO | __GFP_FS | __GFP_HARDWALL)
#define GFP_HIGHUSER	(__GFP_WAIT | __GFP_IO | __GFP_FS | __GFP_HARDWALL | \
                        __GFP_HIGHMEM)
#define GFP_HIGHUSER_MOVABLE	(__GFP_WAIT | __GFP_IO | __GFP_FS | \
                        __GFP_HARDWALL | __GFP_HIGHMEM | \
                        __GFP_MOVABLE)
#define GFP_IOFS	(__GFP_IO | __GFP_FS)
#define GFP_TRANSHUGE	(GFP_HIGHUSER_MOVABLE | __GFP_COMP | \
                    __GFP_NOMEMALLOC | __GFP_NORETRY | __GFP_NOWARN | \
                    __GFP_NO_KSWAPD)

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  内存分配有一个快速分配流程和一个慢速分配流程，采用先快后慢的思路。快速分配根据zone内空闲内存量决定是否使用快速内存回收，如果空闲量足够的话，则直接采用优化型伙伴算法进行分配，否则先进行快速回收再尝试分配。快速分配一旦失败就会使用慢速分配的方式唤醒内存交换进程(kswapd)或触发内存压缩继续尝试分配。下面我们再深入看一下快速分配流程get_page_from_freelist：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/page_alloc.c:

/*
 * get_page_from_freelist goes through the zonelist trying to allocate
 * a page.
 */
static struct page *
get_page_from_freelist(gfp_t gfp_mask, nodemask_t *nodemask, unsigned int order,
                struct zonelist *zonelist, int high_zoneidx, int alloc_flags,
                struct zone *preferred_zone, int migratetype)
{
    struct zoneref *z;
    struct page *page = NULL;
    int classzone_idx;
    struct zone *zone;

    classzone_idx = zone_idx(preferred_zone);
zonelist_scan:
    /*
     * Scan zonelist, looking for a zone with enough free.
     * See also cpuset_zone_allowed() comment in kernel/cpuset.c.
     */
    /*下面的循环体开始遍历zonelist中的每个zone，最大为high_zoneidx，并过滤nodemask*/
    for_each_zone_zonelist_nodemask(zone, z, zonelist, high_zoneidx, nodemask) {
        ...
        if (!(alloc_flags &amp;amp; ALLOC_NO_WATERMARKS)) {
            unsigned long mark;
            int ret;

            /*内存管理初始化时，分为每个zone设定high、low、min三档水位线：空闲内存量大于high表示
              余量充足；空闲量小于high大于low表示有一定的内存压力，余量尚可；空闲量小于low大于min
              表示内存压力较大，余量不足；空闲量小于min，表示内存压力非常大，需要动用紧急内存*/

            /*快速分配时alloc_flags考量的是low水位线，只要当前zone的空闲内存量不低于low水位线，
              都会偿试通过伙伴算法进行分配，否则就进行内存回收*/
            mark = zone-&amp;gt;watermark[alloc_flags &amp;amp; ALLOC_WMARK_MASK];
            if (zone_watermark_ok(zone, order, mark, classzone_idx, alloc_flags))
                goto try_this_zone;
            ...

            ret = zone_reclaim(zone, gfp_mask, order); /*进行内存回收*/
            switch (ret) {
            case ZONE_RECLAIM_NOSCAN:
                /* did not scan */
                continue;
            case ZONE_RECLAIM_FULL:
                /* scanned but unreclaimable */
                continue;
            default:
                /* did we reclaim enough */
                /*回收部分内存后，如果水位线满足要求则偿试进行分配*/
                if (zone_watermark_ok(zone, order, mark, classzone_idx, alloc_flags))
                    goto try_this_zone;

            ...

            continue;
            }
        }

try_this_zone:

    /*正式进行内存分配*/
    page = buffered_rmqueue(preferred_zone, zone, order, gfp_mask, migratetype);
    if (page)
        break;
this_zone_full:
    ...
    }

    ...

    return page;
}


static inline
struct page *buffered_rmqueue(struct zone *preferred_zone,
                struct zone *zone, int order, gfp_t gfp_flags, int migratetype)
{
    unsigned long flags;
    struct page *page;

again:
    if (likely(order == 0)) {
        /*对于单页内存的分配，内核为cpu预留了一部分缓存空间；分配和释放进首先从缓存中进行。
          这样可以提升单页内存分配的效率，具体代码大家可以自行展开分析*/
        ...
    } else {
        spin_lock_irqsave(&amp;amp;zone-&amp;gt;lock, flags);
        /*偿试从当前zone中根据migratetype类型进行内存页分配，内部会调用__rmqueue_smallest*/
        page = __rmqueue(zone, order, migratetype);
        spin_unlock(&amp;amp;zone-&amp;gt;lock);
        ...
    }
    ...
    return page;
    ...
}

/*__rmqueue_smallest就是伙伴算法最核心的代码实现，逻辑比较清楚，大家可以仔细阅读*/
static inline
struct page *__rmqueue_smallest(struct zone *zone, unsigned int order, int migratetype)
{
    unsigned int current_order;
    struct free_area * area;
    struct page *page;

    /*数据结构上，每个zone都有一个free_area数组，下标代表伙伴阶数，最大为10(MAX_ORDER为11)。
      在优化型伙伴算法中，freea_area每个元素再次按迁移性分为不可移动、可移动、可回收三个部分*/
    /* Find a page of the appropriate size in the preferred list */
    for (current_order = order; current_order &amp;lt; MAX_ORDER; ++current_order) { /*阶数从小到大*/
        area = &amp;amp;(zone-&amp;gt;free_area[current_order]);
        if (list_empty(&amp;amp;area-&amp;gt;free_list[migratetype])) /*判断是否符合分配要求*/
            continue;

        page = list_entry(area-&amp;gt;free_list[migratetype].next, struct page, lru); 
        list_del(&amp;amp;page-&amp;gt;lru); /*将符合要求的连续页从伙伴系统中移除*/
        rmv_page_order(page);
        area-&amp;gt;nr_free--;
        expand(zone, page, order, current_order, area, migratetype); /*将打散的空闲页添加到低阶链表中*/
        return page;
    }

    return NULL; /*如果找不到符合要求的空闲页，则返回空*/
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  至此，内存分配中核心的伙伴算法分析完毕，后续博文我们将沿着内存回收线索深入往下分析。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/09/内存分配/&quot;&gt;内存管理之二：内存分配&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 02 Sep 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/09/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/09/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>内存管理之一：地址映射</title>
        <description>&lt;p&gt;  地址映射是CPU核心和MMU共同完成的内存管理功能之一，本节将对此展开深入讨论。计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是地址映射为什么需要它&quot;&gt;什么是地址映射？为什么需要它？&lt;/h3&gt;

&lt;p&gt;  正如在&lt;a href=&quot;https://rootw.github.io/2017/02/计算机/&quot;&gt;计算机系统&lt;/a&gt;整体介绍中所说明的一样，MMU在CPU的配合下(通过页异常触发)，实现了线性地址到物理地址的动态映射，为正在CPU上运行的应用程序(进程)提供了一个独立的连续内存空间(线性地址空间，或称虚拟内存空间，其中放置了代码段、数据段和堆栈段)，屏蔽了地址分配、内存分配和内存回收等一系列复杂的系统行为，不仅提升了内存资源的利用效率，而且大大降低了应用开发难度，使程序猿可以更聚焦业务逻辑。结合CPU的进程管理功能，可以实现一个多任务并行系统，提升系统的可用性和性能。&lt;/p&gt;

&lt;h3 id=&quot;如何实现&quot;&gt;如何实现？&lt;/h3&gt;

&lt;h4 id=&quot;1线性地址&quot;&gt;&lt;strong&gt;1.线性地址&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  x86_64架构下Linux中每个应用程序(进程)可见的线性地址空间如下(注：分段机制在64位模式下已不产生实际作用)：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory1_1.jpg&quot; height=&quot;200&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  该架构支持48位线性地址(高16位仅做符号扩展，不参与地址转换)到40位物理地址(最多52位，由CPU实现决定)的映射。48位线性空间共256T，分为两个128T区间，分别分布在完整的64位空间的两端。其中，低128T为用户空间，映射用户程序代码、数据、堆栈和共享库，物理内存随着程序的运行由内核动态分配。而高128T则为内核空间：direct mapping区映射整个物理内存空间，便于内核访问所有物理内存；vmalloc space区间为内核调用vmalloc时使用的线性空间，物理内存动态分配且物理上不保证连续；virtual memory map是内核标识内存页信息的数组，供内存管理功能使用；kernel text &amp;amp; module区存放内核和模块的代码及数据。此外，也可以参考内核代码的说明：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/Documentation/x86/x86_64/mm.txt:

0000000000000000 - 00007fffffffffff (=47 bits) user space, different per mm
hole caused by [48:63] sign extension
ffff800000000000 - ffff80ffffffffff (=40 bits) guard hole
ffff880000000000 - ffffc7ffffffffff (=64 TB) direct mapping of all phys. memory
ffffc80000000000 - ffffc8ffffffffff (=40 bits) hole
ffffc90000000000 - ffffe8ffffffffff (=45 bits) vmalloc/ioremap space
ffffe90000000000 - ffffe9ffffffffff (=40 bits) hole
ffffea0000000000 - ffffeaffffffffff (=40 bits) virtual memory map (1TB)
... unused hole ...
ffffff0000000000 - ffffff7fffffffff (=39 bits) %esp fixup stacks
... unused hole ...
ffffffff80000000 - ffffffffa0000000 (=512 MB)  kernel text mapping, from phys 0
ffffffffa0000000 - ffffffffff5fffff (=1525 MB) module mapping space
ffffffffff600000 - ffffffffffdfffff (=8 MB) vsyscalls
ffffffffffe00000 - ffffffffffffffff (=2 MB) unused hole

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;2地址转换&quot;&gt;&lt;strong&gt;2.地址转换&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  MMU的线性地址转换是通过页表进行的，具体过程如下图所示(摘自intel程序员手册卷3)：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory1_3.jpg&quot; height=&quot;500&quot; width=&quot;750&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  其实最简单明了的方法是通过一个一维数组来记录映射关系:下标代表线性地址，数组元素内容代表物理地址。可是如此一来，用来表示映射关系的内存空间比被表示的物理空间还要大，显然这不是一个可行的方案。&lt;/p&gt;

&lt;p&gt;  工程师们采用了分段分级的思路来表示这种映射关系：先把线性空间以4K大小为单位进行划分(页)，然后再以大段连续空间进行转换，在每个大段空间内部再次划分成小段进行转换，直到段大小变为4K页大小。用以表示和段空间映射关系的结构称为页表，其大小也是一个页面。由于采用了分段的方法，页表空间大大减小；同时未映射的空间不必分配页表，这也进一步降低了页表占用空间。&lt;/p&gt;

&lt;p&gt;  x86_64架构下Linux用了四级页表来表示一个映射关系，依次为PGD、PUD、PMD、PT。每级页表4K大小，内部元素大小为8字节，高位指向了下一级页表的物理地址，低位表示页表属性(是否存在、读写权限、是否脏等等)。顶层页表PGD的物理地址存放在CPU的CR3寄存器中，供MMU访问。48位线性地址也相应地分成了五段：前四段，每段长9位，用来索引对应页表的元素；最后一段长12位，用来在页面中索引物理地址。各级页表的详细内容参考下表：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory1_4.jpg&quot; height=&quot;650&quot; width=&quot;800&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;3页异常处理&quot;&gt;&lt;strong&gt;3.页异常处理&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  一个进程初始运行时，对应的页表项大多都是空的。一旦MMU在地址转换过程中出现缺页或者读写权限问题时，MMU会触发页异常，打断CPU当前正在执行的程序，转而进行页异常处理(缺页会分配新页)。当页异常处理完毕后，CPU会重新执行引发缺页的指令，此时MMU便可正常完成地址转换。&lt;/p&gt;

&lt;p&gt;  下面，我们进一步深入分析整个页异常处理过程，关键流程如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory1_2.jpg&quot; height=&quot;600&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  CPU收到页异常后，首先进行的是上下文切换的硬件过程，该过程主要完成栈的切换(进入内核栈)、关键寄存器的保存和执行函数的切换(转入页异常处理函数page_fault)。有关中断和异常处理的详细分析请参考&lt;a href=&quot;https://rootw.github.io/2017/03/中断/&quot;&gt;中断分析&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;  CPU被页异常中断后最先执行的是一段汇编代码(page_fault位于linux/arch/x86/kernel/entry_64.S，感兴趣的同学可以自行分析)，它完成了其他上下文寄存器的保存，并进入核心处理逻辑do_page_fault。&lt;/p&gt;

&lt;p&gt;  在理解MMU的工作原理之后，我想大家对缺页异常的核心处理逻辑应该很快能想明白，无非就是分配页、填充页内容、修改页表。然而，回顾一下前面线性地址章节描绘的地址空间分配图，我们会发现其中有代码、有数据、有堆和栈，不同类型的区段的对于页异常的处理逻辑是有区别的，例如代码段的页内容来自可执行文件，是只读类型的；数据段初始内容也来自可执行文件，但后续的修改不影响可执行执行文件；堆和栈的内容不来自任何文件，只在当前进程内部可见。因此，针对不同类型的内存区段需要有不同的处理方式。Linux内核以虚拟内存段(vma, virtual memory area)来表达不同程序区段，不同段可以具有不同的读写权限和属性；不在任何内存段的地址则认为是非法地址。有关内存段的数据结构如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/include/mm_types.h:

/*
 * This struct defines a memory VMM memory area. There is one of these
 * per VM-area/task.  A VM area is any part of the process virtual memory
 * space that has a special rule for the page-fault handlers (ie a shared
 * library, the executable area etc).
 */
struct vm_area_struct {
    /* The first cache line has the info for VMA tree walking. */

    unsigned long vm_start;		/* Our start address within vm_mm. */
    unsigned long vm_end;		/* The first byte after our end address within vm_mm. */

    /* linked list of VM areas per task, sorted by address */
    struct vm_area_struct *vm_next, *vm_prev;

    struct rb_node vm_rb;

    ...

    /* Second cache line starts here. */

    struct mm_struct *vm_mm;	/* The address space we belong to. */
    pgprot_t vm_page_prot;		/* Access permissions of this VMA. */
    unsigned long vm_flags;		/* Flags, see mm.h. */

    ...

    /* Function pointers to deal with this struct. */
    const struct vm_operations_struct *vm_ops;

    /* Information about our backing store: */
    unsigned long vm_pgoff;		/* Offset (within vm_file) in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */
    struct file * vm_file;		/* File we map to (can be NULL). */
    void * vm_private_data;		/* was vm_pte (shared mem) */

    ...
};

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  所有vma会以链表形式统一到mm_struct中，该结构每个进程拥有一个，被进程控制块使用，描述了每个进程的有效内存区段和地址映射关系：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/include/mm_types.h:

struct mm_struct {
    struct vm_area_struct * mmap;		/* list of VMAs */
    struct rb_root mm_rb;
    struct vm_area_struct * mmap_cache;	/* last find_vma result */
#ifdef CONFIG_MMU
    unsigned long (*get_unmapped_area) (struct file *filp,
    unsigned long addr, unsigned long len,
    unsigned long pgoff, unsigned long flags);
    void (*unmap_area) (struct mm_struct *mm, unsigned long addr);
#endif
    unsigned long mmap_base;            /* base of mmap area */
    unsigned long mmap_legacy_base;     /* base of mmap area in bottom-up allocations */
    unsigned long task_size;            /* size of task vm space */
    unsigned long cached_hole_size; 	/* if non-zero, the largest hole below free_area_cache */
    unsigned long free_area_cache;		/* first hole of size cached_hole_size or larger */
    unsigned long highest_vm_end;		/* highest vma end address */
    pgd_t * pgd;                        /* 指向PGD表，owner进程运行时该值被加载到CR3寄存器中*/
    atomic_t mm_users;			/* How many users with user space? */
    atomic_t mm_count;			/* How many references to &quot;struct mm_struct&quot; (users count as 1) */
    int map_count;				/* number of VMAs */

    spinlock_t page_table_lock;		/* Protects page tables and some counters */
    struct rw_semaphore mmap_sem;

    struct list_head mmlist;        /* List of maybe swapped mm's.	These are globally strung
                                     * together off init_mm.mmlist, and are protected
                                     * by mmlist_lock
                                     */

    ...

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  我们回到do_page_fault函数，它通过读取CPU的CR2寄存器可以获知发生页异常的线性地址，并在当前进程对应的mm_struct中查找该线性地址对应的vma虚拟地址内存段，最后根据vma的属性来进一步处理页异常。当然，如果找不到线性地址对应的vma，内核就会认为发生了一次非法内存访问(让程序猿闻风丧胆的segfault由此产生)。代码片断分析如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/arch/x86/mm/fault.c:

/*
 * This routine handles page faults.  It determines the address,
 * and the problem, and then passes it off to one of the appropriate
 * routines.
 */
static void __kprobes
__do_page_fault(struct pt_regs *regs, unsigned long error_code)
{
    struct vm_area_struct *vma;
    struct task_struct *tsk;
    unsigned long address;
    struct mm_struct *mm;
    int fault;
    unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;

    tsk = current;  /*获取当前进程*/
    mm = tsk-&amp;gt;mm;   /*当前进程对应的mm_struct*/

    /* Get the faulting address: */
    address = read_cr2();   /*x86架构下，页异常发生时，CR2寄存器中会记录发生异常的线性地址*/

    if (unlikely(fault_in_kernel_space(address))) {
        /*通过异常地址范围，判断异常地址是否在内核态。
          如果发生在内核态，通常是由于vmalloc导致的，这里会处理页表映射关系*/
        ...
        return;
    }

    ...

    /*如果执行到这里，说明页异常地址处在用户态范围*/
    /*如果代码段也在用户态，则打开中断，并记录标志；
      如果代码段在内核态，则根据页异常发生前的IF标记值来决定是否打开中断*/
    if (user_mode_vm(regs)) {
        local_irq_enable();
        error_code |= PF_USER;
        flags |= FAULT_FLAG_USER;
    } else {
        if (regs-&amp;gt;flags &amp;amp; X86_EFLAGS_IF)
            local_irq_enable();
    }

    ...

    /*
     * If we're in an interrupt, have no user context or are running
     * in an atomic region then we must not take the fault:
     */
    /*这里注意一点：页异常处理属于进程上下文，不是中断上下文，可睡眠*/
    if (unlikely(in_atomic() || !mm)) {
        bad_area_nosemaphore(regs, error_code, address);
        return;
    }

    if (error_code &amp;amp; PF_WRITE)
        flags |= FAULT_FLAG_WRITE;

    /*
     * When running in the kernel we expect faults to occur only to
     * addresses in user space.  All other faults represent errors in
     * the kernel and should generate an OOPS.  Unfortunately, in the
     * case of an erroneous fault occurring in a code path which already
     * holds mmap_sem we will deadlock attempting to validate the fault
     * against the address space.  Luckily the kernel only validly
     * references user space from well defined areas of code, which are
     * listed in the exceptions table.
     * ...
     */
    /*获取当前mm_struct的读信号量，避免后续处理过程中有其它流程修改mm_struct结构*/
    if (unlikely(!down_read_trylock(&amp;amp;mm-&amp;gt;mmap_sem))) {
        if ((error_code &amp;amp; PF_USER) == 0 &amp;amp;&amp;amp;
                !search_exception_tables(regs-&amp;gt;ip)) {
            bad_area_nosemaphore(regs, error_code, address);
            return;
        }
retry:
        down_read(&amp;amp;mm-&amp;gt;mmap_sem);
    } else {
    /*
     * The above down_read_trylock() might have succeeded in
     * which case we'll have missed the might_sleep() from
     * down_read():
     */
        might_sleep();
    }

    /*查找页异常地址对应的vma区段*/
    vma = find_vma(mm, address);
    if (unlikely(!vma)) {
        bad_area(regs, error_code, address);
        return;
    }
    /*如果页异常地址在合理的vma段地址范围内，则进行后续的异常处理*/
    if (likely(vma-&amp;gt;vm_start &amp;lt;= address))
        goto good_area;
    if (unlikely(!(vma-&amp;gt;vm_flags &amp;amp; VM_GROWSDOWN))) {
        /*如果页异常地址小于vma起始地址，但vma又不是往低地址方向增长(栈是往低地址方向增长的)，则出现错误*/
        bad_area(regs, error_code, address);
        return;
    }

    ...

    /*往低地址方向增长栈*/
    if (unlikely(expand_stack(vma, address))) {
        bad_area(regs, error_code, address);
        return;
    }

    /*
     * Ok, we have a good vm_area for this memory access, so
     * we can handle it..
     */
    /*如果执行到这里，后续便开始针对vma的属性进行不同的页异常处理*/
good_area:
    if (unlikely(access_error(error_code, vma))) {
        bad_area_access_error(regs, error_code, address);
        return;
    }

    /*
     * If for any reason at all we couldn't handle the fault,
     * make sure we exit gracefully rather than endlessly redo
     * the fault:
     */
    fault = handle_mm_fault(mm, vma, address, flags);

    ...

}


/*下面补充一些关于页异常错误码的内容，通常在发生段错误时我们在系统日志中可以看到错误码，
  通过错误码我们大致可以得知异常发生的原因*/
/*
 * Page fault error code bits:
 *
 *   bit 0 ==	 0: no page found	1: protection fault
 *   bit 1 ==	 0: read access		1: write access
 *   bit 2 ==	 0: kernel-mode access	1: user-mode access
 *   bit 3 ==				1: use of reserved bit detected
 *   bit 4 ==				1: fault was an instruction fetch
 */
enum x86_pf_error_code {
    PF_PROT     =       1 &amp;lt;&amp;lt; 0,
    PF_WRITE    =       1 &amp;lt;&amp;lt; 1,
    PF_USER     =       1 &amp;lt;&amp;lt; 2,
    PF_RSVD     =       1 &amp;lt;&amp;lt; 3,
    PF_INSTR    =       1 &amp;lt;&amp;lt; 4,
};
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  handle_mm_fault函数基于当前进程的mm_struct、异常地址所在vma和异常处理控制标志flags进行进一步异常处理。我们知道，页表共有四级，这里依次对各级页表进行处理：PGD是在进程创建的时候就分配好的，不需要动态分配，其值保存在mm_struct的pgd域中；从PUD到PT，如果页表不存在会动态分配页并使页表指向新分配的页。页表处理完成后，进入handle_pte_fault处理最后的物理页。handle_mm_fault代码注解如下(这里暂不考虑大页等复杂特性)：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/memory.c:

/*
 * By the time we get here, we already hold the mm semaphore
 */
static int __handle_mm_fault(struct mm_struct *mm, struct vm_area_struct *vma,
unsigned long address, unsigned int flags)
{
    pgd_t *pgd;
    pud_t *pud;
    pmd_t *pmd;
    pte_t *pte;

    ...

retry:
    pgd = pgd_offset(mm, address); /*直接获取当前进程中页异常线性地址在PGD表中对应的项，无须分配*/
    pud = pud_alloc(mm, pgd, address); /*获取PUD表中对应的项，如果PUD表不存在则动态分配*/
    if (!pud)
        return VM_FAULT_OOM;
    pmd = pmd_alloc(mm, pud, address); /*获取PMD表中对应的项，如果PMD不存在则动态分配*/
    if (!pmd)
        return VM_FAULT_OOM;

    ...
    if (unlikely(pmd_none(*pmd)) &amp;amp;&amp;amp;
        unlikely(__pte_alloc(mm, vma, pmd, address))) /*动态分配PTE*/
    return VM_FAULT_OOM;
    ...

    pte = pte_offset_map(pmd, address);

    /*各级页表分配完毕后，真正开始处理页异常*/
    return handle_pte_fault(mm, vma, address, pte, pmd, flags);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  题外话，页表操作的同步。通常情况下，一个确定的映射关系mm_struct只被一个进程引用，同一进程在确定时刻只会运行在一个核上，因此该进程的页异常处理也只在一个核上发生，此时不存在对进程页表做并发操作的可能。然而，如果一个进程有多个线程，那么这些线程将引用相同的mm_struct(代码段、数据段、堆空间完全相同，栈空间各不相同)，此时对mm_struct所涉及的各级页表操作时就需要考虑同步问题。&lt;/p&gt;

&lt;p&gt;  一种简单的方法是在开始页表操作前，对mm_struct先上一把大锁，待各级页表均操作完毕后再解锁。但存在的问题是页表操作过程中会涉及页分配，这是一个极其复杂的过程，可能还会睡眠，这样一来有可能出现成功加到锁的线程进入睡眠态后导致其他线程缺页却加不到锁的情况。即便不同线程访问的是不同内存段，但是却有可能出现因为一个线程的页异常处理不及时导致所有线程无法正常处理页异常的情况。&lt;/p&gt;

&lt;p&gt;  linux内核针对此种问题采用了最小化加锁范围的方法。每次操作页表前，如果页表项不存在则先分配页，然后加mm_struct锁。加锁成功后，如果发现页表项已经被赋值，说明有其他CPU先于当前CPU完成了页表分配，则释放先前分配页并解锁；如果未被赋值，则将分配页赋值给页表项，最后解锁。这种方法虽然会导致一些多余的页分配和释放动作，但加锁区间和持锁时间大大缩短，系统整体并发性大大提升。此外，对于最后一级PT页表的操作比前几级页表复杂性要高得多，因此内核对PT页表使用了一把独立的锁，进一步提升系统并行效率。代码注解如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int __pud_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address)
{
    pud_t *new = pud_alloc_one(mm, address); /*先偿试分配一页，该过程执行时间可能会比较长*/
    if (!new)
    return -ENOMEM;

    smp_wmb(); /* See comment in __pte_alloc */

    /*加锁判断原有页表项是否改变，如果发生改变说明有其它流程已成功分配页表，这里就释放之间分配的页*/
    spin_lock(&amp;amp;mm-&amp;gt;page_table_lock); 
    if (pgd_present(*pgd))		/* Another has populated it */
        pud_free(mm, new);
    else
        pgd_populate(mm, pgd, new);
    spin_unlock(&amp;amp;mm-&amp;gt;page_table_lock);
    return 0;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  我们再回到页异常处理主逻辑，接下来handle_pte_fault函数根据PT页表中异常地址对应的页表项进行不同处理：如果页表项PRESENT位未被置位，代表物理页不存在，需要进行缺页处理；否则，代表访问权限不够，需要调用do_wp_page进行写保护处理。在缺页的情况下，如果页表项不为零，说明前期把物理页交换到磁盘上了，而页表项纪录了交换页所在的磁盘位置信息，那么此时需要通过do_swap_page将交换页取回内存(内存交换将单独起一篇博文分析)；页表项为零则根据vma是否有文件对应进行不同处理，文件映射由do_linear_fault处理，匿名映射由do_anonymous_page处理。handle_pte_fault代码注解如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/memory.c:

int handle_pte_fault(struct mm_struct *mm,
            struct vm_area_struct *vma, unsigned long address,
            pte_t *pte, pmd_t *pmd, unsigned int flags)
{
    pte_t entry;
    spinlock_t *ptl;

    entry = *pte;
    if (!pte_present(entry)) { /*判断页是否不存在*/
        if (pte_none(entry)) { /*如果不仅不存在，而且页表项内容为零*/
            if (vma-&amp;gt;vm_ops) /*文件映射*/
                return do_linear_fault(mm, vma, address, pte, pmd, flags, entry);
            return do_anonymous_page(mm, vma, address, pte, pmd, flags); /*匿名映射*/
        }
        ...
        /*页不存在，但是非零，表示指向一个交换页，则执行换入操作*/
        return do_swap_page(mm, vma, address, pte, pmd, flags, entry);
    }

    ...

    /*处理防问权限异常，如写保护异常*/
    ptl = pte_lockptr(mm, pmd);
    spin_lock(ptl);
    if (unlikely(!pte_same(*pte, entry)))
        goto unlock;
    if (flags &amp;amp; FAULT_FLAG_WRITE) {
        if (!pte_write(entry))
            return do_wp_page(mm, vma, address, pte, pmd, ptl, entry);
        entry = pte_mkdirty(entry);
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  do_linear_fault函数处理线性文件映射内存段的缺页问题。对于读缺页，通过查找文件缓存页后直接采用缓存页作为映射页；对于写缺页，先查找文件缓存页，如果为共享内存段则直接采用缓存页映射，如果为私有内存段则分配新页、拷贝缓存页内容后再映射新页。代码注解如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/memory.c:

static int do_linear_fault(struct mm_struct *mm, struct vm_area_struct *vma,
                        unsigned long address, pte_t *page_table, pmd_t *pmd,
                        unsigned int flags, pte_t orig_pte)
{
    pgoff_t pgoff = (((address &amp;amp; PAGE_MASK)
                    - vma-&amp;gt;vm_start) &amp;gt;&amp;gt; PAGE_SHIFT) + vma-&amp;gt;vm_pgoff; /*计算异常地址对应内容在文件中的偏移*/

    return __do_fault(mm, vma, address, pmd, pgoff, flags, orig_pte);
}


static int __do_fault(struct mm_struct *mm, struct vm_area_struct *vma,
                    unsigned long address, pmd_t *pmd,
                    pgoff_t pgoff, unsigned int flags, pte_t orig_pte)
{
    pte_t *page_table;
    spinlock_t *ptl;
    struct page *page;
    struct page *cow_page;
    pte_t entry;
    int anon = 0;
    struct page *dirty_page = NULL;
    struct vm_fault vmf;
    int ret;


    /*对于写操作，如果页异常地址所在vma段的属性是私有的，即没有设置VM_SHARED标记，
      则需要分配一个匿名页并复制文件中的内容*/
    if ((flags &amp;amp; FAULT_FLAG_WRITE) &amp;amp;&amp;amp; !(vma-&amp;gt;vm_flags &amp;amp; VM_SHARED)) {

        if (unlikely(anon_vma_prepare(vma)))
            return VM_FAULT_OOM;

        cow_page = alloc_page_vma(GFP_HIGHUSER_MOVABLE, vma, address);
        if (!cow_page)
            return VM_FAULT_OOM;

        ...
    } else
        cow_page = NULL;

    vmf.virtual_address = (void __user *)(address &amp;amp; PAGE_MASK);
    vmf.pgoff = pgoff;
    vmf.flags = flags;
    vmf.page = NULL;

    /*通过文件系统中的fault操作，在vmf.page中返回页异常地址对应文件内容的缓存页*/
    ret = vma-&amp;gt;vm_ops-&amp;gt;fault(vma, &amp;amp;vmf);
    ...

    page = vmf.page;
    if (flags &amp;amp; FAULT_FLAG_WRITE) {
        if (!(vma-&amp;gt;vm_flags &amp;amp; VM_SHARED)) {
            page = cow_page;
            anon = 1;
            copy_user_highpage(page, vmf.page, address, vma); /*复制缓存页中的内容到匿名页*/
            __SetPageUptodate(page);
        } else {
            ...
        }
    }

    page_table = pte_offset_map_lock(mm, pmd, address, &amp;amp;ptl);

    if (likely(pte_same(*page_table, orig_pte))) { /*通常都会进入该分支，是一种高效的页表访问方式*/
        entry = mk_pte(page, vma-&amp;gt;vm_page_prot); /*将页地址和基本属性填入页表项*/
        if (flags &amp;amp; FAULT_FLAG_WRITE)
            entry = maybe_mkwrite(pte_mkdirty(entry), vma); /*设置页表项写权限*/
        if (anon) { /*如果是匿名页，则添加反向匿名映射*/
            inc_mm_counter_fast(mm, MM_ANONPAGES);
            page_add_new_anon_rmap(page, vma, address);
        } else { /*如果是文件映射，则添加反向文件映射*/
            inc_mm_counter_fast(mm, MM_FILEPAGES);
            page_add_file_rmap(page);
            if (flags &amp;amp; FAULT_FLAG_WRITE) {
                dirty_page = page;
                get_page(dirty_page);
            }
        }
        set_pte_at(mm, address, page_table, entry); /*最终修改页表项内容*/

        ...
    } else {
        ...
    }

    pte_unmap_unlock(page_table, ptl);

    ...
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  do_anonymous_page函数处理匿名映射内存段的缺页问题。由于匿名映射没有对应文件，这里直接分配新页进行映射。代码注解如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static int do_anonymous_page(struct mm_struct *mm, struct vm_area_struct *vma,
                        unsigned long address, pte_t *page_table, pmd_t *pmd,
                        unsigned int flags)
{
    struct page *page;
    spinlock_t *ptl;
    pte_t entry;

    ...

    /* Allocate our own private page. */
    if (unlikely(anon_vma_prepare(vma)))
        goto oom;
    page = alloc_zeroed_user_highpage_movable(vma, address);
    if (!page)
        goto oom;
    /*
     * The memory barrier inside __SetPageUptodate makes sure that
     * preceeding stores to the page contents become visible before
     * the set_pte_at() write.
     */
    __SetPageUptodate(page);

    entry = mk_pte(page, vma-&amp;gt;vm_page_prot);
    if (vma-&amp;gt;vm_flags &amp;amp; VM_WRITE)
        entry = pte_mkwrite(pte_mkdirty(entry));

    page_table = pte_offset_map_lock(mm, pmd, address, &amp;amp;ptl);
    ...

    inc_mm_counter_fast(mm, MM_ANONPAGES);
    page_add_new_anon_rmap(page, vma, address);
setpte:
    set_pte_at(mm, address, page_table, entry);
    ...

unlock:
    pte_unmap_unlock(page_table, ptl);
    return 0;
...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  do_wp_page函数处理写保护，即针对没有写权限的映射页触发了写请求。这里的处理思路和匿名页处理有些类似，也是分配新页后拷贝原有页的内容，之后解除原有页的映射之后再映射新页。&lt;/p&gt;

&lt;p&gt;  至此，MMU和CPU的内存地址映射功能已经整体分析完毕。CPU在页异常过程中多次涉及内存页分配，而内存分配又牵扯到内存回收和交换，这些都内存管理中不可缺少的部分，后续将对这些部分进行深入分析。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/08/地址映射/&quot;&gt;内存管理之一：地址映射&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/08/%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>CPU中断处理</title>
        <description>&lt;p&gt;  从计算机系统内部看，中断无时无刻不在，这篇博文就和大家一起探讨中断的原理，并以x86_64平台上的linux 3.10内核为例来分析底层实现细节。&lt;/p&gt;

&lt;h3 id=&quot;什么是中断&quot;&gt;什么是中断？&lt;/h3&gt;

&lt;p&gt;  中断是一个系统过程，是计算系统中外部设备向CPU(或CPU之间)通知事件发生的一种机制。这种说法也许有些偏底层，可以从上层更直观的角度来理解：想象你正面对你的个人电脑，当你按下一个键盘按键时，你就触发了一个中断，随后屏幕上会出现你期望的字母；或者当你移动鼠标时，你也会触会一个中断，随后光标会随鼠标的移动而移动。严格意义上说，中断只是一个系统过程(系统调用过程如果抛开其核心处理函数的执行，也是一个系统过程)，是系统的一个部分，而不是一个完整系统，因为它不具备完整系统所应有的&lt;strong&gt;功能&lt;/strong&gt;、&lt;strong&gt;性能&lt;/strong&gt;、&lt;strong&gt;可靠性&lt;/strong&gt;、&lt;strong&gt;可扩展性&lt;/strong&gt;、&lt;strong&gt;安全性&lt;/strong&gt;、&lt;strong&gt;兼容性&lt;/strong&gt;、&lt;strong&gt;可维护性&lt;/strong&gt;等各方面的属性。比如，通过按动键盘，你以中断的方式向计算系统发送命令，但真正执行命令并返回结果的是计算机系统而不是按键动作本身。&lt;/p&gt;

&lt;h3 id=&quot;为什么需要中断&quot;&gt;为什么需要中断？&lt;/h3&gt;

&lt;p&gt;  计算机是个“死脑筋”，从打开电源键开始，就算你不向她发送任何指令，她也会按设定的程序开始忙禄，大多时候都在执行一个叫做IDEL的无聊程序。如何让她听命于你呢？两种方法，要么让她随时可被打断，去做你想让她做的事，随后再去干原来被打断的事；要么让她不停地一直问你想让她做什么，其它的事啥也不干，这样你一发话，她可以立刻响应你的命令。第一种方式，便是中断(interrupt)，第二种方式叫轮询(polling)。在大多数场景下，中断都是一种更为高效的(从完成任务数来看)通知方式，因为计算机干了更多有意义的事，而不是一直在“傻问”；轮询时，如果你想让计算机干得活不是很多，那么计算机大多数问询得到结果都是“谢谢，我不需要你做什么”，这就白白浪费了她的宝贵精力，但是每次你想让计算机做事时，她总是先主动地询问你，之后便立刻进入工作状态了，这比下达命令之后才慢吞吞开始行动的中断方式更为高效(从任务响应时间来看)。因此中断和轮询各有优点，各有各的适用场景：中断适用大多数设备通知场景，而在处理时延敏感场景下(如高性能网络转发)，轮询表现得更好。&lt;/p&gt;

&lt;h3 id=&quot;如何实现中断&quot;&gt;如何实现中断？&lt;/h3&gt;

&lt;p&gt;  下面我们深入系统内部，更细致地理解中断过程。前期的博文介绍过intel i440fx体系的基本组成，这里我们做些简化，只看和中断过程相关的几个部分，并按中断发生后的时序对中断过程作一个概括性的描述：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/interrupt.jpg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;首先，我们可以看到在南桥芯片上集成了一个称为IOAPIC的部件，它共有24根中断引脚可以接收来自外部设备(如键盘、鼠标)的中断请求；当外设触发中断请求后，IOAPIC芯片会根据设备驱动初始化时设定的内容(一个内存地址Address和一个数据Data)向总线发送中断信息(将Data值写入Address地址代表的内存)，如图中绿色线条所示，直观地理解，&lt;strong&gt;这个Address指明了接收本次中断的具体CPU，而Data代表中断向量号(粗略地讲，可以认为这是不同中断相互区别的一个整数值，0~255)&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;其次，对于PCI设备而言，有两种中断触发方式：一种是通过intx中断引脚触发(最终通过IOAPIC发送中断信号，如图中虚线所示)；另一种是MSI/MSI-X方式(Message Signal Interrupt)，PCI设备通过驱动初始化时设定的内容直接向总线发送中断，如图中蓝线所示，其发送原理类似IOAPIC，由于外部设备中断过程并非本文讨论的重点，有兴趣的同学可以查阅PCI规范中相关内容来获得更深入的理解。&lt;/li&gt;
  &lt;li&gt;此外，CPU之间可以通过写ICR寄存器发送IPI(Inter Processors Interrupt)中断来进行核间通信，如图中粉色线条所示。&lt;/li&gt;
  &lt;li&gt;最后，每个CPU逻辑核都有一个称为LAPIC的子部件，它负责接收总线上的中断信息，当确认是发送给本地逻辑核时，便会引发本地CPU的中断过程：CPU会对保存当前正在执行任务的状态信息，之后会根据中断信息找到具体的中断处理逻辑函数；在完成中断处理函数后，CPU便会恢复先前保存的任务状态，继续处理原先的作务。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cpu如何处理中断&quot;&gt;CPU如何处理中断？&lt;/h3&gt;

&lt;p&gt;  介绍完系统内部整体的中断过程后，我们把焦点放到CPU上，更深入地从代码级别看看它是如何处理中断的。&lt;/p&gt;

&lt;h4 id=&quot;1硬件自动完成动作&quot;&gt;&lt;strong&gt;1､硬件自动完成动作&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  x86_64 CPU在中断发生时会执行一系列硬件动作，完成执行上下文的切换，这些都是硬件自动完成的，不受软件控制，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/i440fx/context_switch.jpg&quot; height=&quot;800&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;  图中上半部分表示中断发生前寄存器状态(这里以用户态上下文状态举例)：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CS(代码段寄存器)和rip(指令指针寄存器)指向了当前正在执行的用户态指令的位置(绿色线条所示)；&lt;/li&gt;
  &lt;li&gt;SS(堆栈段寄存器)和rsp(栈指针寄存器)指向了当前用户态堆栈的栈项位置；&lt;/li&gt;
  &lt;li&gt;rflags(标志寄存器)中的IF位为1，表示允许中断发生；&lt;/li&gt;
  &lt;li&gt;TR(Task Register)任务寄存器指向当前任务的任务状态段TSS(Task State Segment)，其中的rsp0域指向了内核态栈顶位置(内核特权级为0)；&lt;/li&gt;
  &lt;li&gt;IDTR(Interrupt Descriptor Table Register)指向了全局中断描述符表(Interrupt Descriptor Table)，表中共有256个中断描述符(Interrupt Descriptor)，每个描述符指向一个中断处理函数入口，中断描述符在表中的索引(下标)称为中断向量(Interrupt Vector)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  中断发生后(只能发生在指令边界，不能打断单条指令的执行)，寄存器状态将发生变化，如上图下半部分所示：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;对于运行在用户态的程序，中断发生后需要切换到内核态执行中断处理函数，出于安全的考虑，堆栈也需要切换到内核态(注意，每个进程在内核态都有一个独立的栈空间，3.10内核中有16K大小，栈项指针保存在TSS)；&lt;/li&gt;
  &lt;li&gt;切换到内核态栈后，CPU自动将用户态SS、rsp、rflags、CS、rip压入栈中(从上到下，栈顶在下，栈底在上)；&lt;/li&gt;
  &lt;li&gt;CPU根据中断向量，取出中断描述符表中对应的中断描述符，将CS:rip指向中断描述符中的函数入口地址；&lt;/li&gt;
  &lt;li&gt;对于类型为Interrupt Gate的中断描述符，rflags中的IF标置位将被清零，表示CPU此时开始不响应外部中断。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  细心的同学可能会问如果程序正好在执行系统调用进入内核态，那中断的硬件过程是怎样的？除了不用进行栈切换外，其它的过程和上面的一样，因为系统调用已经完成了栈切换的动作。&lt;/p&gt;

&lt;h4 id=&quot;2中断描述符表&quot;&gt;&lt;strong&gt;2､中断描述符表&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  硬件自动完成动作的最后是根据中断描述表中的内容找到中断处理函数入口，下面我们看看3.10内核里的中断描述符表的相关实现，其初始流程大致为start_kernel-&amp;gt;init_IRQ-&amp;gt;native_init_IRQ，其核心片断如下所示：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/irqinit.c:

void __init native_init_IRQ(void)
{
    int i;
    
    ...

    /*
     * Cover the whole vector space, no vector can escape
     * us. (some of these will be overridden and become
     * 'special' SMP interrupts)
     */
    i = FIRST_EXTERNAL_VECTOR;
    for_each_clear_bit_from(i, used_vectors, NR_VECTORS) {
        /* IA32_SYSCALL_VECTOR could be used in trap_init already. */
        set_intr_gate(i, interrupt[i - FIRST_EXTERNAL_VECTOR]);
    }

    ...

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  FIRST_EXTERNAL_VECTOR为32，NR_VECTOR为256，开头的这段注释的意思是说这里会给从32到256的所有中断向量注册处理函数，从下面的代码看出处理函数在全局数组interrupt中。那么就有两个问题：为什么从32开始？为什么一开始就能把中断处理函数全部注册好，此时驱动程序都没初始化，具体的中断处理逻辑难道不是在驱动代码中实现的吗？第一个问题比较好回答，其实0~31的向量是intel预留给&lt;strong&gt;异常&lt;/strong&gt;使用的，这是CPU用来处理内部问题的一种方式，如除零、缺页等等。第二个问题目前确实比较难回答，我们就带着这个问题看看interrupt数组的定义吧：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

/*
 * Build the entry stubs and pointer table with some assembler magic.
 * We pack 7 stubs into a single 32-byte chunk, which will fit in a
 * single cache line on all modern x86 implementations.
 */
    .section .init.rodata,&quot;a&quot;
ENTRY(interrupt)
    .section .entry.text
    .p2align 5
    .p2align CONFIG_X86_L1_CACHE_SHIFT
ENTRY(irq_entries_start)
vector=FIRST_EXTERNAL_VECTOR
.rept (NR_VECTORS-FIRST_EXTERNAL_VECTOR+6)/7
    .balign 32
    .rept	7
    .if vector &amp;lt; NR_VECTORS
1:	pushq_cfi $(~vector+0x80)	/* Note: always in signed byte range */
            .if ((vector-FIRST_EXTERNAL_VECTOR)%7) &amp;lt;&amp;gt; 6
    jmp 2f
            .endif
    .previous
    .quad 1b
    .section .entry.text
    vector=vector+1
    .endif
    .endr
2:	jmp common_interrupt
.endr
END(irq_entries_start)

.previous
END(interrupt)
.previous
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  这段汇编代码确实比较晦涩，它把32到256的中断按7个一组划成一个个大组，每个大组的内存占用空间大小在32个字节内，这样这些组块可以被CPU缓存到内部缓存中，以加速对这些内存的访问，显然这是一个性能优化手段。每个大组内包含了7个中断的桩(stub)函数和每个中断的处理函数入口地址，其内存结构如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/i440fx/array.jpg&quot; height=&quot;500&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;  每个中断处理函数的入口地址以XXX_表示，桩函数包含两条指令，一条push指令和一条jmp指令。前6个中断桩函数的jmp指令都会跳转到最后一个桩函数的jmp指令位置，而该指令最终跳转到common_interrupt位置处继续执行。在每个桩函数的最后(组内的最后一个桩函数是在jmp指令前)放置了当前处理函数的入口地址，最终这些地址会组成全局interrupt数组。&lt;/p&gt;

&lt;h4 id=&quot;3公共入口函数common_interrupt&quot;&gt;&lt;strong&gt;3､公共入口函数common_interrupt&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  从上节的介绍中可以看出，中断发生后，CPU会执行中断描述符表所指向的各个中断的桩函数(如上图中XXX_32表示32号向量所对应的中断处理函数入口)，而所有桩函数在将中断向量压入栈后(会做符号化处理)，最终会跳转到common_interrupt函数，这个函数就成了所有中断的公共入口：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

/*
 * Interrupt entry/exit.
 *
 * Interrupt entry points save only callee clobbered registers in fast path.
 *
 * Entry runs with interrupts off.
 */

/* 0(%rsp): ~(interrupt number) */
.macro interrupt func
    /* reserve pt_regs for scratch regs and rbp */
    subq $ORIG_RAX-RBP, %rsp
    SAVE_ARGS_IRQ
    call \func
.endm

/*
 * Interrupt entry/exit should be protected against kprobes
 */
.pushsection .kprobes.text, &quot;ax&quot;
/*
 * The interrupt stubs push (~vector+0x80) onto the stack and
 * then jump to common_interrupt.
 */
.p2align CONFIG_X86_L1_CACHE_SHIFT
common_interrupt:
    addq $-0x80,(%rsp)		/* Adjust vector to [-256,-1] range */
    interrupt do_IRQ
    /* 0(%rsp): old_rsp-ARGOFFSET */
ret_from_intr:
    ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  这里的interrupt代表一个宏，而不是之前讨论的interrupt全局数组。common_interrupt的工作过程就是将栈顶的向量号转化成负数(-256,-1)，然后通过SAVE_ARGS_IRQ宏保存必要的寄要器，最后调用C语言函数do_IRQ来处理中断。SAVE_ARGS_IRQ宏定义如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

/* save partial stack frame */
.macro SAVE_ARGS_IRQ
    cld
    /* start from rbp in pt_regs and jump over */
    movq_cfi rdi, (RDI-RBP)
    movq_cfi rsi, (RSI-RBP)
    movq_cfi rdx, (RDX-RBP)
    movq_cfi rcx, (RCX-RBP)
    movq_cfi rax, (RAX-RBP)
    movq_cfi  r8,  (R8-RBP)
    movq_cfi  r9,  (R9-RBP)
    movq_cfi r10, (R10-RBP)
    movq_cfi r11, (R11-RBP)

    /* Save rbp so that we can unwind from get_irq_regs() */
    movq_cfi rbp, 0

    /* Save previous stack value */
    movq %rsp, %rsi

    leaq -RBP(%rsp),%rdi	/* arg1 for handler */
    testl $3, CS-RBP(%rsi)
    je 1f
    SWAPGS
    /*
     * irq_count is used to check if a CPU is already on an interrupt stack
     * or not. While this is essentially redundant with preempt_count it is
     * a little cheaper to use a separate counter in the PDA (short of
     * moving irq_enter into assembly, which would be too much work)
     */
1:	incl PER_CPU_VAR(irq_count)
    cmovzq PER_CPU_VAR(irq_stack_ptr),%rsp

    /* Store previous stack value */
    pushq %rsi
    TRACE_IRQS_OFF
.endm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/include/asm/calling.h:

/*
 * 64-bit system call stack frame layout defines and helpers,
 * for assembly code:
 */

#define R15		  0
#define R14		  8
#define R13		 16
#define R12		 24
#define RBP		 32
#define RBX		 40

/* arguments: interrupts/non tracing syscalls only save up to here: */
#define R11		 48
#define R10		 56
#define R9		 64
#define R8		 72
#define RAX		 80
#define RCX		 88
#define RDX		 96
#define RSI		104
#define RDI		112
#define ORIG_RAX	120       /* + error_code */
/* end of arguments */

/* cpu exception frame or undefined in case of fast syscall: */
#define RIP		128
#define CS		136
#define EFLAGS		144
#define RSP		152
#define SS		160
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  为什么只保存rdi~r11寄存器？这就涉及gcc编译方面的知识了，对于一个C函数来说，调用者如果在rdi~r11寄存器中保存了有用的信息，那调用者就需要在执行该C函数的调用前保存这些寄存器，因为C函数执行的过程中有可能会修改这些寄存器且不对这些寄存器做保存；而对于rbx,rbp,r12-r15这些寄存器，调用者如果在其中保存了有用的信息，在C函数调用返回后，这些寄存器的值不会发生改变，因为如果C函数内部会使用这些寄存器，它会保存旧的值并在函数返回前恢复这些寄存器旧有的值。&lt;/p&gt;

&lt;p&gt;  终于来到了C语言函数do_IRQ:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/irq.c:

/*
 * do_IRQ handles all normal device IRQ's (the special
 * SMP cross-CPU interrupts have their own specific
 * handlers).
 */
unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
{
    struct pt_regs *old_regs = set_irq_regs(regs);

    /* high bit used in ret_from_ code  */
    unsigned vector = ~regs-&amp;gt;orig_ax;
    unsigned irq;

    irq_enter();
    exit_idle();

    irq = __this_cpu_read(vector_irq[vector]);

    if (!handle_irq(irq, regs)) {
        ...
    }

    irq_exit();

    set_irq_regs(old_regs);
    return 1;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  上述函数的参数regs对应寄存器rdi(可以回顾下x86_64寄存器传参规则)，它是在SAVE_ARGS_IRQ宏中赋值的，指向了栈顶保存的r15寄存器。我理解此时栈顶有可能并没有保存r15寄存器的值，就看do_IRQ函数汇编后需不需要使用r15，但是其实do_IRQ只需要通过regs找到偏移为orig_ax的值(保存了向量号)就行，并不会去访问regs-&amp;gt;r15，所以并不影响程序的正确性。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;do_IRQ函数先保存了旧的栈帧结构指针，并在函数返回前恢复了旧的栈帧结构指针(目前还不是太理解在x86中的作用)；&lt;/li&gt;
  &lt;li&gt;通过regs中的orig_ax取出中断向量号，这里会将负数再次转成正数；&lt;/li&gt;
  &lt;li&gt;执行irq_enter表明正式进入中断上下文，如将当前进程的preempt_count计数增加；exit_idle表明CPU将退出空闲状态，这里均不作展开；&lt;/li&gt;
  &lt;li&gt;通过percpu变量将中断向量转换成irq号，并根据irq号处理中断；&lt;/li&gt;
  &lt;li&gt;执行riq_exit表明退出中断上下文，并恢复旧的栈帖结构指针；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  这里最让人困惑的是&lt;strong&gt;irq&lt;/strong&gt;号，它和中断向量是什么关系？转化关系为什么又是percpu类型的？为了回答这些问题，我们的思路暂时切出中断发生后的过程，来了解一些中断管理类的概念和初始化动作。&lt;/p&gt;

&lt;p&gt;  smp系统出现之前，系统中不同的外部中断完全可以用中断向量来区分，但在smp系统中，CPU核数增加导致中断处理也变得复杂，每个CPU都可以处理不同的中断，如果还用全局性的中断向量来区分中断，所能表示的中断数目太少。那是否可以给每个CPU都设立独立的中断描述符表？不行，这样会大大增加内核实现的复杂性，它采用了一种变通的方式：所有外部中断通过irq号来区分，&lt;strong&gt;不同的中断(即不同的irq)可以使用相同的中断向量，只要这些中断被分配到不同的核上&lt;/strong&gt;，例如在我的系统中查看中断信息得到如下结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/i440fx/example.jpg&quot; height=&quot;680&quot; width=&quot;900&quot; /&gt;&lt;/p&gt;

&lt;p&gt;  第一列中的数字即代表中断irq号，如0号irq代表ISA总线上的全局PIT时钟中断；通常来说0-15号irq对应传统ISA中断；16—39号开始分配给IOAPIC(i440fx中只有一个IOAPIC，占用24个irq)；再往后的irq分配给MSI/MSI-X(i440fx中从16+24=40号开始)。上图中我们看不到系统给每个中断分配的中断向量，假设系统初始化时给irq 0分配了0号核的32号向量，给irq 1分配了1号核的32号向量，那么0号核的percpu数组vector_irq的32号元素就指向irq 0，而1号核的percpu数组vecotr_irq的32号元素指向irq 1，如此一来，虽然0号核和1号核收到的中断向量都是32，但是do_IRQ可以通过percpu的vector_irq找到不同的irq，并通handle_irq执行真正的中断处理逻辑。这就是percpu的vectro_irq的神奇作用，也回答了前篇所提出的&lt;strong&gt;为什么在驱动初始化前就可以给所有中断向量注册处理函数：&lt;/strong&gt;中断描述符表中所指的函数只是一个伪入口(即桩函数)，而非实际的处理函数；实际的处理函数是在驱动初始化时，在为设备申请了irq号之后，通过request_irq(irq, function…)注册给不同的irq的。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;这里还可以再思考一个问题：系统中最多可处理的中断是多少个？是256么？&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;  我们再切回中断的处理过程，在理解irq、中断向量、CPU核之间的关系后，可以看到handle_irq即是对每个中断进行实质性处理的核心函数，最终会调用request_irq函数注册的中断处理逻辑。下面我们就来分析一下handle_irq的实现逻辑。&lt;/p&gt;

&lt;h4 id=&quot;4中断处理逻辑handle_irq&quot;&gt;&lt;strong&gt;4､中断处理逻辑handle_irq&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  该函数整体逻辑比较简单：先将irq转换成&lt;code class=&quot;highlighter-rouge&quot;&gt;struct irq_desc&lt;/code&gt;结构，然后调用的generic_handle_irq_desc函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/irq_64.c:

bool handle_irq(unsigned irq, struct pt_regs *regs)
{
    struct irq_desc *desc;

    ...

    desc = irq_to_desc(irq);
    if (unlikely(!desc))
        return false;

    generic_handle_irq_desc(irq, desc);
    return true;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  irq_desc结构体将包含与中断相关的所有关键信息，内核中将所有中断的irq_desc结构组织成一棵树的结构：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;include/linux/irqdesc.h:

/**
 * struct irq_desc - interrupt descriptor
 * @irq_data:		per irq and chip data passed down to chip functions
 * @kstat_irqs:		irq stats per cpu
 * @handle_irq:		highlevel irq-events handler
 * @preflow_handler:	handler called before the flow handler (currently used by sparc)
 * @action:		the irq action chain
 * @status:		status information
 * @core_internal_state__do_not_mess_with_it: core internal status information
 * @depth:		disable-depth, for nested irq_disable() calls
 * @wake_depth:		enable depth, for multiple irq_set_irq_wake() callers
 * @irq_count:		stats field to detect stalled irqs
 * @last_unhandled:	aging timer for unhandled count
 * @irqs_unhandled:	stats field for spurious unhandled interrupts
 * @threads_handled:	stats field for deferred spurious detection of threaded handlers
 * @threads_handled_last: comparator field for deferred spurious detection of theraded handlers
 * @lock:		locking for SMP
 * @affinity_hint:	hint to user space for preferred irq affinity
 * @affinity_notify:	context for notification of affinity changes
 * @pending_mask:	pending rebalanced interrupts
 * @threads_oneshot:	bitfield to handle shared oneshot threads
 * @threads_active:	number of irqaction threads currently running
 * @wait_for_threads:	wait queue for sync_irq to wait for threaded handlers
 * @dir:		/proc/irq/ procfs entry
 * @name:		flow handler name for /proc/interrupts output
 */
struct irq_desc {
    struct irq_data		irq_data;
    unsigned int __percpu	*kstat_irqs;
    irq_flow_handler_t	handle_irq;

    struct irqaction	*action;	/* IRQ action list */
    unsigned int		status_use_accessors;
    unsigned int		core_internal_state__do_not_mess_with_it;
    unsigned int		depth;		/* nested irq disables */
    unsigned int		wake_depth;	/* nested wake enables */
    unsigned int		irq_count;	/* For detecting broken IRQs */
    unsigned long		last_unhandled;	/* Aging timer for unhandled count */
    unsigned int		irqs_unhandled;
    atomic_t		threads_handled;
    int			threads_handled_last;
    raw_spinlock_t		lock;
    struct cpumask		*percpu_enabled;
#ifdef CONFIG_SMP
    const struct cpumask	*affinity_hint;
    struct irq_affinity_notify *affinity_notify;
#ifdef CONFIG_GENERIC_PENDING_IRQ
    cpumask_var_t		pending_mask;
#endif
#endif
    unsigned long		threads_oneshot;
    atomic_t		threads_active;
    wait_queue_head_t       wait_for_threads;
#ifdef CONFIG_PROC_FS
    struct proc_dir_entry	*dir;
#endif
    int			parent_irq;
    struct module		*owner;
    const char		*name;
} ____cacheline_internodealigned_in_smp;

...

/*
 * Architectures call this to let the generic IRQ layer
 * handle an interrupt. If the descriptor is attached to an
 * irqchip-style controller then we call the -&amp;gt;handle_irq() handler,
 * and it calls __do_IRQ() if it's attached to an irqtype-style controller.
 */
static inline void generic_handle_irq_desc(unsigned int irq, struct irq_desc *desc)
{
    desc-&amp;gt;handle_irq(irq, desc);
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  对于上述代码片断，我不再多作解释，大家可以对照代码注释仔细理解。这里的generic_handle_irq_desc函数通过内联的方式会调用每个中断对应的handle_irq函数。可能很多同学会把这里的handle_irq理解成就是用户(驱动程序)通过request_irq注册的中断处理函数。其实不然，这里的handle_irq仍然是一段通用的中断处理逻辑，用来实现对不同中断模式的处理和中断流控功能。这些通用的处理函数主要有三类：handle_level_irq、handle_edge_irq、handle_fasteoi_irq。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kernel/irq/chip.c:

/**
 *	handle_level_irq - Level type irq handler
 *	@irq:	the interrupt number
 *	@desc:	the interrupt description structure for this irq
 *
 *	Level type interrupts are active as long as the hardware line has
 *	the active level. This may require to mask the interrupt and unmask
 *	it after the associated handler has acknowledged the device, so the
 *	interrupt line is back to inactive.
 */
void
handle_level_irq(unsigned int irq, struct irq_desc *desc)
{
    ...
}

/**
 *	handle_fasteoi_irq - irq handler for transparent controllers
 *	@irq:	the interrupt number
 *	@desc:	the interrupt description structure for this irq
 *
 *	Only a single callback will be issued to the chip: an -&amp;gt;eoi()
 *	call when the interrupt has been serviced. This enables support
 *	for modern forms of interrupt handlers, which handle the flow
 *	details in hardware, transparently.
 */
void
handle_fasteoi_irq(unsigned int irq, struct irq_desc *desc)
{
    ...
}

/**
 *	handle_edge_irq - edge type IRQ handler
 *	@irq:	the interrupt number
 *	@desc:	the interrupt description structure for this irq
 *
 *	Interrupt occures on the falling and/or rising edge of a hardware
 *	signal. The occurrence is latched into the irq controller hardware
 *	and must be acked in order to be reenabled. After the ack another
 *	interrupt can happen on the same source even before the first one
 *	is handled by the associated event handler. If this happens it
 *	might be necessary to disable (mask) the interrupt depending on the
 *	controller hardware. This requires to reenable the interrupt inside
 *	of the loop which handles the interrupts which have arrived while
 *	the handler was running. If all pending interrupts are handled, the
 *	loop is left.
 */
void
handle_edge_irq(unsigned int irq, struct irq_desc *desc)
{
    ...
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  这三类函数主要是针对不同物理电气特性的中断和中断控制器(如IO-APIC、支持MSI的PCI设备等)做不同的处理。有兴趣的同学可以结合intel IO-APIC说明和PCI规范来仔细理解里面的实现过程。&lt;/p&gt;

&lt;p&gt;  最后，这几类函数都会调用handle_irq_event，它会调用irq_desc中action的handler，这个函数指针，才是用户通过request_irq注册的中断处理函数。到这一步，才真正调用到实际的中断处理逻辑。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kernel/irq/handler.c:

irqreturn_t
handle_irq_event_percpu(struct irq_desc *desc, struct irqaction *action)
{
    irqreturn_t retval = IRQ_NONE;
    unsigned int flags = 0, irq = desc-&amp;gt;irq_data.irq;

    do {
        irqreturn_t res;

        res = action-&amp;gt;handler(irq, action-&amp;gt;dev_id);

        ...

        switch (res) {
        case IRQ_WAKE_THREAD:
            /*
             * Catch drivers which return WAKE_THREAD but
             * did not set up a thread function
             */
            if (unlikely(!action-&amp;gt;thread_fn)) {
                warn_no_thread(irq, action);
                break;
            }

            irq_wake_thread(desc, action);

            /* Fall through to add to randomness */
        case IRQ_HANDLED:
            flags |= action-&amp;gt;flags;
            break;

        default:
            break;
        }

        retval |= res;
        action = action-&amp;gt;next;
    } while (action);

    add_interrupt_randomness(irq, flags);

    if (!noirqdebug)
        note_interrupt(irq, desc, retval);
    return retval;
}

irqreturn_t handle_irq_event(struct irq_desc *desc)
{
    struct irqaction *action = desc-&amp;gt;action;
    irqreturn_t ret;

    desc-&amp;gt;istate &amp;amp;= ~IRQS_PENDING;
    irqd_set(&amp;amp;desc-&amp;gt;irq_data, IRQD_IRQ_INPROGRESS);
    raw_spin_unlock(&amp;amp;desc-&amp;gt;lock);

    ret = handle_irq_event_percpu(desc, action);

    raw_spin_lock(&amp;amp;desc-&amp;gt;lock);
    irqd_clear(&amp;amp;desc-&amp;gt;irq_data, IRQD_IRQ_INPROGRESS);
    return ret;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;5中断返回ret_from_intr&quot;&gt;&lt;strong&gt;5､中断返回ret_from_intr&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  当irq_desc的action处理完毕之后，中断处理过程将逐步返回到ret_from_intr：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

ret_from_intr:
    DISABLE_INTERRUPTS(CLBR_NONE)
    TRACE_IRQS_OFF
    decl PER_CPU_VAR(irq_count)

    /* Restore saved previous stack */
    popq %rsi
    leaq ARGOFFSET-RBP(%rsi), %rsp

exit_intr:
    GET_THREAD_INFO(%rcx)
    testl $3,CS-ARGOFFSET(%rsp)
    je retint_kernel

/* Interrupt came from user space */
/*
 * Has a correct top of stack, but a partial stack frame
 * %rcx: thread info. Interrupts off.
 */
retint_with_reschedule:
    movl $_TIF_WORK_MASK,%edi
retint_check:
    LOCKDEP_SYS_EXIT_IRQ
    movl TI_flags(%rcx),%edx
    andl %edi,%edx
    jnz  retint_careful

retint_swapgs:		/* return to user-space */
    /*
     * The iretq could re-enable interrupts:
     */
    DISABLE_INTERRUPTS(CLBR_ANY)
    TRACE_IRQS_IRETQ
    SWAPGS
    jmp restore_args

retint_restore_args:	/* return to kernel space */
    DISABLE_INTERRUPTS(CLBR_ANY)
    /*
     * The iretq could re-enable interrupts:
     */
    TRACE_IRQS_IRETQ
restore_args:
    RESTORE_ARGS 1,8,1

irq_return:
    INTERRUPT_RETURN
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  上述过程首先判断中断发生时是在用户态还是在内核态，&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果是在内核态，就跳转到retint_kernel执行，这里会根据内核是否打开抢占进行不同的处理：如果内核不可抢占，那就恢复寄存器后返回到被中断的上下文继续执行；如果是可抢占的，那就可以进行调度。&lt;/li&gt;
  &lt;li&gt;如果是在用户态，就进行调度及信号相关的判断和处理；处理完成并恢复寄存器后，便通过iretq指令返回被中断的上下文继续执行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  至此，CPU上中断处理的整个系统过程完美结束，这真是一个漫长的旅途:-&amp;gt;&lt;/p&gt;

&lt;h3 id=&quot;中断处理如何优化软中断&quot;&gt;中断处理如何优化？－软中断&lt;/h3&gt;

&lt;p&gt;  通过前文的分析，我们看到中断的处理过程已经比较复杂了，即便如此，系统工程师们仍努力在思考如何改进中断的处理。一个显著的问题就是，如果CPU每次都是等整个中断处理逻辑执行完毕之后再开始响应下一个中断，那后续中断处理的实时性就会受影响，而且长时间处于中断上下文也会影响时钟和任务调度。于是，内核工程师想了一个办法：把中断的处理分成两部分：一部分是立刻要做的(通常是和硬件相关的部分)，并且只有等这部分做完了才能响应下一个中断，这部分通常处理时间很短，我们称这部分为上半部；另一部分是可以晚些时候处理(偏上层逻辑的部分)，并且在处理这部分工作的时候是可以响应一下个中断的，这部分通常处理时间较长，我们称之为下半部。软中断就是下半部的一种实现方式，它大大提升了中断处理的实时性。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/03/中断/&quot;&gt;CPU中断处理&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 18 Mar 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/03/%E4%B8%AD%E6%96%AD/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/%E4%B8%AD%E6%96%AD/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
  </channel>
</rss>
