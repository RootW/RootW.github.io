<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>吴斌</title>
    <description>欢迎来到我的技术博客~</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 28 Dec 2017 16:27:33 +0800</pubDate>
    <lastBuildDate>Thu, 28 Dec 2017 16:27:33 +0800</lastBuildDate>
    <generator>Jekyll v3.4.0</generator>
    
      <item>
        <title>内存管理之一：地址映射</title>
        <description>&lt;p&gt;  地址映射是CPU核心和MMU共同完成的内存管理功能之一，本节将对此展开深入讨论。计算子系统相关内容目录&lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;点此进入&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是地址映射为什么需要它&quot;&gt;什么是地址映射？为什么需要它？&lt;/h3&gt;

&lt;p&gt;  正如在&lt;a href=&quot;https://rootw.github.io/2017/02/计算机/&quot;&gt;计算机系统&lt;/a&gt;整体介绍中所说明的一样，MMU在CPU核心的配合下(通过页异常触发)，实现了线性地址到物理地址的动态映射，为正在CPU上运行的应用程序提供了一个独立的连续内存空间(线性地址空间，或称虚拟内存空间)，屏蔽了地址分配、内存分配和内存回收等一系列复杂的系统行为，不仅提升了内存资源的利用效率，而且大大降低了应用开发难度，使程序猿可以更聚焦业务逻辑。&lt;/p&gt;

&lt;h3 id=&quot;如何实现&quot;&gt;如何实现？&lt;/h3&gt;

&lt;h4 id=&quot;1线性地址&quot;&gt;&lt;strong&gt;1.线性地址&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  x86_64架构下Linux中每个应用程序可见的线性地址空间如下(注：分段机制在64位模式下已不产生实际作用)：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory1_1.jpg&quot; height=&quot;200&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  该架构支持48位线性地址(高16位仅做符号扩展，不参与地址转换)到40位物理地址(最多52位，由CPU实现决定)的映射。48位线性空间共256T，分为两个128T区间，分别分布在完整的64位空间的两端。其中，低128T为用户空间，映射用户程序代码、数据、堆栈和共享库，物理内存随着程序的运行由内核动态分配。而高128T则为内核空间：direct mapping区映射整个物理内存空间，便于内核访问所有物理内存；vmalloc space区间为内核调用vmalloc时使用的线性空间，物理内存动态分配且物理上不保证连续；virtual memory map是内核标识内存页信息的数组，供内存管理功能使用；kernel text &amp;amp; module区存放内核和模块的代码及数据。此外，也可以参考内核代码的说明：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/Documentation/x86/x86_64/mm.txt:

0000000000000000 - 00007fffffffffff (=47 bits) user space, different per mm
hole caused by [48:63] sign extension
ffff800000000000 - ffff80ffffffffff (=40 bits) guard hole
ffff880000000000 - ffffc7ffffffffff (=64 TB) direct mapping of all phys. memory
ffffc80000000000 - ffffc8ffffffffff (=40 bits) hole
ffffc90000000000 - ffffe8ffffffffff (=45 bits) vmalloc/ioremap space
ffffe90000000000 - ffffe9ffffffffff (=40 bits) hole
ffffea0000000000 - ffffeaffffffffff (=40 bits) virtual memory map (1TB)
... unused hole ...
ffffff0000000000 - ffffff7fffffffff (=39 bits) %esp fixup stacks
... unused hole ...
ffffffff80000000 - ffffffffa0000000 (=512 MB)  kernel text mapping, from phys 0
ffffffffa0000000 - ffffffffff5fffff (=1525 MB) module mapping space
ffffffffff600000 - ffffffffffdfffff (=8 MB) vsyscalls
ffffffffffe00000 - ffffffffffffffff (=2 MB) unused hole

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;2地址转换&quot;&gt;&lt;strong&gt;2.地址转换&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  MMU的线性地址转换是通过页表进行的，具体过程如下图所示(摘自intel程序员手册卷3)：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory1_3.jpg&quot; height=&quot;500&quot; width=&quot;750&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  其实最简单明了的方法是通过一个一维数组来记录映射关系:下标代表线性地址，数组元素内容代表物理地址。可是如此一来，用来表示映射关系的内存空间比被表示的物理空间还要大，显然这不是一个可行的方案。&lt;/p&gt;

&lt;p&gt;  工程师们采用了分段分级的思路来表示这种映射关系：先把线性空间以4K大小为单位进行划分(页)，然后再以大段连续空间进行转换，在每个大段空间内部再次划分成小段进行转换，直到段大小变为4K页大小。用以表示和段空间映射关系的结构称为页表，其大小也是一个页面。由于采用了分段的方法，页表空间大大减小；同时未映射的空间不必分配页表，这也进一步降低了页表占用空间。&lt;/p&gt;

&lt;p&gt;  x86_64架构下Linux用了四级页表来表示一个映射关系，依次为PGD、PUD、PMD、PT。每级页表4K大小，内部元素大小为8字节，高位指向了下一级页表的物理地址，低位表示页表属性(是否存在、读写权限、是否脏等等)。顶层页表PGD的物理地址存放在CPU的CR3寄存器中，供MMU访问。48位线性地址也相应地分成了五段：前四段，每段长9位，用来索引对应页表的元素；最后一段长12位，用来在页面中索引物理地址。各级页表的详细内容参考下表：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory1_4.jpg&quot; height=&quot;650&quot; width=&quot;800&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;3页异常处理&quot;&gt;&lt;strong&gt;3.页异常处理&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  一个进程初始运行时，对应的页表项大多都是空的。一旦MMU在地址转换过程中出现缺页或者读写权限问题时，MMU会触发页异常，打断CPU当前正在执行的程序，转而进行页异常处理(缺页会分配新页)。当页异常处理完毕后，CPU会重新执行引发缺页的指令，此时MMU便可正常完成地址转换。&lt;/p&gt;

&lt;p&gt;  下面，我们进一步深入分析整个页异常处理过程，关键流程如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/memory1_2.jpg&quot; height=&quot;600&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  CPU收到页异常后，首先进行的是上下文切换的硬件过程，该过程主要完成栈的切换(进入内核栈)、关键寄存器的保存和执行函数的切换(转入页异常处理函数page_fault)。有关中断和异常处理的详细分析请参考&lt;a href=&quot;https://rootw.github.io/2017/03/中断/&quot;&gt;中断分析&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;  CPU被页异常中断后最先执行的是一段汇编代码(page_fault位于linux/arch/x86/kernel/entry_64.S，感兴趣的同学可以自行分析)，它完成了其他上下文寄存器的保存，并进入核心处理逻辑do_page_fault。&lt;/p&gt;

&lt;p&gt;  在理解MMU的工作原理之后，我想大家对缺页异常的核心处理逻辑应该很快能想明白，无非就是分配页、填充页内容、修改页表。然而，回顾一下前面线性地址章节描绘的地址空间分配图，我们会发现其中有代码、有数据、有堆和栈，不同类型的区段的对于页异常的处理逻辑是有区别的，例如代码段的页内容来自可执行文件，是只读类型的；数据段初始内容也来自可执行文件，但后续的修改不影响可执行执行文件；堆和栈的内容不来自任何文件，只在当前进程内部可见。因此，针对不同类型的内存区段需要有不同的处理方式。Linux内核以虚拟内存段(vma, virtual memory area)来表达不同程序区段，不同段可以具有不同的读写权限和属性；不在任何内存段的地址则认为是非法地址。有关内存段的数据结构如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/include/mm_types.h:

/*
 * This struct defines a memory VMM memory area. There is one of these
 * per VM-area/task.  A VM area is any part of the process virtual memory
 * space that has a special rule for the page-fault handlers (ie a shared
 * library, the executable area etc).
 */
struct vm_area_struct {
    /* The first cache line has the info for VMA tree walking. */

    unsigned long vm_start;		/* Our start address within vm_mm. */
    unsigned long vm_end;		/* The first byte after our end address within vm_mm. */

    /* linked list of VM areas per task, sorted by address */
    struct vm_area_struct *vm_next, *vm_prev;

    struct rb_node vm_rb;

    ...

    /* Second cache line starts here. */

    struct mm_struct *vm_mm;	/* The address space we belong to. */
    pgprot_t vm_page_prot;		/* Access permissions of this VMA. */
    unsigned long vm_flags;		/* Flags, see mm.h. */

    ...

    /* Function pointers to deal with this struct. */
    const struct vm_operations_struct *vm_ops;

    /* Information about our backing store: */
    unsigned long vm_pgoff;		/* Offset (within vm_file) in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */
    struct file * vm_file;		/* File we map to (can be NULL). */
    void * vm_private_data;		/* was vm_pte (shared mem) */

    ...
};

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  所有vma会以链表形式统一到mm_struct中，该结构每个进程拥有一个，被进程控制块使用，描述了每个进程的有效内存区段和地址映射关系：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/include/mm_types.h:

struct mm_struct {
    struct vm_area_struct * mmap;		/* list of VMAs */
    struct rb_root mm_rb;
    struct vm_area_struct * mmap_cache;	/* last find_vma result */
#ifdef CONFIG_MMU
    unsigned long (*get_unmapped_area) (struct file *filp,
    unsigned long addr, unsigned long len,
    unsigned long pgoff, unsigned long flags);
    void (*unmap_area) (struct mm_struct *mm, unsigned long addr);
#endif
    unsigned long mmap_base;            /* base of mmap area */
    unsigned long mmap_legacy_base;     /* base of mmap area in bottom-up allocations */
    unsigned long task_size;            /* size of task vm space */
    unsigned long cached_hole_size; 	/* if non-zero, the largest hole below free_area_cache */
    unsigned long free_area_cache;		/* first hole of size cached_hole_size or larger */
    unsigned long highest_vm_end;		/* highest vma end address */
    pgd_t * pgd;
    atomic_t mm_users;			/* How many users with user space? */
    atomic_t mm_count;			/* How many references to &quot;struct mm_struct&quot; (users count as 1) */
    int map_count;				/* number of VMAs */

    spinlock_t page_table_lock;		/* Protects page tables and some counters */
    struct rw_semaphore mmap_sem;

    struct list_head mmlist;        /* List of maybe swapped mm's.	These are globally strung
                                     * together off init_mm.mmlist, and are protected
                                     * by mmlist_lock
                                     */

    ...

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  我们回到do_page_fault函数，它通过读取CPU的CR2寄存器可以获知发生页异常的线性地址，并在当前进程对应的mm_struct中查找该线性地址对应的vma虚拟地址内存段，最后根据vma的属性来进一步处理页异常。当然，如果找不到线性地址对应的vma，内核就会认为发生了一次非法内存访问(让程序猿闻风丧胆的segfault由此产生)。代码片断分析如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/arch/x86/mm/fault.c:

/*
 * This routine handles page faults.  It determines the address,
 * and the problem, and then passes it off to one of the appropriate
 * routines.
 */
static void __kprobes
__do_page_fault(struct pt_regs *regs, unsigned long error_code)
{
    struct vm_area_struct *vma;
    struct task_struct *tsk;
    unsigned long address;
    struct mm_struct *mm;
    int fault;
    unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;

    tsk = current;  /*获取当前进程*/
    mm = tsk-&amp;gt;mm;   /*当前进程对应的mm_struct*/

    /* Get the faulting address: */
    address = read_cr2();   /*x86架构下，页异常发生时，CR2寄存器中会记录发生异常的线性地址*/

    if (unlikely(fault_in_kernel_space(address))) {
        /*通过异常地址范围，判断异常地址是否在内核态。
          如果发生在内核态，通常是由于vmalloc导致的，这里会处理页表映射关系*/
        ...
        return;
    }

    ...

    /*如果执行到这里，说明页异常地址处在用户态范围*/
    /*如果代码段也在用户态，则打开中断，并记录标志；
      如果代码段在内核态，则根据页异常发生前的IF标记值来决定是否打开中断*/
    if (user_mode_vm(regs)) {
        local_irq_enable();
        error_code |= PF_USER;
        flags |= FAULT_FLAG_USER;
    } else {
        if (regs-&amp;gt;flags &amp;amp; X86_EFLAGS_IF)
            local_irq_enable();
    }

    ...

    /*
     * If we're in an interrupt, have no user context or are running
     * in an atomic region then we must not take the fault:
     */
    /*这里注意一点：页异常处理属于进程上下文，不是中断上下文，可睡眠*/
    if (unlikely(in_atomic() || !mm)) {
        bad_area_nosemaphore(regs, error_code, address);
        return;
    }

    if (error_code &amp;amp; PF_WRITE)
        flags |= FAULT_FLAG_WRITE;

    /*
     * When running in the kernel we expect faults to occur only to
     * addresses in user space.  All other faults represent errors in
     * the kernel and should generate an OOPS.  Unfortunately, in the
     * case of an erroneous fault occurring in a code path which already
     * holds mmap_sem we will deadlock attempting to validate the fault
     * against the address space.  Luckily the kernel only validly
     * references user space from well defined areas of code, which are
     * listed in the exceptions table.
     * ...
     */
    /*获取当前mm_struct的读信号量，避免后续处理过程中有其它流程修改mm_struct结构*/
    if (unlikely(!down_read_trylock(&amp;amp;mm-&amp;gt;mmap_sem))) {
        if ((error_code &amp;amp; PF_USER) == 0 &amp;amp;&amp;amp;
                !search_exception_tables(regs-&amp;gt;ip)) {
            bad_area_nosemaphore(regs, error_code, address);
            return;
        }
retry:
        down_read(&amp;amp;mm-&amp;gt;mmap_sem);
    } else {
    /*
     * The above down_read_trylock() might have succeeded in
     * which case we'll have missed the might_sleep() from
     * down_read():
     */
        might_sleep();
    }

    /*查找页异常地址对应的vma区段*/
    vma = find_vma(mm, address);
    if (unlikely(!vma)) {
        bad_area(regs, error_code, address);
        return;
    }
    /*如果页异常地址在合理的vma段地址范围内，则进行后续的异常处理*/
    if (likely(vma-&amp;gt;vm_start &amp;lt;= address))
        goto good_area;
    if (unlikely(!(vma-&amp;gt;vm_flags &amp;amp; VM_GROWSDOWN))) {
        /*如果页异常地址小于vma起始地址，但vma又不是往低地址方向增长(栈是往低地址方向增长的)，则出现错误*/
        bad_area(regs, error_code, address);
        return;
    }

    ...

    /*往低地址方向增长栈*/
    if (unlikely(expand_stack(vma, address))) {
        bad_area(regs, error_code, address);
        return;
    }

    /*
     * Ok, we have a good vm_area for this memory access, so
     * we can handle it..
     */
    /*如果执行到这里，后续便开始针对vma的属性进行不同的页异常处理*/
good_area:
    if (unlikely(access_error(error_code, vma))) {
        bad_area_access_error(regs, error_code, address);
        return;
    }

    /*
     * If for any reason at all we couldn't handle the fault,
     * make sure we exit gracefully rather than endlessly redo
     * the fault:
     */
    fault = handle_mm_fault(mm, vma, address, flags);

    ...

}


/*下面补充一些关于页异常错误码的内容，通常在发生段错误时我们在系统日志中可以看到错误码，
  通过错误码我们大致可以得知异常发生的原因*/
/*
 * Page fault error code bits:
 *
 *   bit 0 ==	 0: no page found	1: protection fault
 *   bit 1 ==	 0: read access		1: write access
 *   bit 2 ==	 0: kernel-mode access	1: user-mode access
 *   bit 3 ==				1: use of reserved bit detected
 *   bit 4 ==				1: fault was an instruction fetch
 */
enum x86_pf_error_code {
    PF_PROT     =       1 &amp;lt;&amp;lt; 0,
    PF_WRITE    =       1 &amp;lt;&amp;lt; 1,
    PF_USER     =       1 &amp;lt;&amp;lt; 2,
    PF_RSVD     =       1 &amp;lt;&amp;lt; 3,
    PF_INSTR    =       1 &amp;lt;&amp;lt; 4,
};
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  handle_mm_fault函数基于当前进程的mm_struct、异常地址所在vma和异常处理控制标志flags进行进一步异常处理。我们知道，页表共有四级，这里依次对各级页表进行处理：PGD是在进程创建的时候就分配好的，不需要动态分配；从PUD到PT，如果页表不存在会动态分配页并使页表指向新分配的页。页表处理完成后，进入handle_pte_fault处理最后的物理页。handle_mm_fault代码注解如下(这里暂不考虑大页等复杂特性)：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/memory.c:

/*
 * By the time we get here, we already hold the mm semaphore
 */
static int __handle_mm_fault(struct mm_struct *mm, struct vm_area_struct *vma,
unsigned long address, unsigned int flags)
{
    pgd_t *pgd;
    pud_t *pud;
    pmd_t *pmd;
    pte_t *pte;

    ...

retry:
    pgd = pgd_offset(mm, address); /*直接获取当前进程中页异常线性地址在PGD表中对应的项，无须分配*/
    pud = pud_alloc(mm, pgd, address); /*获取PUD表中对应的项，如果PUD表不存在则动态分配*/
    if (!pud)
        return VM_FAULT_OOM;
    pmd = pmd_alloc(mm, pud, address); /*获取PMD表中对应的项，如果PMD不存在则动态分配*/
    if (!pmd)
        return VM_FAULT_OOM;

    ...
    if (unlikely(pmd_none(*pmd)) &amp;amp;&amp;amp;
        unlikely(__pte_alloc(mm, vma, pmd, address))) /*动态分配PTE*/
    return VM_FAULT_OOM;
    ...

    pte = pte_offset_map(pmd, address);

    /*各级页表分配完毕后，真正开始处理页异常*/
    return handle_pte_fault(mm, vma, address, pte, pmd, flags);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  题外话，页表操作的同步。通常情况下，一个确定的映射关系mm_struct只被一个进程引用，同一进程在确定时刻只会运行在一个核上，因此该进程的页异常处理也只在一个核上发生，此时不存在对进程页表做并发操作的可能。然而，如果一个进程有多个线程，那么这些线程将引用相同的mm_struct(代码段、数据段、堆空间完全相同，栈空间各不相同)，此时对mm_struct所涉及的各级页表操作时就需要考虑同步问题。&lt;/p&gt;

&lt;p&gt;  一种简单的方法是在开始页表操作前，对mm_struct先上一把大锁，待各级页表均操作完毕后再解锁。但存在的问题是页表操作过程中会涉及页分配，这是一个极其复杂的过程，可能还会睡眠，这样一来有可能出现成功加到锁的线程进入睡眠态后导致其他线程缺页却加不到锁的情况。即便不同线程访问的是不同内存段，但是却有可能出现因为一个线程的页异常处理不及时导致所有线程无法正常处理页异常的情况。&lt;/p&gt;

&lt;p&gt;  linux内核针对此种问题采用了最小化加锁范围的方法。每次操作页表前，如果页表项不存在则先分配页，然后加mm_struct锁。加锁成功后，如果发现页表项已经被赋值，说明有其他CPU先于当前CPU完成了页表分配，则释放先前分配页并解锁；如果未被赋值，则将分配页赋值给页表项，最后解锁。这种方法虽然会导致一些多余的页分配和释放动作，但加锁区间和持锁时间大大缩短，系统整体并发性大大提升。此外，对于最后一级PT页表的操作比前几级页表复杂性要高得多，因此内核对PT页表使用了一把独立的锁，进一步提升系统并行效率。代码注解如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int __pud_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address)
{
    pud_t *new = pud_alloc_one(mm, address); /*先偿试分配一页，该过程执行时间可能会比较长*/
    if (!new)
    return -ENOMEM;

    smp_wmb(); /* See comment in __pte_alloc */

    /*加锁判断原有页表项是否改变，如果发生改变说明有其它流程已成功分配页表，这里就释放之间分配的页*/
    spin_lock(&amp;amp;mm-&amp;gt;page_table_lock); 
    if (pgd_present(*pgd))		/* Another has populated it */
        pud_free(mm, new);
    else
        pgd_populate(mm, pgd, new);
    spin_unlock(&amp;amp;mm-&amp;gt;page_table_lock);
    return 0;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  我们再回到页异常处理主逻辑，接下来handle_pte_fault函数根据PT页表中异常地址对应的页表项进行不同处理：如果页表项PRESENT位未被置位，代表物理页不存在，需要进行缺页处理；否则，代表访问权限不够，需要调用do_wp_page进行写保护处理。在缺页的情况下，如果页表项不为零，说明前期把物理页交换到磁盘上了，而页表项纪录了交换页所在的磁盘位置信息，那么此时需要通过do_swap_page将交换页取回内存(内存交换将单独起一篇博文分析)；页表项为零则根据vma是否有文件对应进行不同处理，文件映射由do_linear_fault处理，匿名映射由do_anonymous_page处理。handle_pte_fault代码注解如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/memory.c:

int handle_pte_fault(struct mm_struct *mm,
            struct vm_area_struct *vma, unsigned long address,
            pte_t *pte, pmd_t *pmd, unsigned int flags)
{
    pte_t entry;
    spinlock_t *ptl;

    entry = *pte;
    if (!pte_present(entry)) { /*判断页是否不存在*/
        if (pte_none(entry)) { /*如果不仅不存在，而且页表项内容为零*/
            if (vma-&amp;gt;vm_ops) /*文件映射*/
                return do_linear_fault(mm, vma, address, pte, pmd, flags, entry);
            return do_anonymous_page(mm, vma, address, pte, pmd, flags); /*匿名映射*/
        }
        ...
        /*页不存在，但是非零，表示指向一个交换页，则执行换入操作*/
        return do_swap_page(mm, vma, address, pte, pmd, flags, entry);
    }

    ...

    /*处理防问权限异常，如写保护异常*/
    ptl = pte_lockptr(mm, pmd);
    spin_lock(ptl);
    if (unlikely(!pte_same(*pte, entry)))
        goto unlock;
    if (flags &amp;amp; FAULT_FLAG_WRITE) {
        if (!pte_write(entry))
            return do_wp_page(mm, vma, address, pte, pmd, ptl, entry);
        entry = pte_mkdirty(entry);
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  do_linear_fault函数处理线性文件映射内存段的缺页问题。对于读缺页，通过查找文件缓存页后直接采用缓存页作为映射页；对于写缺页，先查找文件缓存页，如果为共享内存段则直接采用缓存页映射，如果为私有内存段则分配新页、拷贝缓存页内容后再映射新页。代码注解如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;linux/mm/memory.c:

static int do_linear_fault(struct mm_struct *mm, struct vm_area_struct *vma,
                        unsigned long address, pte_t *page_table, pmd_t *pmd,
                        unsigned int flags, pte_t orig_pte)
{
    pgoff_t pgoff = (((address &amp;amp; PAGE_MASK)
                    - vma-&amp;gt;vm_start) &amp;gt;&amp;gt; PAGE_SHIFT) + vma-&amp;gt;vm_pgoff; /*计算异常地址对应内容在文件中的偏移*/

    return __do_fault(mm, vma, address, pmd, pgoff, flags, orig_pte);
}


static int __do_fault(struct mm_struct *mm, struct vm_area_struct *vma,
                    unsigned long address, pmd_t *pmd,
                    pgoff_t pgoff, unsigned int flags, pte_t orig_pte)
{
    pte_t *page_table;
    spinlock_t *ptl;
    struct page *page;
    struct page *cow_page;
    pte_t entry;
    int anon = 0;
    struct page *dirty_page = NULL;
    struct vm_fault vmf;
    int ret;


    /*对于写操作，如果页异常地址所在vma段的属性是私有的，即没有设置VM_SHARED标记，
      则需要分配一个匿名页并复制文件中的内容*/
    if ((flags &amp;amp; FAULT_FLAG_WRITE) &amp;amp;&amp;amp; !(vma-&amp;gt;vm_flags &amp;amp; VM_SHARED)) {

        if (unlikely(anon_vma_prepare(vma)))
            return VM_FAULT_OOM;

        cow_page = alloc_page_vma(GFP_HIGHUSER_MOVABLE, vma, address);
        if (!cow_page)
            return VM_FAULT_OOM;

        ...
    } else
        cow_page = NULL;

    vmf.virtual_address = (void __user *)(address &amp;amp; PAGE_MASK);
    vmf.pgoff = pgoff;
    vmf.flags = flags;
    vmf.page = NULL;

    /*通过文件系统中的fault操作，在vmf.page中返回页异常地址对应文件内容的缓存页*/
    ret = vma-&amp;gt;vm_ops-&amp;gt;fault(vma, &amp;amp;vmf);
    ...

    page = vmf.page;
    if (flags &amp;amp; FAULT_FLAG_WRITE) {
        if (!(vma-&amp;gt;vm_flags &amp;amp; VM_SHARED)) {
            page = cow_page;
            anon = 1;
            copy_user_highpage(page, vmf.page, address, vma); /*复制缓存页中的内容到匿名页*/
            __SetPageUptodate(page);
        } else {
            ...
        }
    }

    page_table = pte_offset_map_lock(mm, pmd, address, &amp;amp;ptl);

    if (likely(pte_same(*page_table, orig_pte))) { /*通常都会进入该分支，是一种高效的页表访问方式*/
        entry = mk_pte(page, vma-&amp;gt;vm_page_prot); /*将页地址和基本属性填入页表项*/
        if (flags &amp;amp; FAULT_FLAG_WRITE)
            entry = maybe_mkwrite(pte_mkdirty(entry), vma); /*设置页表项写权限*/
        if (anon) { /*如果是匿名页，则添加反向匿名映射*/
            inc_mm_counter_fast(mm, MM_ANONPAGES);
            page_add_new_anon_rmap(page, vma, address);
        } else { /*如果是文件映射，则添加反向文件映射*/
            inc_mm_counter_fast(mm, MM_FILEPAGES);
            page_add_file_rmap(page);
            if (flags &amp;amp; FAULT_FLAG_WRITE) {
                dirty_page = page;
                get_page(dirty_page);
            }
        }
        set_pte_at(mm, address, page_table, entry); /*最终修改页表项内容*/

        ...
    } else {
        ...
    }

    pte_unmap_unlock(page_table, ptl);

    ...
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  do_anonymous_page函数处理匿名映射内存段的缺页问题。由于匿名映射没有对应文件，这里直接分配新页进行映射。代码注解如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static int do_anonymous_page(struct mm_struct *mm, struct vm_area_struct *vma,
                        unsigned long address, pte_t *page_table, pmd_t *pmd,
                        unsigned int flags)
{
    struct page *page;
    spinlock_t *ptl;
    pte_t entry;

    ...

    /* Allocate our own private page. */
    if (unlikely(anon_vma_prepare(vma)))
        goto oom;
    page = alloc_zeroed_user_highpage_movable(vma, address);
    if (!page)
        goto oom;
    /*
     * The memory barrier inside __SetPageUptodate makes sure that
     * preceeding stores to the page contents become visible before
     * the set_pte_at() write.
     */
    __SetPageUptodate(page);

    entry = mk_pte(page, vma-&amp;gt;vm_page_prot);
    if (vma-&amp;gt;vm_flags &amp;amp; VM_WRITE)
        entry = pte_mkwrite(pte_mkdirty(entry));

    page_table = pte_offset_map_lock(mm, pmd, address, &amp;amp;ptl);
    ...

    inc_mm_counter_fast(mm, MM_ANONPAGES);
    page_add_new_anon_rmap(page, vma, address);
setpte:
    set_pte_at(mm, address, page_table, entry);
    ...

unlock:
    pte_unmap_unlock(page_table, ptl);
    return 0;
...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  do_wp_page函数处理写保护，即针对没有写权限的映射页触发了写请求。这里的处理思路和匿名页处理有些类似，也是分配新页后拷贝原有页的内容，之后解除原有页的映射之后再映射新页。&lt;/p&gt;

&lt;p&gt;  至此，MMU和CPU的内存地址映射功能已经整体分析完毕。CPU在页异常过程中多次涉及内存页分配，而内存分配又牵扯到内存回收和交换，这些都内存管理中不可缺少的部分，后续将对这些部分进行深入分析。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/08/地址映射/&quot;&gt;内存管理之一：地址映射&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/08/%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/%E5%9C%B0%E5%9D%80%E6%98%A0%E5%B0%84/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>CPU中断处理</title>
        <description>&lt;p&gt;  从计算机系统内部看，中断无时无刻不在，这篇博文就和大家一起探讨中断的原理，并以x86_64平台上的linux 3.10内核为例来分析底层实现细节。&lt;/p&gt;

&lt;h3 id=&quot;什么是中断&quot;&gt;什么是中断？&lt;/h3&gt;

&lt;p&gt;  中断是一个系统过程，是计算系统中外部设备向CPU(或CPU之间)通知事件发生的一种机制。这种说法也许有些偏底层，可以从上层更直观的角度来理解：想象你正面对你的个人电脑，当你按下一个键盘按键时，你就触发了一个中断，随后屏幕上会出现你期望的字母；或者当你移动鼠标时，你也会触会一个中断，随后光标会随鼠标的移动而移动。严格意义上说，中断只是一个系统过程(系统调用过程如果抛开其核心处理函数的执行，也是一个系统过程)，是系统的一个部分，而不是一个完整系统，因为它不具备完整系统所应有的&lt;strong&gt;功能&lt;/strong&gt;、&lt;strong&gt;性能&lt;/strong&gt;、&lt;strong&gt;可靠性&lt;/strong&gt;、&lt;strong&gt;可扩展性&lt;/strong&gt;、&lt;strong&gt;安全性&lt;/strong&gt;、&lt;strong&gt;兼容性&lt;/strong&gt;、&lt;strong&gt;可维护性&lt;/strong&gt;等各方面的属性。比如，通过按动键盘，你以中断的方式向计算系统发送命令，但真正执行命令并返回结果的是计算机系统而不是按键动作本身。&lt;/p&gt;

&lt;h3 id=&quot;为什么需要中断&quot;&gt;为什么需要中断？&lt;/h3&gt;

&lt;p&gt;  计算机是个“死脑筋”，从打开电源键开始，就算你不向她发送任何指令，她也会按设定的程序开始忙禄，大多时候都在执行一个叫做IDEL的无聊程序。如何让她听命于你呢？两种方法，要么让她随时可被打断，去做你想让她做的事，随后再去干原来被打断的事；要么让她不停地一直问你想让她做什么，其它的事啥也不干，这样你一发话，她可以立刻响应你的命令。第一种方式，便是中断(interrupt)，第二种方式叫轮询(polling)。在大多数场景下，中断都是一种更为高效的(从完成任务数来看)通知方式，因为计算机干了更多有意义的事，而不是一直在“傻问”；轮询时，如果你想让计算机干得活不是很多，那么计算机大多数问询得到结果都是“谢谢，我不需要你做什么”，这就白白浪费了她的宝贵精力，但是每次你想让计算机做事时，她总是先主动地询问你，之后便立刻进入工作状态了，这比下达命令之后才慢吞吞开始行动的中断方式更为高效(从任务响应时间来看)。因此中断和轮询各有优点，各有各的适用场景：中断适用大多数设备通知场景，而在处理时延敏感场景下(如高性能网络转发)，轮询表现得更好。&lt;/p&gt;

&lt;h3 id=&quot;如何实现中断&quot;&gt;如何实现中断？&lt;/h3&gt;

&lt;p&gt;  下面我们深入系统内部，更细致地理解中断过程。前期的博文介绍过intel i440fx体系的基本组成，这里我们做些简化，只看和中断过程相关的几个部分，并按中断发生后的时序对中断过程作一个概括性的描述：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/i440fx/interrupt.jpg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;首先，我们可以看到在南桥芯片上集成了一个称为IOAPIC的部件，它共有24根中断引脚可以接收来自外部设备(如键盘、鼠标)的中断请求；当外设触发中断请求后，IOAPIC芯片会根据设备驱动初始化时设定的内容(一个内存地址Address和一个数据Data)向总线发送中断信息(将Data值写入Address地址代表的内存)，如图中绿色线条所示，直观地理解，&lt;strong&gt;这个Address指明了接收本次中断的具体CPU，而Data代表中断向量号(粗略地讲，可以认为这是不同中断相互区别的一个整数值，0~255)&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;其次，对于PCI设备而言，有两种中断触发方式：一种是通过intx中断引脚触发(最终通过IOAPIC发送中断信号，如图中虚线所示)；另一种是MSI/MSI-X方式(Message Signal Interrupt)，PCI设备通过驱动初始化时设定的内容直接向总线发送中断，如图中蓝线所示，其发送原理类似IOAPIC，由于外部设备中断过程并非本文讨论的重点，有兴趣的同学可以查阅PCI规范中相关内容来获得更深入的理解。&lt;/li&gt;
  &lt;li&gt;此外，CPU之间可以通过写ICR寄存器发送IPI(Inter Processors Interrupt)中断来进行核间通信，如图中粉色线条所示。&lt;/li&gt;
  &lt;li&gt;最后，每个CPU逻辑核都有一个称为LAPIC的子部件，它负责接收总线上的中断信息，当确认是发送给本地逻辑核时，便会引发本地CPU的中断过程：CPU会对保存当前正在执行任务的状态信息，之后会根据中断信息找到具体的中断处理逻辑函数；在完成中断处理函数后，CPU便会恢复先前保存的任务状态，继续处理原先的作务。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cpu如何处理中断&quot;&gt;CPU如何处理中断？&lt;/h3&gt;

&lt;p&gt;  介绍完系统内部整体的中断过程后，我们把焦点放到CPU上，更深入地从代码级别看看它是如何处理中断的。&lt;/p&gt;

&lt;h4 id=&quot;1硬件自动完成动作&quot;&gt;&lt;strong&gt;1､硬件自动完成动作&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  x86_64 CPU在中断发生时会执行一系列硬件动作，完成执行上下文的切换，这些都是硬件自动完成的，不受软件控制，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/i440fx/context_switch.jpg&quot; height=&quot;800&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;  图中上半部分表示中断发生前寄存器状态(这里以用户态上下文状态举例)：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CS(代码段寄存器)和rip(指令指针寄存器)指向了当前正在执行的用户态指令的位置(绿色线条所示)；&lt;/li&gt;
  &lt;li&gt;SS(堆栈段寄存器)和rsp(栈指针寄存器)指向了当前用户态堆栈的栈项位置；&lt;/li&gt;
  &lt;li&gt;rflags(标志寄存器)中的IF位为1，表示允许中断发生；&lt;/li&gt;
  &lt;li&gt;TR(Task Register)任务寄存器指向当前任务的任务状态段TSS(Task State Segment)，其中的rsp0域指向了内核态栈顶位置(内核特权级为0)；&lt;/li&gt;
  &lt;li&gt;IDTR(Interrupt Descriptor Table Register)指向了全局中断描述符表(Interrupt Descriptor Table)，表中共有256个中断描述符(Interrupt Descriptor)，每个描述符指向一个中断处理函数入口，中断描述符在表中的索引(下标)称为中断向量(Interrupt Vector)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  中断发生后(只能发生在指令边界，不能打断单条指令的执行)，寄存器状态将发生变化，如上图下半部分所示：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;对于运行在用户态的程序，中断发生后需要切换到内核态执行中断处理函数，出于安全的考虑，堆栈也需要切换到内核态(注意，每个进程在内核态都有一个独立的栈空间，3.10内核中有16K大小，栈项指针保存在TSS)；&lt;/li&gt;
  &lt;li&gt;切换到内核态栈后，CPU自动将用户态SS、rsp、rflags、CS、rip压入栈中(从上到下，栈顶在下，栈底在上)；&lt;/li&gt;
  &lt;li&gt;CPU根据中断向量，取出中断描述符表中对应的中断描述符，将CS:rip指向中断描述符中的函数入口地址；&lt;/li&gt;
  &lt;li&gt;对于类型为Interrupt Gate的中断描述符，rflags中的IF标置位将被清零，表示CPU此时开始不响应外部中断。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  细心的同学可能会问如果程序正好在执行系统调用进入内核态，那中断的硬件过程是怎样的？除了不用进行栈切换外，其它的过程和上面的一样，因为系统调用已经完成了栈切换的动作。&lt;/p&gt;

&lt;h4 id=&quot;2中断描述符表&quot;&gt;&lt;strong&gt;2､中断描述符表&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  硬件自动完成动作的最后是根据中断描述表中的内容找到中断处理函数入口，下面我们看看3.10内核里的中断描述符表的相关实现，其初始流程大致为start_kernel-&amp;gt;init_IRQ-&amp;gt;native_init_IRQ，其核心片断如下所示：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/irqinit.c:

void __init native_init_IRQ(void)
{
    int i;
    
    ...

    /*
     * Cover the whole vector space, no vector can escape
     * us. (some of these will be overridden and become
     * 'special' SMP interrupts)
     */
    i = FIRST_EXTERNAL_VECTOR;
    for_each_clear_bit_from(i, used_vectors, NR_VECTORS) {
        /* IA32_SYSCALL_VECTOR could be used in trap_init already. */
        set_intr_gate(i, interrupt[i - FIRST_EXTERNAL_VECTOR]);
    }

    ...

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  FIRST_EXTERNAL_VECTOR为32，NR_VECTOR为256，开头的这段注释的意思是说这里会给从32到256的所有中断向量注册处理函数，从下面的代码看出处理函数在全局数组interrupt中。那么就有两个问题：为什么从32开始？为什么一开始就能把中断处理函数全部注册好，此时驱动程序都没初始化，具体的中断处理逻辑难道不是在驱动代码中实现的吗？第一个问题比较好回答，其实0~31的向量是intel预留给&lt;strong&gt;异常&lt;/strong&gt;使用的，这是CPU用来处理内部问题的一种方式，如除零、缺页等等。第二个问题目前确实比较难回答，我们就带着这个问题看看interrupt数组的定义吧：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

/*
 * Build the entry stubs and pointer table with some assembler magic.
 * We pack 7 stubs into a single 32-byte chunk, which will fit in a
 * single cache line on all modern x86 implementations.
 */
    .section .init.rodata,&quot;a&quot;
ENTRY(interrupt)
    .section .entry.text
    .p2align 5
    .p2align CONFIG_X86_L1_CACHE_SHIFT
ENTRY(irq_entries_start)
vector=FIRST_EXTERNAL_VECTOR
.rept (NR_VECTORS-FIRST_EXTERNAL_VECTOR+6)/7
    .balign 32
    .rept	7
    .if vector &amp;lt; NR_VECTORS
1:	pushq_cfi $(~vector+0x80)	/* Note: always in signed byte range */
            .if ((vector-FIRST_EXTERNAL_VECTOR)%7) &amp;lt;&amp;gt; 6
    jmp 2f
            .endif
    .previous
    .quad 1b
    .section .entry.text
    vector=vector+1
    .endif
    .endr
2:	jmp common_interrupt
.endr
END(irq_entries_start)

.previous
END(interrupt)
.previous
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  这段汇编代码确实比较晦涩，它把32到256的中断按7个一组划成一个个大组，每个大组的内存占用空间大小在32个字节内，这样这些组块可以被CPU缓存到内部缓存中，以加速对这些内存的访问，显然这是一个性能优化手段。每个大组内包含了7个中断的桩(stub)函数和每个中断的处理函数入口地址，其内存结构如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/i440fx/array.jpg&quot; height=&quot;500&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;  每个中断处理函数的入口地址以XXX_表示，桩函数包含两条指令，一条push指令和一条jmp指令。前6个中断桩函数的jmp指令都会跳转到最后一个桩函数的jmp指令位置，而该指令最终跳转到common_interrupt位置处继续执行。在每个桩函数的最后(组内的最后一个桩函数是在jmp指令前)放置了当前处理函数的入口地址，最终这些地址会组成全局interrupt数组。&lt;/p&gt;

&lt;h4 id=&quot;3公共入口函数common_interrupt&quot;&gt;&lt;strong&gt;3､公共入口函数common_interrupt&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  从上节的介绍中可以看出，中断发生后，CPU会执行中断描述符表所指向的各个中断的桩函数(如上图中XXX_32表示32号向量所对应的中断处理函数入口)，而所有桩函数在将中断向量压入栈后(会做符号化处理)，最终会跳转到common_interrupt函数，这个函数就成了所有中断的公共入口：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

/*
 * Interrupt entry/exit.
 *
 * Interrupt entry points save only callee clobbered registers in fast path.
 *
 * Entry runs with interrupts off.
 */

/* 0(%rsp): ~(interrupt number) */
.macro interrupt func
    /* reserve pt_regs for scratch regs and rbp */
    subq $ORIG_RAX-RBP, %rsp
    SAVE_ARGS_IRQ
    call \func
.endm

/*
 * Interrupt entry/exit should be protected against kprobes
 */
.pushsection .kprobes.text, &quot;ax&quot;
/*
 * The interrupt stubs push (~vector+0x80) onto the stack and
 * then jump to common_interrupt.
 */
.p2align CONFIG_X86_L1_CACHE_SHIFT
common_interrupt:
    addq $-0x80,(%rsp)		/* Adjust vector to [-256,-1] range */
    interrupt do_IRQ
    /* 0(%rsp): old_rsp-ARGOFFSET */
ret_from_intr:
    ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  这里的interrupt代表一个宏，而不是之前讨论的interrupt全局数组。common_interrupt的工作过程就是将栈顶的向量号转化成负数(-256,-1)，然后通过SAVE_ARGS_IRQ宏保存必要的寄要器，最后调用C语言函数do_IRQ来处理中断。SAVE_ARGS_IRQ宏定义如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

/* save partial stack frame */
.macro SAVE_ARGS_IRQ
    cld
    /* start from rbp in pt_regs and jump over */
    movq_cfi rdi, (RDI-RBP)
    movq_cfi rsi, (RSI-RBP)
    movq_cfi rdx, (RDX-RBP)
    movq_cfi rcx, (RCX-RBP)
    movq_cfi rax, (RAX-RBP)
    movq_cfi  r8,  (R8-RBP)
    movq_cfi  r9,  (R9-RBP)
    movq_cfi r10, (R10-RBP)
    movq_cfi r11, (R11-RBP)

    /* Save rbp so that we can unwind from get_irq_regs() */
    movq_cfi rbp, 0

    /* Save previous stack value */
    movq %rsp, %rsi

    leaq -RBP(%rsp),%rdi	/* arg1 for handler */
    testl $3, CS-RBP(%rsi)
    je 1f
    SWAPGS
    /*
     * irq_count is used to check if a CPU is already on an interrupt stack
     * or not. While this is essentially redundant with preempt_count it is
     * a little cheaper to use a separate counter in the PDA (short of
     * moving irq_enter into assembly, which would be too much work)
     */
1:	incl PER_CPU_VAR(irq_count)
    cmovzq PER_CPU_VAR(irq_stack_ptr),%rsp

    /* Store previous stack value */
    pushq %rsi
    TRACE_IRQS_OFF
.endm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/include/asm/calling.h:

/*
 * 64-bit system call stack frame layout defines and helpers,
 * for assembly code:
 */

#define R15		  0
#define R14		  8
#define R13		 16
#define R12		 24
#define RBP		 32
#define RBX		 40

/* arguments: interrupts/non tracing syscalls only save up to here: */
#define R11		 48
#define R10		 56
#define R9		 64
#define R8		 72
#define RAX		 80
#define RCX		 88
#define RDX		 96
#define RSI		104
#define RDI		112
#define ORIG_RAX	120       /* + error_code */
/* end of arguments */

/* cpu exception frame or undefined in case of fast syscall: */
#define RIP		128
#define CS		136
#define EFLAGS		144
#define RSP		152
#define SS		160
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  为什么只保存rdi~r11寄存器？这就涉及gcc编译方面的知识了，对于一个C函数来说，调用者如果在rdi~r11寄存器中保存了有用的信息，那调用者就需要在执行该C函数的调用前保存这些寄存器，因为C函数执行的过程中有可能会修改这些寄存器且不对这些寄存器做保存；而对于rbx,rbp,r12-r15这些寄存器，调用者如果在其中保存了有用的信息，在C函数调用返回后，这些寄存器的值不会发生改变，因为如果C函数内部会使用这些寄存器，它会保存旧的值并在函数返回前恢复这些寄存器旧有的值。&lt;/p&gt;

&lt;p&gt;  终于来到了C语言函数do_IRQ:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/irq.c:

/*
 * do_IRQ handles all normal device IRQ's (the special
 * SMP cross-CPU interrupts have their own specific
 * handlers).
 */
unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
{
    struct pt_regs *old_regs = set_irq_regs(regs);

    /* high bit used in ret_from_ code  */
    unsigned vector = ~regs-&amp;gt;orig_ax;
    unsigned irq;

    irq_enter();
    exit_idle();

    irq = __this_cpu_read(vector_irq[vector]);

    if (!handle_irq(irq, regs)) {
        ...
    }

    irq_exit();

    set_irq_regs(old_regs);
    return 1;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  上述函数的参数regs对应寄存器rdi(可以回顾下x86_64寄存器传参规则)，它是在SAVE_ARGS_IRQ宏中赋值的，指向了栈顶保存的r15寄存器。我理解此时栈顶有可能并没有保存r15寄存器的值，就看do_IRQ函数汇编后需不需要使用r15，但是其实do_IRQ只需要通过regs找到偏移为orig_ax的值(保存了向量号)就行，并不会去访问regs-&amp;gt;r15，所以并不影响程序的正确性。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;do_IRQ函数先保存了旧的栈帧结构指针，并在函数返回前恢复了旧的栈帧结构指针(目前还不是太理解在x86中的作用)；&lt;/li&gt;
  &lt;li&gt;通过regs中的orig_ax取出中断向量号，这里会将负数再次转成正数；&lt;/li&gt;
  &lt;li&gt;执行irq_enter表明正式进入中断上下文，如将当前进程的preempt_count计数增加；exit_idle表明CPU将退出空闲状态，这里均不作展开；&lt;/li&gt;
  &lt;li&gt;通过percpu变量将中断向量转换成irq号，并根据irq号处理中断；&lt;/li&gt;
  &lt;li&gt;执行riq_exit表明退出中断上下文，并恢复旧的栈帖结构指针；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  这里最让人困惑的是&lt;strong&gt;irq&lt;/strong&gt;号，它和中断向量是什么关系？转化关系为什么又是percpu类型的？为了回答这些问题，我们的思路暂时切出中断发生后的过程，来了解一些中断管理类的概念和初始化动作。&lt;/p&gt;

&lt;p&gt;  smp系统出现之前，系统中不同的外部中断完全可以用中断向量来区分，但在smp系统中，CPU核数增加导致中断处理也变得复杂，每个CPU都可以处理不同的中断，如果还用全局性的中断向量来区分中断，所能表示的中断数目太少。那是否可以给每个CPU都设立独立的中断描述符表？不行，这样会大大增加内核实现的复杂性，它采用了一种变通的方式：所有外部中断通过irq号来区分，&lt;strong&gt;不同的中断(即不同的irq)可以使用相同的中断向量，只要这些中断被分配到不同的核上&lt;/strong&gt;，例如在我的系统中查看中断信息得到如下结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/i440fx/example.jpg&quot; height=&quot;680&quot; width=&quot;900&quot; /&gt;&lt;/p&gt;

&lt;p&gt;  第一列中的数字即代表中断irq号，如0号irq代表ISA总线上的全局PIT时钟中断；通常来说0-15号irq对应传统ISA中断；16—39号开始分配给IOAPIC(i440fx中只有一个IOAPIC，占用24个irq)；再往后的irq分配给MSI/MSI-X(i440fx中从16+24=40号开始)。上图中我们看不到系统给每个中断分配的中断向量，假设系统初始化时给irq 0分配了0号核的32号向量，给irq 1分配了1号核的32号向量，那么0号核的percpu数组vector_irq的32号元素就指向irq 0，而1号核的percpu数组vecotr_irq的32号元素指向irq 1，如此一来，虽然0号核和1号核收到的中断向量都是32，但是do_IRQ可以通过percpu的vector_irq找到不同的irq，并通handle_irq执行真正的中断处理逻辑。这就是percpu的vectro_irq的神奇作用，也回答了前篇所提出的&lt;strong&gt;为什么在驱动初始化前就可以给所有中断向量注册处理函数：&lt;/strong&gt;中断描述符表中所指的函数只是一个伪入口(即桩函数)，而非实际的处理函数；实际的处理函数是在驱动初始化时，在为设备申请了irq号之后，通过request_irq(irq, function…)注册给不同的irq的。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;这里还可以再思考一个问题：系统中最多可处理的中断是多少个？是256么？&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;  我们再切回中断的处理过程，在理解irq、中断向量、CPU核之间的关系后，可以看到handle_irq即是对每个中断进行实质性处理的核心函数，最终会调用request_irq函数注册的中断处理逻辑。下面我们就来分析一下handle_irq的实现逻辑。&lt;/p&gt;

&lt;h4 id=&quot;4中断处理逻辑handle_irq&quot;&gt;&lt;strong&gt;4､中断处理逻辑handle_irq&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  该函数整体逻辑比较简单：先将irq转换成&lt;code class=&quot;highlighter-rouge&quot;&gt;struct irq_desc&lt;/code&gt;结构，然后调用的generic_handle_irq_desc函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/irq_64.c:

bool handle_irq(unsigned irq, struct pt_regs *regs)
{
    struct irq_desc *desc;

    ...

    desc = irq_to_desc(irq);
    if (unlikely(!desc))
        return false;

    generic_handle_irq_desc(irq, desc);
    return true;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  irq_desc结构体将包含与中断相关的所有关键信息，内核中将所有中断的irq_desc结构组织成一棵树的结构：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;include/linux/irqdesc.h:

/**
 * struct irq_desc - interrupt descriptor
 * @irq_data:		per irq and chip data passed down to chip functions
 * @kstat_irqs:		irq stats per cpu
 * @handle_irq:		highlevel irq-events handler
 * @preflow_handler:	handler called before the flow handler (currently used by sparc)
 * @action:		the irq action chain
 * @status:		status information
 * @core_internal_state__do_not_mess_with_it: core internal status information
 * @depth:		disable-depth, for nested irq_disable() calls
 * @wake_depth:		enable depth, for multiple irq_set_irq_wake() callers
 * @irq_count:		stats field to detect stalled irqs
 * @last_unhandled:	aging timer for unhandled count
 * @irqs_unhandled:	stats field for spurious unhandled interrupts
 * @threads_handled:	stats field for deferred spurious detection of threaded handlers
 * @threads_handled_last: comparator field for deferred spurious detection of theraded handlers
 * @lock:		locking for SMP
 * @affinity_hint:	hint to user space for preferred irq affinity
 * @affinity_notify:	context for notification of affinity changes
 * @pending_mask:	pending rebalanced interrupts
 * @threads_oneshot:	bitfield to handle shared oneshot threads
 * @threads_active:	number of irqaction threads currently running
 * @wait_for_threads:	wait queue for sync_irq to wait for threaded handlers
 * @dir:		/proc/irq/ procfs entry
 * @name:		flow handler name for /proc/interrupts output
 */
struct irq_desc {
    struct irq_data		irq_data;
    unsigned int __percpu	*kstat_irqs;
    irq_flow_handler_t	handle_irq;

    struct irqaction	*action;	/* IRQ action list */
    unsigned int		status_use_accessors;
    unsigned int		core_internal_state__do_not_mess_with_it;
    unsigned int		depth;		/* nested irq disables */
    unsigned int		wake_depth;	/* nested wake enables */
    unsigned int		irq_count;	/* For detecting broken IRQs */
    unsigned long		last_unhandled;	/* Aging timer for unhandled count */
    unsigned int		irqs_unhandled;
    atomic_t		threads_handled;
    int			threads_handled_last;
    raw_spinlock_t		lock;
    struct cpumask		*percpu_enabled;
#ifdef CONFIG_SMP
    const struct cpumask	*affinity_hint;
    struct irq_affinity_notify *affinity_notify;
#ifdef CONFIG_GENERIC_PENDING_IRQ
    cpumask_var_t		pending_mask;
#endif
#endif
    unsigned long		threads_oneshot;
    atomic_t		threads_active;
    wait_queue_head_t       wait_for_threads;
#ifdef CONFIG_PROC_FS
    struct proc_dir_entry	*dir;
#endif
    int			parent_irq;
    struct module		*owner;
    const char		*name;
} ____cacheline_internodealigned_in_smp;

...

/*
 * Architectures call this to let the generic IRQ layer
 * handle an interrupt. If the descriptor is attached to an
 * irqchip-style controller then we call the -&amp;gt;handle_irq() handler,
 * and it calls __do_IRQ() if it's attached to an irqtype-style controller.
 */
static inline void generic_handle_irq_desc(unsigned int irq, struct irq_desc *desc)
{
    desc-&amp;gt;handle_irq(irq, desc);
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  对于上述代码片断，我不再多作解释，大家可以对照代码注释仔细理解。这里的generic_handle_irq_desc函数通过内联的方式会调用每个中断对应的handle_irq函数。可能很多同学会把这里的handle_irq理解成就是用户(驱动程序)通过request_irq注册的中断处理函数。其实不然，这里的handle_irq仍然是一段通用的中断处理逻辑，用来实现对不同中断模式的处理和中断流控功能。这些通用的处理函数主要有三类：handle_level_irq、handle_edge_irq、handle_fasteoi_irq。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kernel/irq/chip.c:

/**
 *	handle_level_irq - Level type irq handler
 *	@irq:	the interrupt number
 *	@desc:	the interrupt description structure for this irq
 *
 *	Level type interrupts are active as long as the hardware line has
 *	the active level. This may require to mask the interrupt and unmask
 *	it after the associated handler has acknowledged the device, so the
 *	interrupt line is back to inactive.
 */
void
handle_level_irq(unsigned int irq, struct irq_desc *desc)
{
    ...
}

/**
 *	handle_fasteoi_irq - irq handler for transparent controllers
 *	@irq:	the interrupt number
 *	@desc:	the interrupt description structure for this irq
 *
 *	Only a single callback will be issued to the chip: an -&amp;gt;eoi()
 *	call when the interrupt has been serviced. This enables support
 *	for modern forms of interrupt handlers, which handle the flow
 *	details in hardware, transparently.
 */
void
handle_fasteoi_irq(unsigned int irq, struct irq_desc *desc)
{
    ...
}

/**
 *	handle_edge_irq - edge type IRQ handler
 *	@irq:	the interrupt number
 *	@desc:	the interrupt description structure for this irq
 *
 *	Interrupt occures on the falling and/or rising edge of a hardware
 *	signal. The occurrence is latched into the irq controller hardware
 *	and must be acked in order to be reenabled. After the ack another
 *	interrupt can happen on the same source even before the first one
 *	is handled by the associated event handler. If this happens it
 *	might be necessary to disable (mask) the interrupt depending on the
 *	controller hardware. This requires to reenable the interrupt inside
 *	of the loop which handles the interrupts which have arrived while
 *	the handler was running. If all pending interrupts are handled, the
 *	loop is left.
 */
void
handle_edge_irq(unsigned int irq, struct irq_desc *desc)
{
    ...
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  这三类函数主要是针对不同物理电气特性的中断和中断控制器(如IO-APIC、支持MSI的PCI设备等)做不同的处理。有兴趣的同学可以结合intel IO-APIC说明和PCI规范来仔细理解里面的实现过程。&lt;/p&gt;

&lt;p&gt;  最后，这几类函数都会调用handle_irq_event，它会调用irq_desc中action的handler，这个函数指针，才是用户通过request_irq注册的中断处理函数。到这一步，才真正调用到实际的中断处理逻辑。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kernel/irq/handler.c:

irqreturn_t
handle_irq_event_percpu(struct irq_desc *desc, struct irqaction *action)
{
    irqreturn_t retval = IRQ_NONE;
    unsigned int flags = 0, irq = desc-&amp;gt;irq_data.irq;

    do {
        irqreturn_t res;

        res = action-&amp;gt;handler(irq, action-&amp;gt;dev_id);

        ...

        switch (res) {
        case IRQ_WAKE_THREAD:
            /*
             * Catch drivers which return WAKE_THREAD but
             * did not set up a thread function
             */
            if (unlikely(!action-&amp;gt;thread_fn)) {
                warn_no_thread(irq, action);
                break;
            }

            irq_wake_thread(desc, action);

            /* Fall through to add to randomness */
        case IRQ_HANDLED:
            flags |= action-&amp;gt;flags;
            break;

        default:
            break;
        }

        retval |= res;
        action = action-&amp;gt;next;
    } while (action);

    add_interrupt_randomness(irq, flags);

    if (!noirqdebug)
        note_interrupt(irq, desc, retval);
    return retval;
}

irqreturn_t handle_irq_event(struct irq_desc *desc)
{
    struct irqaction *action = desc-&amp;gt;action;
    irqreturn_t ret;

    desc-&amp;gt;istate &amp;amp;= ~IRQS_PENDING;
    irqd_set(&amp;amp;desc-&amp;gt;irq_data, IRQD_IRQ_INPROGRESS);
    raw_spin_unlock(&amp;amp;desc-&amp;gt;lock);

    ret = handle_irq_event_percpu(desc, action);

    raw_spin_lock(&amp;amp;desc-&amp;gt;lock);
    irqd_clear(&amp;amp;desc-&amp;gt;irq_data, IRQD_IRQ_INPROGRESS);
    return ret;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;5中断返回ret_from_intr&quot;&gt;&lt;strong&gt;5､中断返回ret_from_intr&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  当irq_desc的action处理完毕之后，中断处理过程将逐步返回到ret_from_intr：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

ret_from_intr:
    DISABLE_INTERRUPTS(CLBR_NONE)
    TRACE_IRQS_OFF
    decl PER_CPU_VAR(irq_count)

    /* Restore saved previous stack */
    popq %rsi
    leaq ARGOFFSET-RBP(%rsi), %rsp

exit_intr:
    GET_THREAD_INFO(%rcx)
    testl $3,CS-ARGOFFSET(%rsp)
    je retint_kernel

/* Interrupt came from user space */
/*
 * Has a correct top of stack, but a partial stack frame
 * %rcx: thread info. Interrupts off.
 */
retint_with_reschedule:
    movl $_TIF_WORK_MASK,%edi
retint_check:
    LOCKDEP_SYS_EXIT_IRQ
    movl TI_flags(%rcx),%edx
    andl %edi,%edx
    jnz  retint_careful

retint_swapgs:		/* return to user-space */
    /*
     * The iretq could re-enable interrupts:
     */
    DISABLE_INTERRUPTS(CLBR_ANY)
    TRACE_IRQS_IRETQ
    SWAPGS
    jmp restore_args

retint_restore_args:	/* return to kernel space */
    DISABLE_INTERRUPTS(CLBR_ANY)
    /*
     * The iretq could re-enable interrupts:
     */
    TRACE_IRQS_IRETQ
restore_args:
    RESTORE_ARGS 1,8,1

irq_return:
    INTERRUPT_RETURN
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  上述过程首先判断中断发生时是在用户态还是在内核态，&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果是在内核态，就跳转到retint_kernel执行，这里会根据内核是否打开抢占进行不同的处理：如果内核不可抢占，那就恢复寄存器后返回到被中断的上下文继续执行；如果是可抢占的，那就可以进行调度。&lt;/li&gt;
  &lt;li&gt;如果是在用户态，就进行调度及信号相关的判断和处理；处理完成并恢复寄存器后，便通过iretq指令返回被中断的上下文继续执行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  至此，CPU上中断处理的整个系统过程完美结束，这真是一个漫长的旅途:-&amp;gt;&lt;/p&gt;

&lt;h3 id=&quot;中断处理如何优化软中断&quot;&gt;中断处理如何优化？－软中断&lt;/h3&gt;

&lt;p&gt;  通过前文的分析，我们看到中断的处理过程已经比较复杂了，即便如此，系统工程师们仍努力在思考如何改进中断的处理。一个显著的问题就是，如果CPU每次都是等整个中断处理逻辑执行完毕之后再开始响应下一个中断，那后续中断处理的实时性就会受影响，而且长时间处于中断上下文也会影响时钟和任务调度。于是，内核工程师想了一个办法：把中断的处理分成两部分：一部分是立刻要做的(通常是和硬件相关的部分)，并且只有等这部分做完了才能响应下一个中断，这部分通常处理时间很短，我们称这部分为上半部；另一部分是可以晚些时候处理(偏上层逻辑的部分)，并且在处理这部分工作的时候是可以响应一下个中断的，这部分通常处理时间较长，我们称之为下半部。软中断就是下半部的一种实现方式，它大大提升了中断处理的实时性。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/03/中断/&quot;&gt;CPU中断处理&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 18 Mar 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/03/%E4%B8%AD%E6%96%AD/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/%E4%B8%AD%E6%96%AD/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>系统调用</title>
        <description>&lt;p&gt;  计算子系统的诸多功能大多是通过系统调用来实现的，而且对于应用程序员来说，函数调用可能再熟悉不过了，但是对于系统调用这类特殊的函数调用，可能就局限在使用层面，而不会过多地去做深入研究。因此，这篇博文就从系统调用的角度来深入理解计算子系统。&lt;/p&gt;

&lt;h3 id=&quot;什么是系统调用&quot;&gt;什么是系统调用？&lt;/h3&gt;

&lt;p&gt;  在计算子系统中，当CPU执行进程时，系统调用是经常发生的一个过程。它是操作系统内核为应用程序提供的一组功能接口(API)，通过这组接口应用程序可以实现一系列全局性的系统功能，如创建新的进程(进程是系统全局性的资源，受内核统一调度和管理)、访问文件系统(文件系统也是系统全局性资源，可供多个应用程序共同使用)、访问网络接口设备(网卡是系统全局性资源，同样可被多个应用程序共享)。抛开内部实现功能的核心逻辑，系统调用是一个产生系统权限变化的&lt;strong&gt;特殊系统过程&lt;/strong&gt;。站在上层用户的视角来说，当你打开一个文件、点开一个新的应用窗口或者发送一个网络消息时都会涉及到系统调用。&lt;/p&gt;

&lt;h3 id=&quot;为什么需要系统调用&quot;&gt;为什么需要系统调用？&lt;/h3&gt;

&lt;p&gt;  前期的博文在介绍计算系统时说过，通用计算系统的优点在于可通过软件的部署实现功能的不断扩展。这里就引入一系列问题：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;运行在同一个计算系统上的不同应用程序有时需要实现相同的功能，是否需要各自都实现一套代码？&lt;/li&gt;
  &lt;li&gt;系统性的功能该如何实现？&lt;/li&gt;
  &lt;li&gt;如果某一个应用程序恶意破坏系统资源状态，该如何做防护？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  对于不同应用程序需要实现相同功能的问题，大家可能都会想到通过&lt;strong&gt;函数库&lt;/strong&gt;的方式对相同功能进行抽取和复用，但这里需要注意一点：不同应用程序即便使用相同的库函数，函数内部所使用进程级全局对象在不同进程间是相互隔离的，并不会相互影响。&lt;/p&gt;

&lt;p&gt;  那么对于系统级的全局资源的操作该如何实现？比如两个应用进程都想访问存储设备，如果只是通过函数库的方式实现了对存储设备的访问功能，那么两个应用进程就有可能破环彼此在存储设备上的数据，因为两个进程逻辑上是隔离的，都认为自己是以独占的方式在使用存储设备。正是为了实现对系统全局资源的统一访问和操作，系统工程师们创造一个被所有进程所共享的代码空间和数据空间(这就是被我们被为&lt;strong&gt;内核&lt;/strong&gt;的东西)。内核不仅代码空间被所有进程所共享，而且任意进程修改了数据空间中的数据后，其它进程都可以感知到它的修改。这样所有涉及系统全局资源的操作都可以放到内核中来实现，因此内核是一个涵盖进程、内存、磁盘、网卡等全局资源操作的复杂软件系统。&lt;/p&gt;

&lt;p&gt;  内核既然如此重要，而又被所有进程所共同改变，如果有恶意进程刻意破坏内核怎么办？硬件工程师给出了他们的解决方案：将CPU的执行空间划分为不同的&lt;strong&gt;等级&lt;/strong&gt;(比如x86中共分0到3,四个等级)，内核被放在最高的等级、应用程序独有的代码和数据被放在比较低的等级(如何linux在x86中将内核放在0级，将应用代码和数据放在3级)，高级别的代码可以访问低级别的代码和数据，而低级别的代码不允计访问高级别的代码和数据；同时提供若干特殊指令允许特权级切换到指定的代码位置执行已设定好的代码功能，这些代码功能就是系统调用，是内核为应用程序提供的安全访问系统功能的函数入口。&lt;/p&gt;

&lt;h3 id=&quot;如何实现系统调用&quot;&gt;如何实现系统调用？&lt;/h3&gt;

&lt;p&gt;  下面我们将深入系统内部，从寄存器和指令过程的层次来理解整体系统调用过程。&lt;/p&gt;

&lt;p&gt;  以文件访问为例，首先从应用层开始，为实现对文件的读取操作，一个C语言应用程序通常是这样的：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;

int main()
{
    int fd = -1;
    char buff[1024] = {0};
    
    fd = open(&quot;XXX&quot;, O_RDWR); //执行打开文件的系统调用
    ...
    read(fd, buff, 1024); //执行读取文件的系统调用
    ...
    
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  C语言应用程序中的系统调用最终会由glibc库实现，在glibc库中这些系统调用是用汇编语言完成的(原因是涉及特殊的特权级切换指令的调用)。当然，我们也可以直接通过汇编指令来实现系统调用：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;

int main()
{
    int fd = -1;
    char buff[1024] = {0};

    //调用open系统调用，其系统调用号为2，第一个参数放在rdi寄存器中，代表打开的文件名
    //第二个参数放在rsi寄存器中，代表文件打开方式(这里以读写方式打开文件)

    asm(&quot;mov %2, %%rax;
         syscall;&quot;
        :&quot;=a&quot;(fd)
        :&quot;D&quot;(FILENAME), &quot;S&quot;(O_RDWR)
    );

    ...

    //调用read系统调用，其系统调用号为0，第一个参数rdi代表之前打开的文件句柄号
    //第二个参数rsi代表数据存储内存起始地址，第三个参数rdx代表读取的最大长度

    asm(&quot;mov %0, %%rax;
         syscall;&quot;
        :&quot;=a&quot;
        :&quot;D&quot;(fd), &quot;S&quot;(buff), &quot;d&quot;(1024)
    );
    ...

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  所有系统调用通过特权切换后都将跳转到相同的函数地址，因此为区别不同的系统调用功能，内核将所有的系统调用功能实现函数组成一个数组，并通过数组下标来索引具体的系统调用功能实现函数，这个下标就是系统调用号，如open系统调用的调用号为2，read系统调用的调用号为0。具体代码如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/syscalls/syscall_64.tbl:

#
# 64-bit system call numbers and entry vectors
#
# The format is:
# &amp;lt;number&amp;gt; &amp;lt;abi&amp;gt; &amp;lt;name&amp;gt; &amp;lt;entry point&amp;gt;
#
# The abi is &quot;common&quot;, &quot;64&quot; or &quot;x32&quot; for this file.
#
0	common	read			sys_read
1	common	write			sys_write
2	common	open			sys_open
3	common	close			sys_close
...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  有的读者可能对C语言内嵌汇编的语法不太熟悉(可参考有关内嵌AT&amp;amp;T汇编语法的学习资料)，这里再简要介绍下前面系统调用的指令过程：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;首先，将希望调用的系统调用功能的系统调用号放入rax寄存器中；&lt;/li&gt;
  &lt;li&gt;接着，通过给寄存器赋值来进行参数传递，最多可传递6个参数，依次为rdi、rsi、rdx、r10、r8、r9；&lt;/li&gt;
  &lt;li&gt;最后，执行syscall指令进行特权级切换和执行跳转；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  syscall指令是x86_64架构下引入的轻量级特权切换指令(相对于x86_32架构下的&lt;strong&gt;int 0x80&lt;/strong&gt;指令)，其主要功功能是：(1)将当前函数执行地址(rip寄存器的值)保存到rcx中；(2)将当前标志寄存器rflag的值保存到r11寄存器中；(3)通过修改rip跳转到MSR_LSTAR寄存器指向的内核函数入口；(4)根据MSR_SYSCALL_MASK寄存器修改rflag寄存器。可见相比x86_32架构，syscall指令执行的动作要少得多，因此它的执行速度更快。&lt;/p&gt;

&lt;p&gt;  至此我们终于要涉足内核了，那么系统调用入口函数是什么？答案就在内核启动过程中系统调用的初始化流程中：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/cpu/common.c:

void syscall_init(void)
{
    /*
     * LSTAR and STAR live in a bit strange symbiosis.
     * They both write to the same internal register. STAR allows to
     * set CS/DS but only a 32bit target. LSTAR sets the 64bit rip.
     */
    wrmsrl(MSR_STAR,  ((u64)__USER32_CS)&amp;lt;&amp;lt;48  | ((u64)__KERNEL_CS)&amp;lt;&amp;lt;32);
    wrmsrl(MSR_LSTAR, system_call);
    wrmsrl(MSR_CSTAR, ignore_sysret);
    
    ...

    /* Flags to clear on syscall */
    wrmsrl(MSR_SYSCALL_MASK,
        X86_EFLAGS_TF|X86_EFLAGS_DF|X86_EFLAGS_IF|
        X86_EFLAGS_IOPL|X86_EFLAGS_AC|X86_EFLAGS_NT);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  这段代码说明在linux-3.10系统中，执行syscall指令后，当前进程会切换到内核态并将开始执行system_call函数；同时rflag标志寄存器的中断标志位(X86_EFLAGS_IF)会清零，这使得当前CPU不会响应普通中断，即不会被普通中断打断执行逻辑(但会被不可屏蔽中断NMI打断)。下面我们就来看system_call函数的实现，该函数在linux-3.10/arch/x86/kernel/entry_64.S中，这是一段底层代码，因此是用汇编语言编写的，在正式分析函数功能前，建议大家先看看函数的注释：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

/*
 * System call entry. Up to 6 arguments in registers are supported.
 *
 * SYSCALL does not save anything on the stack and does not change the
 * stack pointer.  However, it does mask the flags register for us, so
 * CLD and CLAC are not needed.
 */

/*
 * Register setup:
 * rax  system call number
 * rdi  arg0
 * rcx  return address for syscall/sysret, C arg3
 * rsi  arg1
 * rdx  arg2
 * r10  arg3 	(--&amp;gt; moved to rcx for C)
 * r8   arg4
 * r9   arg5
 * r11  eflags for syscall/sysret, temporary for C
 * r12-r15,rbp,rbx saved by C code, not touched.
 *
 * Interrupts are off on entry.
 * Only called from user space.
 *
 * XXX	if we had a free scratch register we could save the RSP into the stack frame
 *      and report it properly in ps. Unfortunately we haven't.
 *
 * When user can change the frames always force IRET. That is because
 * it deals with uncanonical addresses better. SYSRET has trouble
 * with them due to bugs in both AMD and Intel CPUs.
 */

ENTRY(system_call)
    CFI_STARTPROC	simple
    CFI_SIGNAL_FRAME
    CFI_DEF_CFA	rsp,KERNEL_STACK_OFFSET
    CFI_REGISTER	rip,rcx
    /*CFI_REGISTER	rflags,r11*/
    SWAPGS_UNSAFE_STACK
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  从这里的注释中我们可以看出如下要点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;syscall指令不会在栈在保存中作何信息，也不会切换栈指针，即修改rsp寄存器；因此，熟悉x86_32架构下int 0x80系统调用原理的同学注意了，这里是不同的；&lt;/li&gt;
  &lt;li&gt;系统调用最多传递6个参数，依次放在rdi、rsi、rdx、r10、r8、r9寄存器中；这里有一个扩展的知识点，&lt;strong&gt;在x86_64下普通C语言函数也可以通过寄存器传参数的，前6个参数的顺序是rdi、rsi、rdx、rcx、r8、r9寄存器&lt;/strong&gt;，好奇的读者可能会问那系统调用的传参为何不跟普通C函数保持一致呢？回顾一下syscall指令的执行过程，大家可能就会发现此时rcx已经存放了系统调用结束后的返回地址，因此不能用来传参了；&lt;/li&gt;
  &lt;li&gt;进入system_call函数的时候，CPU是不响应外部中断的；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  system_call函数开始的几个CFI开头的宏和函数追踪相关，通过展开后是空的，因此不作关心。SWAPGS_UNSAFE_STACK用来切换gs寄存器，我们继续往下分析：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

GLOBAL(system_call_after_swapgs)

    movq	%rsp,PER_CPU_VAR(old_rsp)
    movq	PER_CPU_VAR(kernel_stack),%rsp
/*
 * No need to follow this irqs off/on section - it's straight
 * and short:
 */
    ENABLE_INTERRUPTS(CLBR_NONE)
    SAVE_ARGS 8,0
    movq  %rax,ORIG_RAX-ARGOFFSET(%rsp)
    movq  %rcx,RIP-ARGOFFSET(%rsp)
    CFI_REL_OFFSET rip,RIP-ARGOFFSET
    testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags+THREAD_INFO(%rsp,RIP-ARGOFFSET)
    jnz tracesys
system_call_fastpath:
#if __SYSCALL_MASK == ~0
    cmpq $__NR_syscall_max,%rax
#else
    andl $__SYSCALL_MASK,%eax
    cmpl $__NR_syscall_max,%eax
#endif
    ja badsys
    movq %r10,%rcx
    call *sys_call_table(,%rax,8)  # XXX:	 rip relative
    movq %rax,RAX-ARGOFFSET(%rsp)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  GLOBAL定义了一个全局函数system_call_after_swapgs，随后两条mov指令是在关中断的前提下执行的，因此不会被打断，它们的指令过程是：先将当前rsp寄存器(指向用户态栈空间)保存到内核中per cpu变量old_rsp中(即每个CPU访问不同的old_rsp变量)，接着将当前CPU的kernel_stack值(指向当前进程内核栈且预留了ss、rsp、rflags、cs、rip的40个字节的空间)赋给rsp寄存器，即完成了栈的切换。将栈指针切换到内核态之后，即完成了基本执行环境的准备，随后通过ENABLE_INTERRUPT宏(本质为执行sti指令)打开当前CPU的中断，后续的执行过程中CPU又可以响应外部中断了。接着SAVE_ARGS宏开始保存rdi到r11寄存器的值到栈中，其实现在linux-3.10/arch/x86/include/asm/calling.h中：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/include/asm/calling.h:

#define R15		  0
#define R14		  8
#define R13		 16
#define R12		 24
#define RBP		 32
#define RBX		 40

/* arguments: interrupts/non tracing syscalls only save up to here: */
#define R11		 48
#define R10		 56
#define R9		 64
#define R8		 72
#define RAX		 80
#define RCX		 88
#define RDX		 96
#define RSI		104
#define RDI		112
#define ORIG_RAX	120       /* + error_code */
/* end of arguments */

/* cpu exception frame or undefined in case of fast syscall: */
#define RIP		128
#define CS		136
#define EFLAGS		144
#define RSP		152
#define SS		160

#define ARGOFFSET	R11
#define SWFRAME		ORIG_RAX

.macro SAVE_ARGS addskip=0, save_rcx=1, save_r891011=1
    subq  $9*8+\addskip, %rsp
    CFI_ADJUST_CFA_OFFSET	9*8+\addskip
    movq_cfi rdi, 8*8
    movq_cfi rsi, 7*8
    movq_cfi rdx, 6*8

.if \save_rcx
    movq_cfi rcx, 5*8
.endif

    movq_cfi rax, 4*8

.if \save_r891011
    movq_cfi r8,  3*8
    movq_cfi r9,  2*8
    movq_cfi r10, 1*8
    movq_cfi r11, 0*8
.endif

.endm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  回到system_call主逻辑，保存完rdi到r11的寄存器和rax寄存器后，紧随的mov指令把rcx(前面讲过多次，此时rcx保存的是用户态返回地址)也保存到栈中。随后的一段逻辑用来判断是否需要对系统调用进行追踪及rax中的系统调用号是否超过设定的最大值__NR_syscall_max，如果无须追踪且系统调用号没有超过最大值，则通过call指令调用sys_call_table数组中由系统调用号索引的具体处理函数(如系统调用号为0，则调用sys_read函数)。当然，在调用sys_函数前需要将系统调用的第4个参数从r10中复制到rcx中，以确保sys_函数能获取正确的参数。当sys_函数调用完成后，rax将保存其返回值，这里也会将返回值压入栈中。到这步系统调用核心功能已经完成，但是在返回到用户空间前，内核还会做一些常规性的事务，如检查信号、检查当前进程是否需要被调度等，最后才是从栈中恢复之前保存的诸多寄存器、切换栈指针到用户态、通过sysret指令返回到用户空间(syscall的下一条指令)继续执行。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arch/x86/kernel/entry_64.S:

/*
* Syscall return path ending with SYSRET (fast path)
* Has incomplete stack frame and undefined top of stack.
*/
ret_from_sys_call:
    movl $_TIF_ALLWORK_MASK,%edi
    /* edi:	flagmask */
sysret_check:
    LOCKDEP_SYS_EXIT
    DISABLE_INTERRUPTS(CLBR_NONE)
    TRACE_IRQS_OFF
    movl TI_flags+THREAD_INFO(%rsp,RIP-ARGOFFSET),%edx
    andl %edi,%edx
    jnz  sysret_careful
    CFI_REMEMBER_STATE
/*
 * sysretq will re-enable interrupts:
 */
    TRACE_IRQS_ON
    movq RIP-ARGOFFSET(%rsp),%rcx
    CFI_REGISTER	rip,rcx
    RESTORE_ARGS 1,-ARG_SKIP,0
    /*CFI_REGISTER	rflags,r11*/
    movq	PER_CPU_VAR(old_rsp), %rsp
    USERGS_SYSRET64
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;  至此，linux-3.10内核在x86_64上完整系统调用过程中已分析完毕，过程中分析的部分内容涉及C函数编译和汇编，建议结合网上现有的一些资料来加深理解。enjoy hacking the system~&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/02/系统调用/&quot;&gt;系统调用&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 26 Feb 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/02/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>计算子系统-开篇与目录</title>
        <description>&lt;p&gt;  计算子系统是计算机内部最为复杂的系统，如&lt;a href=&quot;https://rootw.github.io/2017/02/计算机/&quot;&gt;计算机&lt;/a&gt;所述，它的系统过程包含应用和内核两部分，其中内核又包含了内存管理(地址转换、空间分配、空间回收等)、进程执行(完成数据计算、外设控制等核心功能，以及系统调用切换等系统过程)、进程管理(创建、替换、终止、调度、通信)、中断处理、内核同步等一系列功能。因此我们需要从不同的功能视角来观察和理解它们，才能形成更加全面的认识。因此后续博文将从内存管理、进程管理、系统调用、中断处理等多个方面来分析该系统，建议的阅读目录顺序如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://rootw.github.io/2017/08/地址映射/&quot;&gt;内存管理之一：地址映射&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://rootw.github.io/2017/02/系统调用/&quot;&gt;系统调用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  针对功能的深入分析，其实也是对计算子系统物理工作过程的深入理解。功能分析时，我们可以借助高级语言来表达分析过程(这里我们主要以C语言并结合linux 3.10内核来理解核心子系统的实现)。然而，当分析深入到一定程度时，高级语言可能无法细致地表达某些系统过程，此时我们就需要通过汇编语言(AT&amp;amp;T语法)来描述系统内部的寄存器及其操作过程。本质上来说，高级语言所描述的功能最终也是转化成汇编来实现的，因此掌握汇编语言是深入理解系统一个必不可少的技能。这里我们先对CPU内部寄存器及内存布局设计做一个总体描绘，它们的内部结构如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;/images/posts/i440fx/cpu_low_level.jpg&quot; height=&quot;550&quot; width=&quot;400&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  对于AT&amp;amp;T汇编语法和intel x86_64架构原理，网上应该有不少资源供大家学习，这里暂不作全面介绍，后续分析时如果涉及将会补充一些说明。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/02/计算子系统/&quot;&gt;计算子系统-开篇与目录&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 11 Feb 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/02/%E8%AE%A1%E7%AE%97%E5%AD%90%E7%B3%BB%E7%BB%9F/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/%E8%AE%A1%E7%AE%97%E5%AD%90%E7%B3%BB%E7%BB%9F/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
      <item>
        <title>计算机</title>
        <description>&lt;p&gt;  作为&lt;strong&gt;自顶向下分析计算机系统&lt;/strong&gt;的开篇，我们先抛开一些底层实现的细节，先从顶层理解什么是计算机？为什么我们需要它？然后再深入一层看看计算机内部整体的组成结构。&lt;/p&gt;

&lt;h3 id=&quot;什么是计算机&quot;&gt;什么是计算机？&lt;/h3&gt;

&lt;p&gt;  我们每个人都有个人电脑(PC, Personal Computer)，可以想象一下，你的电脑正在你的面前。首先，我们都知道通常它是由显示器、鼠标、键盘和主机组成的。当你按下电源键打开电脑后，如果你想在电脑中保存一些内容，你会把光标移动到word程序图标之上，并通过双击鼠标左键打开这个程序；之后你可以在程序的窗口中输入你想保存的东西，比如通过键盘输入”hello,world!”；接着通过菜单栏中的保存按钮你可以确认期望保存的文件位置，比如/root/hello.txt；如果一切顺利，那么当你再次打开这个文件的时候，你会看到里面的内容还是”hello,world!”。又或者你想借助电脑进行一些数值运算，这时你会打开计算器程序，在里面输入你想计算的算式，比如”1+1”；当前点击等号按钮时，你就会得到你想要的计算结果，比如这里就是2。再或者你想给远方的朋友发个问候，你只需要打开即时通信程序，选择你的好友之后，输入你想说的话，点击发送之后你的好友就会在他的电脑上看到你发送的消息。如果你想在工作的时候听听音乐，也未尝不可，你只需要打开音乐播放器后选择你想听的歌曲，当你回到工作程序时，你的电脑会保持工作程序和音乐播放器同时运行，两者不会有影响。当然，如果你和我一样，也是一个程序员的话，也可以完全不必受限于电脑中已有的程序：打开代码编辑器，输入你想要的代码，编译，运行，想要什么功能就有什么功能(简直就是上帝:-))。&lt;/p&gt;

&lt;p&gt;  上面这些既是大家所熟悉的使用场景，也涵盖了机算机的核心概念：从物理视角上看，它的结构包含输入输出设备和主机；它的使用过程是，首先使用者通过输入设备向主机传递命令和信息，接着主机基于内部状态并和输入信息，在命令的控制下可以计算出输出结果或改变内部状态，最后主机通过输出设备将计算结果或内部状态传递给使用者；从功能视角上看，它提供了以存储、计算、网络通信为基础的各种功能，这些功能不但可以并行化以提升效率，而且可以通过编程的方式组合扩展出更多丰富的功能。&lt;/p&gt;

&lt;h3 id=&quot;为什么需要计算机&quot;&gt;为什么需要计算机？&lt;/h3&gt;

&lt;p&gt;  计算机提供的存储、计算和网络功能就像七巧板一样，可以拼装出各色各样鲜活漂亮的图案，所以理论上，它可以满足人们所有的信息化需求(信息获取、状态改变)，取代大量的脑力劳动，成为人类最忠实的助手。通常它在需求的满足方式上有通用和专用两种：&lt;/p&gt;

&lt;p&gt;  通用计算机(例如我们的个人电脑)的优点在于它的灵活性，通过优化已有软件或部署新的软件，可以让已有系统更好地满足用户新的需求。但它也有缺点，通用系统需要采用通用的硬件设计和通用的操作系统内核，而通用的硬件设计针对特定功能无法将性能发挥到极致，同样通用的操作系统内核需要考虑应用软件之间的隔离性、安全性和兼容性，这就意味着系统软件的复杂性大大提高。专用计算机(例如网络交换机)则正好相反，它的优点在于系统性能高、软件复杂度低，缺点则在于功能不灵活，不易扩展。&lt;/p&gt;

&lt;p&gt;  因此，大型计算系统的设计中往往没有绝对的通用和绝对的专用，而是从用户对系统的述求出发，在通用和专用之间寻找一个平衡点：将性能要求不高的功能交给系统通用部分去完成，而将性能要求较高的功能卸载到专用硬件完成，通用和专用相互配合对外提供高效、灵活的功能。&lt;/p&gt;

&lt;h3 id=&quot;如何实现计算机&quot;&gt;如何实现计算机？&lt;/h3&gt;

&lt;p&gt;  在自项向下的分析方法中，每当我们深入一个系统(或一个部件)内部时，就会看到一些子系统，包括它们的结构和工作过程(回答子系统是什么)，以及它们相互之间是如何配合以完成系统整体功能的(回答为什么需要这个子系统)，这就是自顶向下方法的精髓所在。&lt;/p&gt;

&lt;p&gt;  对于计算机系统来说，这里我以intel x86架构下经典的i440fx系统为例来展示其内部组成，来看一幅我的手绘图：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;/images/posts/i440fx/i440fx.jpg&quot; height=&quot;400&quot; width=&quot;500&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  图中从上往下看，整个i440fx系统中的设备包含：CPU（图中画了两个逻辑核示意，每个CPU内部包含Memory Management Unit）、北桥（PMC, PCI and Memory Controller）、显卡（AGP）、内存、南桥（PIIX3, PCI IDE ISA Accelerator）、PCI插槽和设备（如网卡、存储Raid卡控制器等）。另外，i440fx属多核体系，其中断部分包含LAPIC（Local Advanced Programmable Interrupt Controller，每个逻辑CPU包含一个）和IOAPIC（Input/Output Advanced Programmable Interrupt Controller，集成在PIIX3南桥中）两部分。除了设备，系统中还包含连接设备的各类总线：FSB（Front Side Bus，连接CPU和北桥）、PCI总线（Peripheral Component Interconnect，连接南北桥和所有的PCI设备）、IDE总线（“Integrated Drive Electronics，连接南桥中IDE控制器和传统IDE硬盘）、USB（Universal Serial Bus，连接USB控制器和USB设备）、ISA总线（Industry Standard Architecture，连接南桥ISA控制器和传统ISA设备，如鼠标和键盘；传统ISA总线采用两片级联的8259A芯片作为中断控制器直连单核CPU的INTR引脚，在i440fx中为了兼容老的单核操作系统仍保留了该功能，但是现代多核操作系统已不使用8259A芯片，而采用IOAPIC进行中断通知，详细内容可参考后续中断相关博文）。&lt;/p&gt;

&lt;p&gt;  对于熟悉计算机系统原理的人来说，看到上面的图应该就能联想起计算机内部的工作原理了；可对于一般使用者或应用程序开发人员来说，对计算机内部探究较少，因此这里我们介绍一下最核心的几个部件：CPU(MMU)、内存、存储设备和网络设备。&lt;/p&gt;

&lt;p&gt;  我们通过命令控制计算机，命令在计算机内部是以程序的方式得以执行(运行的程序也称为进程)。每个程序包含一些函数和数据，这些函数通过操作数据实现各种功能。这样便引出了计算机内部两个重要的部件：&lt;strong&gt;CPU&lt;/strong&gt;和&lt;strong&gt;内存&lt;/strong&gt;：内存负责存储函数和数据；CPU则负责从内存中取出函数（指令），然后在指令的控制下完成数据读取、运算或数据写回等动作。&lt;/p&gt;

&lt;p&gt;  在多任务系统中，有关内存的使用似乎没有表面上看起来的那么简单。如果大家写过C语言应用程序，可以尝试问自己几个问题: main函数运行时被放置在内存什么位置？操作的变量在内存中的存储位置又是哪里？同时运行的程序是怎么保证不会相互影响的？也许这些问题会让你觉得有些难以回答，因为应用程序员可以认为每个程序都独占了从零地址开始的一大段连续内存，在这段空间内怎么放置变量和函数可以随心所欲。可是实际上，每个程序所见的只是个虚拟内存，由CPU内部的&lt;strong&gt;MMU(Memory Management Unit)&lt;/strong&gt;实现虚拟内存到物理内存的映射，并且MMU并非一开始就记录了所有地址的映射关系，如果CPU访问的地址在MMU中没有记录，就会引发CPU的缺页异常。缺页异常的发生迫使CPU执行一段被所有CPU共享的公共核心程序(我们称之为&lt;strong&gt;内核&lt;/strong&gt;)，内核在处理缺页异常时会为程序分配内存并更新MMU页表，处理完成后会返回程序重新执行，这样程序对内存的再次访问时就不会触发缺页异常。内核被所有程序所共享，它除了实现缺页处理等内存管理功能外，还负责进程创建、调度等进程管理功能，并以系统调用的方式为应用程序提供安全的系统服务和资源的统一访问。因此内核程序涵盖了CPU在执行应用程序之外的所有底层过程，对于计算机用户来说虽然并不直接感知，但它却为多任务并行系统的开发和系统资源统一使用带来了具大便利。&lt;/p&gt;

&lt;p&gt;  介绍完了CPU和内存，我们再来看看外部设备：&lt;strong&gt;存储设备&lt;/strong&gt;为CPU提供数据存取服务，如磁盘；&lt;strong&gt;网络设备&lt;/strong&gt;为CPU提供数据收发服务，如网卡。虽然存储设备和网络设备内部可能包含复杂的系统结构，但是它们和CPU之间通信总是通过总线和中断进行的。CPU将外设的访问接口视为内存(MMIO)或端口(PIO)，通过读写内存或端口完成命令和数据传递；外设则通过中断方式通知CPU特定事件的发生。&lt;/p&gt;

&lt;p&gt;  我们以使用word程序进行文档保存的场景来看看是计算机内部部件是如何协同工作的：移动鼠标并双击图标时，鼠标会将这此操作转换成事件并通过中断通知CPU；CPU进入中断处理逻辑捕获这些事件后交由SHELL程序(计算机开机后自动运行的服务程序，负责接收用户的输入、显示图形界面并运行相应的程序)进行解析；SHELL解析得知用户期望运行word程序，接着通过系统调用来创建一个新的进程(运行中的程序)；CPU在时钟的驱使下开始调度执行新创建的word进程，进程运行初期由于并未分配可用的内存会产生缺页异常；CPU在异常处理过程中为进程分配内存并进行地址映射，完成后便重新进行进程的执行(此时MMU可以正常进行地址转换)；该进程正常运行时首先会通知SHELL程序需要在显示器上生成一个新窗口并注册事件处理函数；新窗口产生后，word进程便可以捕获用户的输入；用户完成输入以后，点按保存按钮进行保存时SHELL再次通知word进程发生了保存事件，word进程便会执行事件处理函数通过系统存储接口向存储设备发起存储请求，word进程自身则进入睡眠状态；存储设备存储完成后，通过中断通知CPU，CPU便会唤醒word进程再次进入可编辑状态(注：实际的word程序不会以同步化方式等待IO操作，这里为了方便说明问题作了一些简化)。&lt;/p&gt;

&lt;p&gt;  由此可见，一个简单的使用场景，也需要计算机内部各部件协同工作才能完成：CPU(MMU)、内存等完成系统核心的资源管理和计算等功能，构成了计算子系统（也称核心子系统）；各类存储控制器完成数据的存取，构成了存储子系统；网卡设备完成网络消息的收发，构成了网络子系统；；存储子系统和网络子系统为核心子系统提供存储和通信服务。由此可见，不仅大型系统可区分计算、存储、网络三大子系统，就连基本的计算机单元内部，也可划分出计算、存储、网络三个部分。&lt;/p&gt;

&lt;p&gt;  在这篇博文里，暂不对计算机的各个子系统都进行全面的分析，后续将基于x86_64架构上的linux_3.10内核分篇对计算、存储和网络子系统分别进行分析，自上而下、层层深入。愿自己能有更多的时间学习、总结和分享，enjoy hacking the system~&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2017/02/计算机/&quot;&gt;计算机&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Feb 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/%E8%AE%A1%E7%AE%97%E6%9C%BA/</guid>
        
        <category>自顶向下分析计算机系统</category>
        
        
      </item>
    
  </channel>
</rss>
