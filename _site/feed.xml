<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>吴斌</title>
    <description>欢迎来到我的技术博客~</description>
    <link>http://rootw.github.io/</link>
    <atom:link href="http://rootw.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 09 Sep 2021 20:40:15 +0800</pubDate>
    <lastBuildDate>Thu, 09 Sep 2021 20:40:15 +0800</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>【firecracker】系统启动与epoll事件循环</title>
        <description>&lt;p&gt;  在分析完firecracker虚拟机中各个子系统的运行时原理和初始化流程后，最后我们整体分析一下firecracker的系统启动过程，并重点分析IO线程(fc_vmm)所采用的epoll事件循环框架。&lt;/p&gt;

&lt;p&gt;  回顾首文中介绍的firecracker进程的线程模型，下图展示了线程间的事件通知关系：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/thread_com.jpg&quot; height=&quot;155&quot; width=&quot;757&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  firecracker进程的主线程在启动完成后会成为API Server Thread，它通过进程间socket句柄与外部HTTP Client进行通信，接收外部程序发送的配置或控制命令(回顾一下使用方法)；API Server Thread收到外部命令后通过api_event_fd向IO Thread发送请求，由IO Thread完成实际的处理动作；当虚拟机正常启动后，IO Thread主要通过io_event_fd接受来自虚拟CPU的IO请求，并在完成IO请求后通过irq_fd通知CPU处理结果。&lt;/p&gt;

&lt;p&gt;  接下来，我们从main函数开始，逐步分析一下系统的启动过程。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/src/main.rs:

fn main() {
    …
    let shared_info = Arc::new(RwLock::new(InstanceInfo {      // InstanceInfo对象是主线程和fc_vmm线程之间的共享对象
                                                               //     Arc是Rust标准库提供的原子引用类型，跟踪多个线程对相同
                                                               //     对象的引用计数；RwLock是Rust标准库提供的读写锁                      
        state: InstanceState::Uninitialized,                                    
        id: instance_id,                                                        
        vmm_version: crate_version!().to_string(),                               
    }));                                                                        
    let mmds_info = MMDS.clone();                                               
    let (to_vmm, from_api) = channel();                        // 该channel对象用于在主线程和fc_vmm线程之间传递对象
                                                               //     to_vmm为发送端对象，在主线程中使用；from_api为接收
                                                               //     端，在fc_vmm线程中使用                    
    let server =                                                                
        ApiServer::new(mmds_info, shared_info.clone(), to_vmm) // 创建一个ApiServer对象，用于接收外部程序的HTTP请求
        .expect(&quot;Cannot create API server&quot;);

    let api_event_fd = server                                  // 申请一个event_fd，用于主线程和fc_vmm线程之间的事件通知
        .get_event_fd_clone()                                                   
        .expect(&quot;Cannot clone API eventFD.&quot;);                                   

    let _vmm_thread_handle =                                                    
        vmm::start_vmm_thread(                                 // 正式拉起fc_vmm线程，下文将进一步分析
            shared_info,
            api_event_fd,
            from_api,
            seccomp_level);

    match server.bind_and_run(                                 // 主线程开始作为API Server线程，监听socket请求
        bind_path, start_time_us,
        start_time_cpu_us, seccomp_level) {
        …                                                                      
    }                                                                           
}


firecracker/vmm/src/lib.rs:

pub fn start_vmm_thread(                                                        
    api_shared_info: Arc&amp;lt;RwLock&amp;lt;InstanceInfo&amp;gt;&amp;gt;,                                 
    api_event_fd: EventFd,                                                       
    from_api: Receiver&amp;lt;Box&amp;lt;VmmAction&amp;gt;&amp;gt;,                                         
    seccomp_level: u32,                                                         
    ) -&amp;gt; thread::JoinHandle&amp;lt;()&amp;gt; {                                                    
    thread::Builder::new()                                                      
        .name(&quot;fc_vmm&quot;.to_string())                                                           // 将新线程取名为fc_vmm                                     
        .spawn(move || {                                                                      // 创建新线程，参数为新线程入口函数(闭包)
            let mut vmm = Vmm::new(api_shared_info, api_event_fd, from_api, seccomp_level)    // 新线程首先创建全局Vmm对象
                .expect(&quot;Cannot create VMM&quot;);                                   
            match vmm.run_control() {                                                         // 进入epoll事件循环
                …                                                              
            }                                                                   
        })                                                                       
        .expect(&quot;VMM thread spawn failed.&quot;)                                     
}

struct Vmm {                                            // Vmm全局对象
    kvm: KvmContext,                                    // KVM操作上下文

    vm_config: VmConfig,                                // 虚拟机配置，如CPU数、内存大小等
    shared_info: Arc&amp;lt;RwLock&amp;lt;InstanceInfo&amp;gt;&amp;gt;,             // API Server线程与fc_vmm线程共享对象            

    // Guest VM core resources.                                                  
    guest_memory: Option&amp;lt;GuestMemory&amp;gt;,                  // 虚拟机内存对象              
    kernel_config: Option&amp;lt;KernelConfig&amp;gt;,                // 内核配置，如启动命令行参数     
    vcpus_handles: Vec&amp;lt;thread::JoinHandle&amp;lt;()&amp;gt;&amp;gt;,         // vCPU线程返回句柄数组            
    exit_evt: Option&amp;lt;EpollEvent&amp;lt;EventFd&amp;gt;&amp;gt;,              // 虚拟机退出事件eventfd        
    vm: Vm,                                             // 虚拟机对象

    // Guest VM devices.                                                        
    mmio_device_manager: Option&amp;lt;MMIODeviceManager&amp;gt;,     // mmio总线管理器                             
    legacy_device_manager: LegacyDeviceManager,         // legacy总线管理器                

    // Device configurations.                                                    
    block_device_configs: BlockDeviceConfigs,           // 后端存储块设备配置，供virtio-blk使用      
    network_interface_configs: NetworkInterfaceConfigs, // 后端网络接口配置，供virtio-net使用                   
    …                                    

    epoll_context: EpollContext,                        // epoll事件循环上下文

    // API resources.                                                           
    api_event: EpollEvent&amp;lt;EventFd&amp;gt;,                     // 接收API Server线程通知的eventfd
    from_api: Receiver&amp;lt;Box&amp;lt;VmmAction&amp;gt;&amp;gt;,                 // channel接收方，可接收来向API Server线程对象         
    …                                                       
}

impl Vmm {                                                                      
    fn new(                                                                      
        api_shared_info: Arc&amp;lt;RwLock&amp;lt;InstanceInfo&amp;gt;&amp;gt;,                             
        api_event_fd: EventFd,                                                  
        from_api: Receiver&amp;lt;Box&amp;lt;VmmAction&amp;gt;&amp;gt;,                                      
        seccomp_level: u32,                                                     
    ) -&amp;gt; Result&amp;lt;Self&amp;gt; {                                                         
        let mut epoll_context = EpollContext::new()?;                  // 初始化epoll上下文              
        let api_event = epoll_context                                           
            .add_event(api_event_fd, EpollDispatch::VmmActionRequest)  // 将api_event_fd添加到epoll上下，可监听该句柄          
            .expect(&quot;Cannot add API eventfd to epoll.&quot;);                                     

        let block_device_configs = BlockDeviceConfigs::new();          // 初始化存储配置对象           
        let kvm = KvmContext::new()?;                                  // 创建KVM上下文
        let vm = Vm::new(kvm.fd()).map_err(Error::Vm)?;                // 创建虚拟机对象

        Ok(Vmm {                                                                
            kvm,                                                                
            vm_config: VmConfig::default(),                                     
            shared_info: api_shared_info,                                       
            guest_memory: None,                                                 
            kernel_config: None,                                                 
            vcpus_handles: vec![],                                              
            exit_evt: None,                                                     
            vm,                                                                  
            mmio_device_manager: None,                                          
            legacy_device_manager: LegacyDeviceManager::new().map_err(Error::CreateLegacyDevice)?,
            block_device_configs,                                                
            network_interface_configs: NetworkInterfaceConfigs::new(),          
            …
            epoll_context,                                                      
            api_event,                                                           
            from_api,                                                           
            …                                                       
        })                                                                       
    } 

    fn run_control(&amp;amp;mut self) -&amp;gt; Result&amp;lt;()&amp;gt; {                                                       // 事件循环框架                                
        const EPOLL_EVENTS_LEN: usize = 100;                                     

        let mut events = vec![epoll::Event::new(epoll::Events::empty(), 0); EPOLL_EVENTS_LEN];      // 创建一个events数组，用于接收事件

        let epoll_raw_fd = self.epoll_context.epoll_raw_fd;                     

        'poll: loop {                                                                               // 循环入口                                                     
            let num_events = epoll::wait(epoll_raw_fd, -1, &amp;amp;mut events[..]).map_err(Error::Poll)?;  // 通过epoll获知已经发生的事件

            for event in events.iter().take(num_events) {                                           // 针对已经发生的事件依次进行处理                       
                let dispatch_idx = event.data as usize;                                             // 获知事件dispatch_idx，注册事件时传入                       
                let evset = match epoll::Events::from_bits(event.events) {                          // 获知具体事件，如POLLIN     
                    …                                                            
            };                                                               

            if let Some(dispatch_type) = self.epoll_context.dispatch_table[dispatch_idx] {          // 根据disptach_idx找到事件类型，注册时填入
                match dispatch_type {                                       
                    EpollDispatch::Exit =&amp;gt; {                                                        // 第一类别，退出；VCPU线程退出时产生
                        …               
                    }                                                       
                    EpollDispatch::Stdin =&amp;gt; {                                                       // 第二类型，标准输入；使能串口使注册，接
                                                                                                    // 收标准输入并作为虚拟机串口的输入                              
                        …                     
                    }                                                       
                    EpollDispatch::DeviceHandler(device_idx, device_token) =&amp;gt; {                     // 第三类型，virtio设备IO处理；VCPU通过io_event_fd产生     
                        match self                                          
                            .epoll_context                                  
                            .get_device_handler_by_handler_id(device_idx)                            // 首次处理时通过channel获取EpollHandler对象，回顾virtio
                        {                                                                            // 设备的activate流程
                            Ok(handler) =&amp;gt; match handler.handle_event(device_token, evset) {         // 调用EpollHandler对象的handle_event函数
                                …                                    
                            },                                              
                            …                                               
                        }                                                    
                    }                                               
                    EpollDispatch::VmmActionRequest =&amp;gt; {                                             // 第四类型，管理动作；来作API Server线程          
                        self.api_event.fd.read().map_err(Error::EventFd)?;  
                        self.run_vmm_action().unwrap_or_else(|_| {                                   // 调用run_vmm_action     
                            …
                        });                                                 
                    }                                                       
                    …                                                      
                }                                                           
            }                                                               
        }                                                                    
    }                                                                       
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  firecracker启动初期，fc_vmm线程仅对api_event_fd进行监听，即仅能对第四类型事件进行处理。回顾首篇对firecracker使用流程的介绍，我们通过curl工具对firecracker进行kernel、rootfs和虚拟机的配置后，最后通过InstanceStart命令启动虚拟机。这里的配置和启动命令最后都交由fc_vmm的run_vmm_action函数进行处理：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;
    fn run_vmm_action(&amp;amp;mut self) -&amp;gt; Result&amp;lt;()&amp;gt; {                                                             
        let request = match self.from_api.try_recv() {                                    // 从API Server线程接收用户请求                      
            …                                                                 
        };                                                                      

        match request {                                                                    // 根据用户请求类别分别进行处理                                                      
            VmmAction::ConfigureBootSource(boot_source_body, sender) =&amp;gt; {                  // 内核启动参数配置     
                Vmm::send_response(                                             
                    self.configure_boot_source(                                 
                        boot_source_body.kernel_image_path,                     
                        boot_source_body.boot_args,                             
                    ),                                                          
                    sender,                                                      
                ); 

            }                                                                   
            …                                                                
            VmmAction::InsertBlockDevice(block_device_config, sender) =&amp;gt; {                 // 配置存储块设备
                Vmm::send_response(self.insert_block_device(block_device_config), sender);
            }                                                                    
            VmmAction::InsertNetworkDevice(netif_body, sender) =&amp;gt; {                        // 配置网络接口设备
                Vmm::send_response(self.insert_net_device(netif_body), sender); 
            }                                                                    
            …                                                                 
            VmmAction::StartMicroVm(sender) =&amp;gt; {                                           // 配置完成后，启动一个虚拟机
                Vmm::send_response(self.start_microvm(), sender);               
            }                                                                                                                                    
            VmmAction::SetVmConfiguration(machine_config_body, sender) =&amp;gt; {                // 配置虚拟机CPU和内存等    
                Vmm::send_response(self.set_vm_configuration(machine_config_body), sender);
            }                                                                   
            …                                                                    
        };                                                                      
       Ok(())                                                                  
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  最后，我们来看一下firecracker虚拟机的启动过程，对各个子系统初始化进行一些串联：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;    fn start_microvm(&amp;amp;mut self) -&amp;gt; std::result::Result&amp;lt;VmmData, VmmActionError&amp;gt; {
        …         
        self.shared_info                                                                       
            .write()                                               // 对共享对象加写锁
            .expect(&quot;Failed to start microVM because shared info couldn't be written due to poisoned lock&quot;)
            .state = InstanceState::Starting;                      // 将虚拟机状态设为Starting，完成后自动解锁(Rust语言特性)

        self.init_guest_memory()?;                                 // 虚拟内存初始化，参考CPU与内存部分

        let vcpus;                                                              

        #[cfg(target_arch = &quot;x86_64&quot;)]                                          
        {                                                                       
            self.setup_interrupt_controller()?;                   // 中断控制器初始化，参考时钟与中断部分       
            self.attach_virtio_devices()?;                        // 添加virito-blk/net，内部将调用register_virtio_device，参考virtio设备部分
            self.attach_legacy_devices()?;                        // legacy设备初始化，参考legacy设备部分

            let entry_addr = self.load_kernel()?;                 // 加载ELF内核到entry_addr
            vcpus = self.create_vcpus(entry_addr, request_ts)?;   // 创建VCPU，参考CPU与内存部分             
        }
        …                                                               
        self.configure_system()?;                                 // 配置系统，主要是生成mptable和引导数据头部

        self.register_events()?;                                  // 向epoll事件循环注册退出事件和标准输入事件

        self.start_vcpus(vcpus)?;                                 // 启动虚拟CPU，参考CPU与内存部分                                               

        self.shared_info                                                         
            .write()                                              // 重新对共享对象加写锁
            .expect(&quot;Failed to start microVM because shared info couldn't be written due to poisoned lock&quot;)
            .state = InstanceState::Running;                      // 将虚拟机状态设为Running，代表虚拟机已正常运行!!!                                                                   
        …                                                                                                                                          
        Ok(VmmData::Empty)                                                      
    }                
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-startvm/&quot;&gt;【firecracker】系统启动与epoll事件循环&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 10 Sep 2019 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2019/09/firecracker-startvm/</link>
        <guid isPermaLink="true">http://rootw.github.io/2019/09/firecracker-startvm/</guid>
        
        <category>firecracker</category>
        
        
      </item>
    
      <item>
        <title>【firecracker】legacy设备</title>
        <description>&lt;p&gt;  除了virtio-mmio设备，firecracker还实现了串口、键盘等legacy设备，这些设备可以直接由虚拟机内核自带驱动程序驱动，并为虚拟机提供基本的输入输出功能。X86架构下，legacy设备主要通过IO端口进行控制和操作，因此firecracker采用IO总线来组织和管理所有的legacy设备。&lt;/p&gt;

&lt;h3 id=&quot;运行时原理&quot;&gt;运行时原理&lt;/h3&gt;

&lt;p&gt;  和mmio总线类似，legacy设备也以BTree形式组织于devices::Bus下，并且每个设备都需要实现BusDevice trait：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/legacy/i8042.rs:

pub struct I8042Device {                               // i8042为键盘对象
    …
}

impl BusDevice for I8042Device {                       // 实现端口读写操作                                  
    fn read(&amp;amp;mut self, offset: u64, data: &amp;amp;mut [u8]) {
        …
    }

    fn write(&amp;amp;mut self, offset: u64, data: &amp;amp;[u8]) {
        …
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/legacy/serial.rs:

pub struct Serial {                                    // 串口对象
    …
}

impl BusDevice for Serial {                            // 实现端口读写操作                                                  
    fn read(&amp;amp;mut self, offset: u64, data: &amp;amp;mut [u8]) {
        …
    }

    fn write(&amp;amp;mut self, offset: u64, data: &amp;amp;[u8]) {
        …
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  回顾前文分析CPU原理时介绍的内容，当虚拟CPU执行端口读写指令时(in/out指令)，会退出到用户态VMM程序进行处理，这里就是firecracker的vCPU线程上下文。此时vCPU线程就会根据端口地址在IO总线上搜索对应的legacy设备，并调用设备对端口的读写操作接口。具体设备的操作方法大家可以对照相关规范文档展开代码分析。&lt;/p&gt;

&lt;h3 id=&quot;初始化&quot;&gt;初始化&lt;/h3&gt;

&lt;p&gt;  firecracker使用LegacyDeviceManager来管理所有legacy设备，并通过其下register_devices方法来初始化legacy设备：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/vmm/src/lib.rs:
    fn attach_legacy_devices(&amp;amp;mut self) -&amp;gt; std::result::Result&amp;lt;(), StartMicrovmError&amp;gt; {            // legacy设备整体初始化函数
        self.legacy_device_manager                                                                 //  通过LegacyDeviceManager的register_devices来注册legacy设备                                           
            .register_devices()                                                      
            .map_err(StartMicrovmError::LegacyIOBus)?;                              

        self.vm                                                                      
            .get_fd()                                                               
            .register_irqfd(self.legacy_device_manager.com_evt_1_3.as_raw_fd(), 4)                 // 为串口对应的eventfd申请irqfd
            .map_err(|e| {                                                          
                StartMicrovmError::LegacyIOBus(device_manager::legacy::Error::EventFd(e))
            })?;                                                                    
        …                                                                     
        self.vm                                                                     
            .get_fd()                                                               
            .register_irqfd(self.legacy_device_manager.kbd_evt.as_raw_fd(), 1)                     // 为键盘对应的eventfd申请irqfd
            .map_err(|e| StartMicrovmError::LegacyIOBus(device_manager::legacy::Error::EventFd(e)))
}


firecracker/vmm/src/device_manager/legacy.rs:

pub struct LegacyDeviceManager {                           // 所有legacy设备管理器                                             
    pub io_bus: devices::Bus,                              // IO总线，以BTree组织legacy设备
    pub stdio_serial: Arc&amp;lt;Mutex&amp;lt;devices::legacy::Serial&amp;gt;&amp;gt;, // 串口对象 
    pub i8042: Arc&amp;lt;Mutex&amp;lt;devices::legacy::I8042Device&amp;gt;&amp;gt;,   // 键盘对象                     

    pub com_evt_1_3: EventFd,                              // 串口1、3对应的eventfd                                                 
    pub com_evt_2_4: EventFd,                              // 串口2、4对应的eventfd
    pub kbd_evt: EventFd,                                  // 键盘对应的eventfd
    pub stdin_handle: io::Stdin,                           // 标准输入
}

impl LegacyDeviceManager {
    …                                                            
    pub fn register_devices(&amp;amp;mut self) -&amp;gt; Result&amp;lt;()&amp;gt; {                          
        self.io_bus                                        // 将串口对象添加到端口地址0x3F8~0x3FF，
            .insert(self.stdio_serial.clone(), 0x3f8, 0x8) // 由规范定义               
            .map_err(Error::BusError)?;                                         
        …                                                              
        self.io_bus                                        // 将键盘对象添加到端口地址0x60~0x64 ，                                                     
            .insert(self.i8042.clone(), 0x060, 0x5)        // 由规范定义            
            .map_err(Error::BusError)?;    
        Ok(())                                                                  
    }                                                                           
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-legacy/&quot;&gt;【firecracker】legacy设备&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 09 Sep 2019 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2019/09/firecracker-legacy/</link>
        <guid isPermaLink="true">http://rootw.github.io/2019/09/firecracker-legacy/</guid>
        
        <category>firecracker</category>
        
        
      </item>
    
      <item>
        <title>【firecracker】virtio-mmio设备</title>
        <description>&lt;p&gt;  外部设备为CPU提供存储、网络等多种服务，是计算机系统中除运算功能之外最为重要的功能载体。CPU与外设之间通过某种协议传递命令和执行结果；virtio协议最初是为虚拟机外设而设计的IO协议，但是随着应用范围逐步扩展到物理机外设，virtio协议正朝着更适合物理机使用的方向而演进。&lt;/p&gt;

&lt;h3 id=&quot;virtio设备运行原理&quot;&gt;virtio设备运行原理&lt;/h3&gt;

&lt;h4 id=&quot;一抽象原理&quot;&gt;&lt;strong&gt;一、抽象原理&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  对于采用virtio协议进行通信的CPU和外设，其抽象原理如下图所示。CPU与外设可以共同访问内存(例如外设以DMA方式访问内存)；内存中存在一个称为环形队列(IO RING)的数据结构，根据存放对象不同，该队列可分成由IO请求组成的请求队列(Avail Queue)和由IO响应组成的响应队列(Used Queue)。一个IO的处理过程可以分成如下四步：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;第一步，应用程序下发IO时，CPU将IO请求放入环形结构(IO RING)的请求队列(Avail Queue)中并通知设备；&lt;/li&gt;
    &lt;li&gt;第二步，设备收到通知后从请求队列中取出IO请求并在内部进行实际处理；&lt;/li&gt;
    &lt;li&gt;第三步，设备将IO处理完成后，将结果作为IO响应放入响应队列(Used Queue)并以中断通知CPU；&lt;/li&gt;
    &lt;li&gt;第四步，CPU从响应队列中取出IO处理结果并返回给应用程序。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/io.png&quot; height=&quot;504&quot; width=&quot;327&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;二总线协议&quot;&gt;&lt;strong&gt;二、总线协议&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  virtio协议实现过程中，CPU与外设之间的通知机制以及外设访问内存方式由实际连接CPU与外设的总线协议决定，如下图所示。换句话说，virtio协议可以基于多种不同的总线协议来实现。虚拟化场景中，主要采用PCI总线协议和MMIO总线协议：采用PCI总线协议的virtio设备叫virtio-pci设备，它可以支持virtio设备的热插拔特性(基于PCI总线的设备热插拔机制)，并可应用于真实物理外设；采用mmio总线协议的virito设备叫virito-mmio设备，它完全是针对虚拟机设计的，是一种轻量的虚拟总线机制，支持快速设备发现，但是无法使用在真实物理外设中。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/bus.png&quot; height=&quot;399&quot; width=&quot;488&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;三队列结构与操作&quot;&gt;&lt;strong&gt;三、队列结构与操作&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  抛开总线协议所决定的通知机制及访存方式，virtio协议定义了明确的队列结构及操作流程。下面我们以virito-blk块设备为例来进一步分析。&lt;/p&gt;

&lt;p&gt;  virtio-blk是一种存储设备，CPU发起的IO请求包含操作类型(读或写)、起始扇区(一个扇区为512节节，是块设备的存储单位)、内存地址、访问长度；请求处理完成后返回的IO响应仅包含结果状态(成功或失败)。如下示例图中，系统产生了一个IO请求(an example of IO)，它在内存上的数据结构分为三个部分：Header，即请求头部，包含操作类型和起始扇区；Data，即数据区，包含地址和长度；Status，即结果状态。&lt;/p&gt;

&lt;p&gt;  virtio-blk设备使用一个环形队列结构(IO RING)，它由三段连续内存组成：Descriptor Table、Avail Queue和Used Queue：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Descriptor Table由固定长度(16字节)的Descriptor组成，其个数等于环形队列(IO RING)长度，其中每个Descriptor包含四个域：addr代表某段内存的起始地址，长度为8个字节；len代表某段内存的长度，本身占用4个字节(因此代表的内存段最大为4GB)；flags代表内存段读写属性等，长度为2个字节；next代表下一个内存段对应的Descpriptor在Descriptor Table中的索引，因此通过next字段可以将一个请求对应的多个内存段连接成链表。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Avail Queue由头部的flags和idx域及entry数组(entry代表数组元素)组成：flags与通知机制相关；idx代表最新放入IO请求的编号，从零开始单调递增，将其对队列长度取余即可得该IO请求在entry数组中的索引；entry数组元素用来存放IO请求占用的首个Descriptor在Descriptor Table中的索引，数组长度等于环形队列长度(不开启event_idx特性)。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Used Queue由头部的flags和idx域及entry数组(entry代表数组元素)组成：flags与通知机制相关；idx代表最新放入IO响应的编号，从零开始单调递增，将其对队列长度取余即可得该IO响应在entry数组中的索引；entry数组元素主要用来存放IO响应占用的首个Descriptor在Descriptor Table中的索引(还有一个len域，virtio-blk并不使用)， 数组长度等于环形队列长度(不开启event_idx特性)。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;环形队列结构(IO RING)被CPU和设备同见。仅CPU可见变量为free_head(空闲Descriptor链表头，初始时所有Descriptor通过next指针依次相连形成空闲链表)和last_used(当前已取的used元素位置)。仅设备可见变量为last_avail(当前已取的avail元素位置)。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;  针对示例图中的IO请求，处理流程分析如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;第一步，CPU放请求。由于示例IO请求在内存中由Header、Data和Status三段内存组成，因此要从Descriptor Table中申请三个空闲项，每项指向一段内存，并将三段内存连接成链表。这里假设我们申请到了前三个Descriptor(free_head更新为3，表示下一个空闲项从索引3开始，因为0、1、2已被占用)，那么会将第一个Descriptor的索引值0填入Aail Queue的第一个entry中，并将idx更新为1，代表放入1个请求；&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;第二步，设备取请求。设备收到通知后，通过比较设备内部的last_avail(初始为0)和Avail Queue中的idx(当前为1)判断是否有新的请求待处理(如果last_vail小于Avail Queue中的idx，则有新请求)。如果有，则取出请求(更新last_avail为1 )并以entry的值为索引从Descriptor Table中找到请求对应的所有Descriptor来获知完整的请求信息。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;第三步，设备放响应。设备完成IO处理后(包括更新Status内存段内容)，将已完成IO的Descriptor Table索引放入Used Queue对应的entry中，并将idx更新为1,代表放入1个响应；&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;第四步，CPU取响应。CPU收到中断后，通过比较内部的last_used(初始化0)和Used Queue中的idx(当前为1)判断是否有新的响应(逻辑类似Avail Queue)。如果有，则取出响应(更新last_used为1)并将Status中断的结果返回应用，最后将完成响应对应的三项Descriptor以链表方式插入到free_head头部。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/example.png&quot; height=&quot;624&quot; width=&quot;709&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;四virtio-mmio后端代码解析&quot;&gt;&lt;strong&gt;四、virtio-mmio后端代码解析&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  完成virtio队列结构和操作流程分析后，我们可以结合virtio-mmio后端代码来进一步加深理解。在收到前端CPU的通知后(后续讨论mmio总线时将分析该通知过程)，fc_vmm线程将对IO进行处理，核心处理函数为handle_event：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/virtio/block.rs:

impl EpollHandler for BlockEpollHandler {                                           // EpollHandler是代表Epoll事件循环框架中的事件处理方法的一个trait。
                                                                                    //     Traint是Rust语言中对相同行为进行抽象的一种方式，是一组公共函数的集合
    fn handle_event(                                                                // EpollHandler这个trait只定义了一个函数handle_event，实现对具体Epoll事件
                                                                                    //     的处理功能
        &amp;amp;mut self,
        device_event: DeviceEvent,                                                  // device_event代表事件类别，这里为QUEUE_AVAIL_EVENT，即对virtio的avail
                                                                                    //     queue中的请求进行处理；另一个类别为RATE_LIMITER_EVENT，与QoS限速有关，
                                                                                    //     这里暂不作讨论
        ...
    ) -&amp;gt; result::Result&amp;lt;(), DeviceError&amp;gt; {
        match device_event {

            QUEUE_AVAIL_EVENT =&amp;gt; {                                                  // 对avail queue进行处理
                ...
                if let Err(e) = self.queue_evt_read(){                              // self.queue_evt为向Epoll事件循环框架中注册的句柄，调用read函数读取句柄内容
                                                                                    //     后便可再次触发事件
                    ...
                } else if !self.rate_limiter.is_blocked() &amp;amp;&amp;amp; self.process_queue(0){ // self.rate_limiter.is_blocked()用来判定是否达到上限限制。如果没有超过上限，则
                                                                                    //     调用process_queue()对ID为0的virtio队列进行请求处理。firecracker实现的
                                                                                    //     virtio-blk只支持单队列，所以这里仅处理0号队列。process_queue的内部实现我
                                                                                    //     们将在下面分析，总的来说，该函数实现了virito抽象原理中描述的第二步和第三步
                    self.signal_used_queue()                                        // 向前端CPU发送中断通知
                } else {
                    Ok(())
                }
            }
            ...
        }
    }
}

pub struct BlockEpollHandler { // BlockEpollHandler结构包含virtio-blk后端和事件处理相关的所有对象和方法
    queue: Vec&amp;lt;Queue&amp;gt;,         //     virtio-blk设备包含的所有virtio队列，这里只有一个
    mem: GuestMemory,          //     虚拟机内存对象，已经映射到firecracker用户态空间，可直接访问
    disk_image: File,          //     virtio-blk设备对应的后端文件，实际的存储点
    disk_nsectors: u64,        //     virtio-blk设备大小，以扇区为单位
    ...
    interrupt_evt: EventFd,    //     virtio队列对应的irq_fd，用来触发中断通知前端虚拟CPU
    queue_evt: EventFd,        //     virtio队列对应的io_event_fd，虚拟CPU通过它通知fc_vmm线程有请求待处理
    ...
}

impl BlockEpollHandler {
    fn process_queue(&amp;amp;mut self, queue_index: usize) -&amp;gt; bool { // 实现virtio抽象原理中的第二步和第三步
        let queue = &amp;amp;mut self.queues(queue_index);            // queue代表queue_index索引的virtio队列
        let mut used_any = false;                             // used_any代表是否成功处理请求

        while let some(head) = queue.pop(&amp;amp;self.mem) {         // 第二步，取出IO请求；每个请求对应由三项Descriptor
                                                              //     组成的链表(DescriptorChain)，链表头部位于head中
            let len;
            match Request::parse(&amp;amp;head, &amp;amp;self.mem) {          // 由链表头部head开始，对请求进行解析，解析后获得完整
                                                              //     请求信息并将其保存到request对象中
                Ok(request) =&amp;gt; {
                    ...
                    let status = match request.execute(       // 根据request对象中的请求信息进行实际的IO处理，例如针对
                                                              //     读请求，将从后端文件中读取实际数据到内存指定位置中。
                                                              //     该函数为同步操作，当读/写操作完成后，结果才会返回到status中

                        &amp;amp;mut self.disk_image,
                        self.disk_nsectors,
                        &amp;amp;self.mem,
                        &amp;amp;self.disk_image_id,
                    ){
                        Ok(l) =&amp;gt; {
                            len = l;
                            VIRTIO_BLK_S_OK
                        }
                        ...
                    };
                    self.mem                                  // 将实际执行结果status填写到IO请求在虚拟机内存中的status字段
                        .write_obj_at_addr(status, request.status_addr)
                        .unwrap();
                }
                ...
            }
            queue.add_used(&amp;amp;self.mem, head.index, len);       // 第三步，放入IO响应
            used_any = true;                                  // used_any赋值为true，代表成功处理请求
        }

        used_any
    }

    fn signal_used_queue(&amp;amp;self) -&amp;gt; result::Result&amp;lt;(), DeviceError&amp;gt; { // 成功处理请求后以中断方式通知前端虚拟CPU
        ...
        self.interrupt_evt.write(1).map_err(...)                     // 通过写irq_fd借助KVM模块触发虚拟中断
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  我们继续深入看一下virtio队列结构相关代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/virtio/queue.rs:

pub struct Queue {                 // firecracker实现的virtio环形队列结构                                                            
    max_size: u16,                 // 设备提供的最大队列长度                                                          
    pub size: u16,                 // 前端驱动设置的最大队列长度，小于max_size                                                    
    pub ready: bool,               // 队列是否已经配置完成                                                             
    pub desc_table: GuestAddress,  // Descriptor Table段在虚拟机内存中的起始地址                                                                                                                                                            
    pub avail_ring: GuestAddress,  // Avail Queue段在虚拟机内存中的起始地址                                                                               
    pub used_ring: GuestAddress,   // Used Queue段在虚拟机内存中的起始地址                                            

    next_avail: Wrapping&amp;lt;u16&amp;gt;,     // 设备可见的last_avail值                                           
    next_used: Wrapping&amp;lt;u16&amp;gt;,      // 下一个将填入的used entry索引                                             
}

impl Queue {
    …
    pub fn pop&amp;lt;'a, 'b&amp;gt;(&amp;amp;'a mut self, mem: &amp;amp;'b GuestMemory) -&amp;gt; Option&amp;lt;DescriptorChain&amp;lt;'b&amp;gt;&amp;gt; {
        if self.len(mem) == 0 {                                                                 // len会计算Avail Queue的idx和last_avail的差值，
                                                                                                //     如果为零，代表没有待处理的请求
            return None;                                                        
        }
        let index_offset = 4 + 2 * (self.next_avail.0 % self.actual_size());                    // 计算last_avail指向的entry项在Avail Queue中的偏移                                                           
        let desc_index: u16 = mem                                                               // 根据偏移读取entry的内容，即请求对应的首个Descriptor索引
            .read_obj_from_addr(self.avail_ring.unchecked_add(usize::from(index_offset)))
            .unwrap();                                                          

        DescriptorChain::checked_new(mem, self.desc_table, self.actual_size(), desc_index).map( // 根据首个Descriptor索引找到完整的DescriptorChain
            |dc| {                                                              
                self.next_avail += Wrapping(1);                                                 // last_avail值递增                      
                dc                                                              
            },                                                                  
        )                                                                       
    }
    …
}          

pub struct DescriptorChain&amp;lt;'a&amp;gt; {  // 每个IO请求对应一个DescriptorChain，含多个Descriptor。
                                  //     结构定义中的'a为Rust语言针对引用使用的生命周期注解，用
                                  //     来显式声明引用变量指向对象的作用域范围。这里主要说明
                                  //     DescriptorChain对象的作用域应当大于或等于mem的作用域。                                          
    mem: &amp;amp;'a GuestMemory,         // 对虚拟机内存对象的引用                                          
    desc_table: GuestAddress,     // Descriptor Table在虚拟机内存中的起始地址                                       
    queue_size: u16,              // 队列长度                              
    ttl: u16,                     // chain链表长度                          
    pub index: u16,               // DescriptorChain中当前Descptor的索引，可通过next_descriptor()更新                                                     
    pub addr: GuestAddress,       // 当前Descriptor的addr字段                                                                                 
    pub len: u32,                 // 当前Descriptor的len字段                                                          
    pub flags: u16,               // 当前Descriptor的flags字段                                                                                     
    pub next: u16,                // 当前Descriptor的next字段                              
}

impl&amp;lt;'a&amp;gt; DescriptorChain&amp;lt;'a&amp;gt; {                                                   
    fn checked_new(                                                                   // 根据index索引创建一个新的DescriptorChain                               
        mem: &amp;amp;GuestMemory,                                                      
        desc_table: GuestAddress,                                               
        queue_size: u16,                                                        
        index: u16,                                                             
    ) -&amp;gt; Option&amp;lt;DescriptorChain&amp;gt; {                                              
        if index &amp;gt;= queue_size {                                                      // 如果索引值大于队列长度，说明索引值无效                                     
            return None;                                                        
        }                                                                       

        let desc_head = match mem.checked_offset(desc_table, (index as usize) * 16) { // 判断索引位置是否在有效的虚拟机内存区间内
            Some(a) =&amp;gt; a,                                                       
            None =&amp;gt; return None,                                                
        };                                                                       
        mem.checked_offset(desc_head, 16)?;                                           // 判断整个Descriptor(16字段)是否在有效的虚拟机内存区间内                                 

        let desc = match mem.read_obj_from_addr::&amp;lt;Descriptor&amp;gt;(desc_head) {            // 从内存中读取Descriptor内容    
            Ok(ret) =&amp;gt; ret,                                                     
            …                                                                   
        };                                                                      
        let chain = DescriptorChain {                                           
            mem,                                                                 
            desc_table,                                                         
            queue_size,                                                         
            ttl: queue_size,                                                    
            index,                                                              
            addr: GuestAddress(desc.addr as usize),                             
            len: desc.len,                                                      
            flags: desc.flags,                                                  
            next: desc.next,                                                    
         };                                                                      

        if chain.is_valid() {                                                   
            Some(chain)
        } else {                                                                
            None                                                                
        }                                                                       
    }
    …
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/virtio/block.rs:

struct Request {                // 该结构描述一个virtio-blk请求，可参考前面数据结构部分的介绍                                      
    request_type: RequestType,  // 请求类型，如读、写、flush等                                                
    sector: u64,                // 请求访问的起始扇区                                 
    data_addr: GuestAddress,    // 数据区在虚拟机内存中的起始地址                                               
    data_len: u32,              // 数据区的长度                                   
    status_addr: GuestAddress,  // 存放请求处理结果的status内存地址                                               
}

impl Request {                                                                  
    fn parse(avail_desc: &amp;amp;DescriptorChain, mem: &amp;amp;GuestMemory) -&amp;gt; result::Result&amp;lt;Request, Error&amp;gt; { // 从DescriptorChain中解析出完整的请求信息
        …                                                                                                                                            
        let mut req = Request {                                                 
            request_type: request_type(&amp;amp;mem, avail_desc.addr)?,                                   // 先从DescriptorChain的第一项即请求的head段中解析出操作类型               
            sector: sector(&amp;amp;mem, avail_desc.addr)?,                                               // 和访问起始扇区
            data_addr: GuestAddress(0),                                          
            data_len: 0,                                                        
            status_addr: GuestAddress(0),                                       
        };                                                                       

        let data_desc;                                                          
        let status_desc;                                                         
        let desc = avail_desc                                                                     // desc指向链表的第二个Descriptor                                                
            .next_descriptor()                                                   
            .ok_or(Error::DescriptorChainTooShort)?;                            

        if !desc.has_next() {                                                                     // 如果链表只有两项，
            status_desc = desc;                                                                   // 说明第二项是status段的Descriptor,
            // Only flush requests are allowed to skip the data descriptor.     
            if req.request_type != RequestType::Flush {                                           // 且请求类型为flush。该类型可以不带数据段  
                return Err(Error::DescriptorChainTooShort);                     
            }                                                                   
        } else {                                                                                  // 否则，
            data_desc = desc;                                                                     // 第二项desc代表数据段Descriptor，
            status_desc = data_desc                                                               // 下一项(即第三项)代表结果段Descriptor
                .next_descriptor()                                              
                .ok_or(Error::DescriptorChainTooShort)?;                         
            …                                                                 

            req.data_addr = data_desc.addr;                                                       // 将数据段Descriptor中的地址填入req中
            req.data_len = data_desc.len;                                                         // 将数据段Descriptor中的长度填入req中
        }                                                                       
        …                                                                                                                                          
        req.status_addr = status_desc.addr;                                                       // 将结果段Descriptor中的地址填入req中

        Ok(req)                                                                 
    }     

    fn execute&amp;lt;T: Seek + Read + Write&amp;gt;(                              // 处理请求                                      
        &amp;amp;self,                                                                  
        disk: &amp;amp;mut T,                                                           
        disk_nsectors: u64,                                                      
        mem: &amp;amp;GuestMemory,                                                      
        disk_id: &amp;amp;Vec&amp;lt;u8&amp;gt;,                                                      
    ) -&amp;gt; result::Result&amp;lt;u32, ExecuteError&amp;gt; {                                     
        …                                                                                                                                              
        disk.seek(SeekFrom::Start(self.sector &amp;lt;&amp;lt; SECTOR_SHIFT))      // 将文件偏移到请求指定的扇区位置
            .map_err(ExecuteError::Seek)?;                                      

        match self.request_type {                                               
            RequestType::In =&amp;gt; {                                     // 对于读请求，读取文件内容到指定内存位置                                        
                mem.read_to_memory(self.data_addr, disk, self.data_len as usize)
                   .map_err(ExecuteError::Read)?;                              
                …                                  
               return Ok(self.data_len);                                       
            }                                                                    
            RequestType::Out =&amp;gt; {                                    // 对于写请求，从指定内存处将数据写入到文件中
                mem.write_from_memory(self.data_addr, disk, self.data_len as usize)
                   .map_err(ExecuteError::Write)?;                             
                …                                
            }                                                                                                                                     
            …                                                                    
        };                                                                      
        Ok(0)                                                                   
    }                                                                            
}            
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;初始化流程与mmio总线机制&quot;&gt;初始化流程与mmio总线机制&lt;/h3&gt;

&lt;p&gt;  在讨论完virtio运行时原理后，我们再来分析一下初始化流程。它与virtio底层所采用的总线协议是强相关的，因此我们也会讨论总线机制的实现。整个初始化流程又可分为virtio设备自身初始化以及前端虚拟CPU与后端设备的协商过程两个部分。&lt;/p&gt;

&lt;h4 id=&quot;一设备自身初始化&quot;&gt;&lt;strong&gt;一、设备自身初始化&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  firecracker采用了一种针对虚拟化的简单总线协议-mmio作为实现virtio的基础。mmio总线预留了0xD000000~0xFFFFFFFF的地址空间作为所有mmio设备的配置空间，并使用5~15号irq作为所有mmio设备可使用的中断号；每个mmio设备通过虚拟机内核启动时的命令行参数来上报设备资源信息(如配置空间地址范围和使用的中断号)，这是一种静态的设备发现机制，它不像PCI设备的总线枚举机制那么灵活，因此不支持设备热插拔等高级特性。&lt;/p&gt;

&lt;p&gt;  firecracker中定义一个全局对象MMIODeviceManager来管理所有mmio设备，virtio-mmio设备的初始化通过register_virtio_device函数进行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;pub struct MMIODeviceManager {                                                     
    pub bus: devices::Bus,      // mmio总线对象，内部通过BTree来组织所有mmio设备对象                                         
    guest_mem: GuestMemory,     // 虚拟机内存对象                                               
    mmio_base: u64,             // mmio总线配空间起始地址，X86架构下为0xD0000000                                    
    irq: u32,                   // mmio总线中断资源起始编号，X86架构下为5                          
    last_irq: u32,              // mmio总线中断资源结束编号，X86架构下为15                             
    id_to_dev_info: HashMap&amp;lt;(DeviceType, String), MMIODeviceInfo&amp;gt;,  // 记录设备信息的哈希表            
}

impl MMIODeviceManager {                                                        
    …               
    pub fn register_virtio_device(                                                         // 注册一个新的virito-mmio设备                                      
        &amp;amp;mut self,                                                                         // MMIODeviceManager对象  
        vm: &amp;amp;VmFd,                                                                         // KVM虚拟机对象      
        device: Box&amp;lt;devices::virtio::VirtioDevice&amp;gt;,                                        // virtio设备对象，注意virtio设备对象是包含在virito-mmio对象中的                         
        cmdline: &amp;amp;mut kernel_cmdline::Cmdline,                                             // 虚拟机内核启动参数                             
        type_id: u32,                                                                      // virtio设备对象类别，例如TYPE_BLOCK代表virtio-blk设备
        device_id: &amp;amp;str,                                                                   // virtio设备对象ID     
    ) -&amp;gt; Result&amp;lt;u64&amp;gt; {                                                          
        …                                                                     
        let mmio_device = devices::virtio::MmioDevice::new(self.guest_mem.clone(), device) // 根据virtio设备对象创建virtio-mmio对象，后续将深入分析
            .map_err(Error::CreateMmioDevice)?;                                 
        for (i, queue_evt) in mmio_device.queue_evts().iter().enumerate() {                 // 为每个virtio队列向KVM内核注册io_event_fd，它是KVM向
                                                                                            //     用户态VMM程序提供的一种事件通知机制
            let io_addr = IoEventAddress::Mmio(                                                               
                self.mmio_base + u64::from(devices::virtio::NOTIFY_REG_OFFSET),             // self.mmio_base为分配给当前mmio设备的mmio配置空间的起
                                                                                            //     始地址。从起始位置偏移NOTIFY_REG_OFFSET是虚拟CPU
                                                                                            //     向后端的通知地址，真正通知过程中CPU会向该地址写入
                                                                                            //     队列号
            );                                                                  

            vm.register_ioevent(queue_evt.as_raw_fd(), &amp;amp;io_addr, i as u32)                  // 向KVM注册io_event_fd，传入队列eventfd、通知地址、写入
                                                                                            //     内容。当虚拟CPU向该地址写入确定内容时，KVM就触发
                                                                                            //     对eventfd的写操作，进而唤醒等待该eventfd的处理线程
                .map_err(Error::RegisterIoEvent)?;                              
        }                                                                       

        if let Some(interrupt_evt) = mmio_device.interrupt_evt() {  
            vm.register_irqfd(interrupt_evt.as_raw_fd(), self.irq)                          // 向KVM注册irqfd，这是反向由后端给前端CPU发送中断通知，
                .map_err(Error::RegisterIrqFd)?;                                            //     后端只需要往irqfd中写入数据，就会通过KVM向前端发中断
        }                                                                       

        self.bus                                                                            // 向mmio总线中添加当前mmio设备
            .insert(Arc::new(Mutex::new(mmio_device)), self.mmio_base, MMIO_LEN)            // 以配置空间作为BTree的Key索引，MMIO_LEN为4K
            .map_err(Error::BusError)?;                                         

        #[cfg(target_arch = &quot;x86_64&quot;)]                                          
        cmdline                                                                             // 向虚拟机内核启动命令行中插入字段，便于前端发现设备                                                                 
            .insert(                                                            
                &quot;virtio_mmio.device&quot;,                                                       // virtio_mmio.device代表virtio-mmio设备对象
                &amp;amp;format!(&quot;{}K@0x{:08x}:{}&quot;, MMIO_LEN / 1024, self.mmio_base, self.irq),     // 设备资源信息，例如第一个设备为&quot;4K@0xD0000000:5&quot;，
// 含议为配置空间从0xD0000000开始，长度4K，中断irq号为5
            )                                                                    
           .map_err(Error::Cmdline)?;                                          
        let ret = self.mmio_base;                                               

        self.id_to_dev_info.insert(                                                         // 向哈希表中记录当前设备信息       
            (DeviceType::Virtio(type_id), device_id.to_string()),               
            MMIODeviceInfo {                                                    
                addr: ret,                                                      
                len: MMIO_LEN,                                                  
                irq: self.irq,                                                  
            },                                                                  
        );                                                                      

        self.mmio_base += MMIO_LEN;                                                         // 将mmio_base加上4K，表明当前设备占用4K                                          
        self.irq += 1;                                                                      // 将中断irq号加1，表明当前设备占用1个irq

        Ok(ret)                                                                 
    }           
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  通过上述代码，我们看到MMIODeviceManager对象在注册设备过程中使用了几个核心概念：devices:;Bus、devices::virtio::VirtioDevice、 devices::virtio::MmioDevice。这些类型包含在firecracker的一个名为devices的子模块中，它是firecracker对设备模型概念的抽象与实现，下面我们深入分析一下该模块。&lt;/p&gt;

&lt;p&gt;  首先firecracker的设备模型中定义了总线和设备两个抽象概念，它们在Rust中的实现如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/bus.sr:

pub struct Bus {                                          // 总线下的设备以BTree组织                                                               
    devices: BTreeMap&amp;lt;BusRange, Arc&amp;lt;Mutex&amp;lt;BusDevice&amp;gt;&amp;gt;&amp;gt;,   // 以设备配置空间范围BusRange作为BTree的Key索引                     
}

impl Bus {                                                                                             
    pub fn new() -&amp;gt; Bus {                                                       
        Bus {                                                                   
            devices: BTreeMap::new(),                                            
        }                                                                       
    }

    pub fn insert(&amp;amp;mut self, device: Arc&amp;lt;Mutex&amp;lt;BusDevice&amp;gt;&amp;gt;, base: u64, len: u64) -&amp;gt; Result&amp;lt;()&amp;gt; {
        …
    }

    pub fn read(&amp;amp;self, addr: u64, data: &amp;amp;mut [u8]) -&amp;gt; bool {     // 对总线地址的读操作(通常由CPU发起，回顾前文对CPU运行时介绍)，             
        if let Some((offset, dev)) = self.get_device(addr) {     // 会转换成对总线上对就设备的读操作(使用相对偏移)        
            dev.lock()                                                           
                .expect(&quot;Failed to acquire device lock&quot;)                        
                .read(offset, data);                                            
            true                                                                 
        } else {                                                                
            false                                                               
        }                                                                        
    }                                                                           

    pub fn write(&amp;amp;self, addr: u64, data: &amp;amp;[u8]) -&amp;gt; bool {        // 对总线地址的写操作               
        if let Some((offset, dev)) = self.get_device(addr) {                    
            dev.lock()                                                          
                .expect(&quot;Failed to acquire device lock&quot;)                         
                .write(offset, data);                                           
            true                                                                
        } else {                                                                 
            false                                                               
        }                                                                       
    }                                                                           
}

pub trait BusDevice: AsAny + Send {                         // 总线上的设备被定义成一个trait，包括一组公共的操作                                               
    fn read(&amp;amp;mut self, offset: u64, data: &amp;amp;mut [u8]) {}     // 设备内的读操作，向上对接总线上的读操作                                                       
    fn write(&amp;amp;mut self, offset: u64, data: &amp;amp;[u8]) {}        // 设备内的写操作，向上对接总线上的写操作                                        
    fn interrupt(&amp;amp;self, irq_mask: u32) {}                   // 设备触发中断         
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  基于抽象的总线和设备概念，virtio-mmio设备是对设备概念的扩展，是一种具体的设备实现方式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/virtio/mmio.rs:

pub struct MmioDevice {                                                            
    device: Box&amp;lt;VirtioDevice&amp;gt;,            // 包含的virtio设备对象，该对象实现VirtioDevice这个trait                                                   
    device_activated: bool,               // 设备是否被激活，即完成与前端的握手                              
    …                                                
    queue_select: u32,                    // 队列选择器，代表当前要操作的队列                           
    …                                             
    interrupt_evt: Option&amp;lt;EventFd&amp;gt;,       // 中断eventfd，如前文述将传递给KVM作为irqfd                                     
    driver_status: u32,                   // 前端驱动状态                         
    …                                                         
    queues: Vec&amp;lt;Queue&amp;gt;,                   // 队列数组                               
    queue_evts: Vec&amp;lt;EventFd&amp;gt;,             // 队列eventfd数组，将传递给KVM作为io_event_fd                                   
    mem: Option&amp;lt;GuestMemory&amp;gt;,             // 虚拟机内存对象                                          
}

impl MmioDevice {                                                                               
    pub fn new(mem: GuestMemory, device: Box&amp;lt;VirtioDevice&amp;gt;) -&amp;gt; std::io::Result&amp;lt;MmioDevice&amp;gt; {
        let mut queue_evts = Vec::new();                                           
        for _ in device.queue_max_sizes().iter() {  // 根据virtio设备的队列数来生成队列eventfd数组                              
            queue_evts.push(EventFd::new()?)                                        
        }                                                                          
        let queues = device                         // 生成队列数组
            .queue_max_sizes()                                                      
            .iter()                                                                
            .map(|&amp;amp;s| Queue::new(s))                                               
            .collect();                                                             
        Ok(MmioDevice {                                                            
            device,                                                                
            device_activated: false,                                                
            …                                              
            queue_select: 0,                                                    
            …                  
            interrupt_evt: Some(EventFd::new()?),                                
            driver_status: DEVICE_INIT,                                         
            …                                                
            queues,                                                             
            queue_evts,                                                         
            mem: Some(mem),                                                     
        })                                                                      
    } 
}

impl BusDevice for MmioDevice {                        // MmioDevice作为BusDevice的扩展，内部实现了对virtio的操作
                                                       // 我们将在下节前后端协商部分分析这部分内容                                    
    fn read(&amp;amp;mut self, offset: u64, data: &amp;amp;mut [u8]) {
        …
    }
    fn write(&amp;amp;mut self, offset: u64, data: &amp;amp;[u8]) {
        …
    }
    fn interrupt(&amp;amp;self, irq_mask: u32) {
        …
    }
}

pub trait VirtioDevice: Send {  // VirtioDevice定义了所有virtio设备都需要实现的公共接口，
                                // 请参考接口上方的描述文档                                              
    /// The virtio device type.                                                  
    fn device_type(&amp;amp;self) -&amp;gt; u32;                                               

    /// The maximum size of each queue that this device supports.               
    fn queue_max_sizes(&amp;amp;self) -&amp;gt; &amp;amp;[u16];                                        

    /// The set of feature bits shifted by `page * 32`.                         
    fn features(&amp;amp;self, page: u32) -&amp;gt; u32 {                                      
        let _ = page;                                                           
        0                                                                        
    }                                                                           

    /// Acknowledges that this set of features should be enabled.                
    fn ack_features(&amp;amp;mut self, page: u32, value: u32);                          

    /// Reads this device configuration space at `offset`.                      
    fn read_config(&amp;amp;self, offset: u64, data: &amp;amp;mut [u8]);                        

    /// Writes to this device configuration space at `offset`.                  
    fn write_config(&amp;amp;mut self, offset: u64, data: &amp;amp;[u8]);                       

    /// Activates this device for real usage.                                   
    fn activate(                                                                 
        &amp;amp;mut self,                                                              
        mem: GuestMemory,                                                       
        interrupt_evt: EventFd,                                                  
        status: Arc&amp;lt;AtomicUsize&amp;gt;,                                               
        queues: Vec&amp;lt;Queue&amp;gt;,                                                     
        queue_evts: Vec&amp;lt;EventFd&amp;gt;,                                                
    ) -&amp;gt; ActivateResult;                                                        

    /// Optionally deactivates this device and returns ownership of the guest memory map, interrupt
    /// event, and queue events.                                                
    fn reset(&amp;amp;mut self) -&amp;gt; Option&amp;lt;(EventFd, Vec&amp;lt;EventFd&amp;gt;)&amp;gt; {                    
        None                                                                     
    }                                                                           
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  virtio-blk设备作一virito设备的一种类型，它将扩展VirtioDevice，并实现VritioDevice定义的接口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/virtio/block.rs:

pub struct Block {                       // virtio-blk设备                                                                                            
    disk_image: Option&amp;lt;File&amp;gt;,            // 后端文件                                                                             
    disk_nsectors: u64,                  // 块设备大小                                                                       
    …                                                                                     
    config_space: Vec&amp;lt;u8&amp;gt;,               // blk配置空间，对前端呈现块设备大小、队列数等                                                                          
    epoll_config: EpollConfig,           // 向epoll事件循环框架传递处理对象                                                                         
    …                                                                          
}

impl VirtioDevice for Block {            // 实现VirtioDevice定义的公共接口，这里仅举了两个例子                                          
    fn device_type(&amp;amp;self) -&amp;gt; u32 {       // 返回设备类型为TYPE_BLOCK                                            
     TYPE_BLOCK                                                              
    }                                                                           

    fn queue_max_sizes(&amp;amp;self) -&amp;gt; &amp;amp;[u16] { //返回每个队列最大长度，这里只有一个队列且长度为256                                      
        QUEUE_SIZES                                                             
    }
    …
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;二前后端协商握手&quot;&gt;&lt;strong&gt;二、前后端协商(握手)&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  上节讲述了firecracker后端如何初始化一个virtio-mmio设备，本节将讨论前后端的协商流程。&lt;/p&gt;

&lt;p&gt;  虚拟机内部系统通过内核命令行参数识别virtio-mmio设备并调用对应的驱动函数对设备进行驱动。通过命令行参数(如virtio-mmio.device 4K@0xD0000000:5)，前端系统可知配置空间地址范围(如0xD0000000~0xD0000FFF)和中断资源(如irq为5)，接着便可以通过读写配置空间与设备进行协商操作。Virtio-mmio设备的配置空间概览如下：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/config.png&quot; height=&quot;694&quot; width=&quot;259&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  前端通过配置空间中的DEVICE ID可以获知具体的设备类别(例如virtio-blk的ID为2)，并通过DEVICE FEATURE和DRIVER FEATURE与后端进行特性协商。此后最为重要的动作便是为VIRTIO环形队列申请内存，并将内存地址填入到配置空间相应字段中。最后向DEVICE STATUS中写入DRIVER OK告诉后端驱动初始化完成。&lt;/p&gt;

&lt;p&gt;  回顾前文对虚拟CPU原理的介绍，当CPU读写MMIO地址空间时将从Guest模式退出到firecracker中并调用mmio总线的读写函数进行处理。接着mmio总线的读写操作将转到地址对应的mmio设备中进行读写，我们深入代码来看一下mmio设备的读写操作：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/virtio/mmio.rs:

impl BusDevice for MmioDevice {       
    fn read(&amp;amp;mut self, offset: u64, data: &amp;amp;mut [u8]) {  // 大家可以对照上面的配置空间解析图来理解代码的含义                                                   
        match offset {                                                                                          
            0x00...0xff if data.len() == 4 =&amp;gt; {                                                                
                let v = match offset {                                                                         
                    0x0 =&amp;gt; MMIO_MAGIC_VALUE,                                                                   
                    0x04 =&amp;gt; MMIO_VERSION,                                       
                    0x08 =&amp;gt; self.device.device_type(),                          
                    0x0c =&amp;gt; VENDOR_ID, // vendor id                                                            
                    0x10 =&amp;gt; {                                                   
                        let mut features = self.device.features(self.features_select);                         
                        if self.features_select == 1 {                          
                            features |= 0x1; // enable support of VirtIO Version 1                              
                        }                                                                                      
                        features                                                                               
                    }                                                           
                    0x34 =&amp;gt; self.with_queue(0, |q| u32::from(q.get_max_size())),
                    0x44 =&amp;gt; self.with_queue(0, |q| q.ready as u32),             
                    0x60 =&amp;gt; self.interrupt_status.load(Ordering::SeqCst) as u32,                               
                    0x70 =&amp;gt; self.driver_status,                                 
                    0xfc =&amp;gt; self.config_generation,                                                             
                    _ =&amp;gt; {                                                      
                        …                                                                               
                    }                                                                                           
                };                                                                                             
               LittleEndian::write_u32(data, v);                                                               
            }                                                                   
            0x100...0xfff =&amp;gt; self.device.read_config(offset - 0x100, data),                                    
            _ =&amp;gt; {                                                                                              
                …                                                                                           
            }                                                                                                   
        };                                                                                                     
    }       

    fn write(&amp;amp;mut self, offset: u64, data: &amp;amp;[u8]) {                              
        fn hi(v: &amp;amp;mut GuestAddress, x: u32) {                                   
            *v = (*v &amp;amp; 0xffff_ffff) | (u64::from(x) &amp;lt;&amp;lt; 32)                      
        }                                                                        

        fn lo(v: &amp;amp;mut GuestAddress, x: u32) {                                   
            *v = (*v &amp;amp; !0xffff_ffff) | u64::from(x)                             
        }                                                                       

        match offset {                                                          
            0x00...0xff if data.len() == 4 =&amp;gt; {                                 
                let v = LittleEndian::read_u32(data);                           
                match offset {                                                  
                    0x14 =&amp;gt; self.features_select = v,                           
                    0x20 =&amp;gt; {                                                   
                        if self                                                 
                            .check_driver_status(DEVICE_DRIVER, DEVICE_FEATURES_OK | DEVICE_FAILED)
                        {                                                       
                            self.device.ack_features(self.acked_features_select, v);
                        } else {                                                
                            …                                                   
                            return;                                             
                        }                                                        
                    }                                                           
                    0x24 =&amp;gt; self.acked_features_select = v,                     
                    0x30 =&amp;gt; self.queue_select = v,                              
                    0x38 =&amp;gt; self.update_queue_field(|q| q.size = v as u16),     
                    0x44 =&amp;gt; self.update_queue_field(|q| q.ready = v == 1),      
                    0x64 =&amp;gt; {                                                    
                        if self.check_driver_status(DEVICE_DRIVER_OK, 0) {      
                            self.interrupt_status                               
                               .fetch_and(!(v as usize), Ordering::SeqCst);    
                        }                                                       
                    }                                                           
                    0x70 =&amp;gt; self.update_driver_status(v),                          // 更新设备状态，需要进一步打开                  
                    0x80 =&amp;gt; self.update_queue_field(|q| lo(&amp;amp;mut q.desc_table, v)),
                    0x84 =&amp;gt; self.update_queue_field(|q| hi(&amp;amp;mut q.desc_table, v)),
                    0x90 =&amp;gt; self.update_queue_field(|q| lo(&amp;amp;mut q.avail_ring, v)),
                    0x94 =&amp;gt; self.update_queue_field(|q| hi(&amp;amp;mut q.avail_ring, v)),
                    0xa0 =&amp;gt; self.update_queue_field(|q| lo(&amp;amp;mut q.used_ring, v)),
                    0xa4 =&amp;gt; self.update_queue_field(|q| hi(&amp;amp;mut q.used_ring, v)),
                    _ =&amp;gt; {                                                      
                        …
                        return;                                                 
                    }                                                           
                }                                                               
            }                                                                   
            0x100...0xfff =&amp;gt; {                                                  
                if self.check_driver_status(DEVICE_DRIVER, DEVICE_FAILED) {     
                    self.device.write_config(offset - 0x100, data)              
                } else {                                                         
                    …
                    return;                                                     
                }                                                               
            }                                                                    
            _ =&amp;gt; {                                                              
                …                                                               
                return;                                                          
            }                                                                   
        }                                                                       
    } 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  当前端更新设备状态为DRIVER OK时，后端将配合执行设备激活动作，下面仍以virito-blk为例进行分析：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/virtio/mmio.rs:

    fn update_driver_status(&amp;amp;mut self, v: u32) {                                                                                 
        match !self.driver_status &amp;amp; v {                                          
            …                                                                
            DEVICE_DRIVER_OK                                                    
            if self.driver_status                                            
            == (DEVICE_ACKNOWLEDGE | DEVICE_DRIVER | DEVICE_FEATURES_OK) =&amp;gt;
            {                                                                   
                self.driver_status = v;                                          
                if !self.device_activated &amp;amp;&amp;amp; self.are_queues_valid() {          
                    if let Some(ref interrupt_evt) = self.interrupt_evt {       
                        if let Some(mem) = self.mem.take() {                     
                            self.device                                         
                                .activate(                                      
                                    mem,                                        
                                    interrupt_evt.try_clone().expect(&quot;Failed to clone eventfd&quot;),
                                    self.interrupt_status.clone(),              
                                    self.queues.clone(),                         
                                    self.queue_evts.split_off(0),               
                                )                                               
                                .expect(&quot;Failed to activate device&quot;);           
                            self.device_activated = true;                       
                        }                                                       
                    }                                                           
                }                                                                
            }                                                                                                                                  
            …                                                                  
        }                                                                       
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/devices/src/virtio/block.rs:

    fn activate(                                                                 // 激活virtio-blk设备                                   
        &amp;amp;mut self,                                                              
        mem: GuestMemory,                                                        //     虚拟机内存对象                                                 
        interrupt_evt: EventFd,                                                  //     中断irqfd，用来触发虚拟中断通知前端
        …                                               
        queues: Vec&amp;lt;Queue&amp;gt;,                                                      //     virtio队列，这里实际只有一个
        mut queue_evts: Vec&amp;lt;EventFd&amp;gt;,                                            //     virtio队列的io_event_fd，供前端通知后端
    ) -&amp;gt; ActivateResult {                                                       
        …                                                                        
        if let Some(disk_image) = self.disk_image.take() {                       
        let queue_evt = queue_evts.remove(0);                               
        let queue_evt_raw_fd = queue_evt.as_raw_fd();                       

        …              
        let handler = BlockEpollHandler {                                        // 构建一个BlockEpollHandler对象，参考前文运行时代码解析                      
            queues,                                                          
            mem,                                                            
            disk_image,                                                     
            disk_nsectors: self.disk_nsectors,                               
            …                                        
            interrupt_evt,                                                  
            queue_evt,                                                      
            …                                                  
        };                                                                  

        self.epoll_config                                                         // 注意，整个激活动作是在vCPU线程上下文执行的，BlockEpollHandler                                             
            .sender                                                               // 对象也在vCPU线程构建，但是BlockEopllHanler是在fc_vmm线程中被
            .send(Box::new(handler))                                              // 调用的，这样做的好处是可以减少vCPU退出时间。因此这里要把
            .expect(&quot;Failed to send through the channel&quot;);                        // BlockEpollHandler对象通过channel发送给fc_vmm线程

        epoll::ctl(                                                                // 向fc_vmm线程中的epoll事件循环框架添加队列的eventfd，这样当前端
            self.epoll_config.epoll_raw_fd,                                        // 借助KVM的io_event_fd便可以唤醒fc_vmm线程。fc_vmm线程首次处理队
            epoll::ControlOptions::EPOLL_CTL_ADD,                                  // 列事件时会从channel中读出BlockEpollHandler对象，并调用handle_event
            queue_evt_raw_fd,                                                      // 函数处理队列请求；后续处理事件，fc_vmm线程可直接使用该对象
            epoll::Event::new(epoll::Events::EPOLLIN, self.epoll_config.q_avail_token),
        )                                                                   
        .map_err(...)?;                                                                
        …                                                                                                                                    
        return Ok(());                                                      
    }                                                                                                                                                  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  至此，我们已经完成对firecracker中的virtio-mmio设备设计和实现思路(以virtio-blk为例，virtio-net实现本质是相同)的分析，这部分是firecracker中实现最复杂的部分，但是相比传统qemu-kvm中virtio-pci实现，已经作了大量精简。从运行时同步IO操作的实现方式可以看出firecracker的IO性能是非常糟糕的，相同队列并不支持IO的并行处理。不过，在serverless轻量化的场景中，系统中可能会存在成千上万的firecracker实例，单个实例具备非常高的IO性能并没有多大意义，因为此时整个系统IO吞吐量已经成为瓶颈。但是如果想把firecracker应用到通用虚拟化场景中，那对IO系统的改造将是一个大工程。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-virtio/&quot;&gt;【firecracker】virtio-mmio设备&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 03 Sep 2019 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2019/09/firecracker-virtio/</link>
        <guid isPermaLink="true">http://rootw.github.io/2019/09/firecracker-virtio/</guid>
        
        <category>firecracker</category>
        
        
      </item>
    
      <item>
        <title>【firecracker】时钟与中断</title>
        <description>&lt;p&gt;  firecracker虚拟机的时钟与中断系统完全是由KVM模块和硬件实现的，这里仅简要说明其原理，更深入的分析需要结合KVM代码和内核代码进行。&lt;/p&gt;

&lt;h3 id=&quot;时钟系统原理&quot;&gt;时钟系统原理&lt;/h3&gt;

&lt;p&gt;  时钟系统包含时间源和时钟事件源两部分：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;时间源类似生活中的手表，系统通过它可以获知时间，其本质为一个递增的计数器，计数器数值代表当前时间；firecracker中的时钟源有KVM_CLOCK和TSC两种，默认使用KVM_CLOCK；&lt;/li&gt;
    &lt;li&gt;时种 事件源类似生活中的闹钟，系统通过它可以获得时间到期通知事件，其本质为一个递减的计数器，且当计数器清零时会产生中断通知；firecracker中的时间事件源有PIT和LAPIC_TIMER两种，系统启动过程中使用PIT，一旦系统启动完成后会切换到LAPIC_TIMER。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;中断系统原理&quot;&gt;中断系统原理&lt;/h3&gt;

&lt;p&gt;  X86系统在单核时代是通过两片级联的8259A芯片实现可编程中断控制器，其原理如下图所示。KVM内核也实现了对8259A的模拟，SMP系统在启动初期是采用8259A作为中断控制器。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/8259A.jpg&quot; height=&quot;303&quot; width=&quot;514&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  到了SMP多核时代，X86系统采用LAPIC+IOAPIC作为中断控制器系统：每个CPU核都有一个LAPIC，作为本地中断控制器；主板上有一个或多个IOAPIC，外设通过IOAPIC广播中断消息给LAPIC，并由各个LAPIC判断是否需要接收并处理该中断消息，如下图蓝色线条所示。SMP在启动过程中通过MP_Table获知了系统中断控制器信息，之后便可以由8259A切换到LAPIC+IOAPIC。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/machine_model.jpg&quot; height=&quot;342&quot; width=&quot;549&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  虽然中断控制器是由KVM模块实现的，但是外设是由用户态VMM程序模拟的，因此KVM模块需要给用户态程序提供触发中断的系统调用接口，即irqfd。它的大致用法如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;
// initializing irqfd for irq(0)
let device_fd = EventFd::new().unwrap();     // 创建一个新的EventFd句柄
Vm.register_irqfd(device_fd.as_raw_fd(), 0); // 通知KVM模块将该句柄与irq进行关联，这里以0号irq(即时钟中断)为例
// trigger interrupt for irq(0)
device_fd.wirte(1);                          // 通过写EventFd句柄触发一次0号中断，KVM内核会将0号中断通过IOAPIC
                                             // 路由到对应的LAPIC，并向vCPU注入中断
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;时钟与中断初始化流程setup_interrupt_controller&quot;&gt;时钟与中断初始化流程setup_interrupt_controller&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/vmm/src/lib.rs:

struct Vmm {
   …
}

impl Vmm {
    fn setup_interrupt_controller(&amp;amp;mut self) -&amp;gt; std::result::Result&amp;lt;(), StartMicrovmError&amp;gt; {
        self.vm                                                                     
            .setup_irqchip()                                                         
            .map_err(StartMicrovmError::ConfigureVm)                                
    }
}


firecracker/vmm/src/vstate.rs:

struct Vm {
    …
}

impl Vm {
    pub fn setup_irqchip(&amp;amp;self) -&amp;gt; Result&amp;lt;()&amp;gt; {                                    
        self.fd.create_irq_chip().map_err(Error::VmSetup)?;      // 通知KVM内核模块创建8259A及IOPAIC+LAPIC中断控制器              
        let mut pit_config = kvm_pit_config::default();     

        pit_config.flags = KVM_PIT_SPEAKER_DUMMY;                                   
        self.fd.create_pit2(pit_config).map_err(Error::VmSetup)  // 通知KVM创建PIT时钟事件源                  
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-interrupt/&quot;&gt;【firecracker】时钟与中断&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 02 Sep 2019 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2019/09/firecracker-interrupt/</link>
        <guid isPermaLink="true">http://rootw.github.io/2019/09/firecracker-interrupt/</guid>
        
        <category>firecracker</category>
        
        
      </item>
    
      <item>
        <title>【firecracker】CPU与内存</title>
        <description>&lt;h3 id=&quot;运行原理&quot;&gt;运行原理&lt;/h3&gt;

&lt;p&gt;  firecracker虚拟机的CPU与内存功能依赖于硬件辅助虚拟化能力(如intel vt-x特性)：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;硬件辅助虚拟化技术为物理CPU增加了一种新的执行模式(Guest Mode/None-Root Mode),在该模式下，CPU中执行的是虚拟机的指令，而非物理机指令。这是一种高效的虚拟指令执行方式，但是在该模式下并不能直接执行所有的虚拟机执令，某些特权指令(如IO指令)的执行会强制将CPU退出到普通模式(Root Mode)交由VMM程序(内核KVM模块/用户态firecracker)进行处理，处理完成后再重新返回到Guest模式执行。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;同时，MMU中增加了一级页表(X86架构下叫EPT)，MMU通过该页表完成虚拟物理地址(Guest Physical Address,GPA)到主机物理地址(Host Physical Address, HPA)的转换。也就是说当CPU处于Guest模式时，CPU发出的内存访问请求，MMU需要经过两层转换：首先是完成由虚拟地址到虚拟机物理地址的转换，接着是完成由虚拟机物理地址到真实物理地址的转换。因此可以保证不同虚拟机在内存访问上的隔离性。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/cpu.jpg&quot; height=&quot;442&quot; width=&quot;567&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  关于硬件辅助虚拟化技术的详细描述可以参考intel手册和KVM内核模块代码，这里不对此进行深入讨论。firecracker的vCPU线程会对部分退出事件进行处理，我们可以结合代码来进一步讨论其实现原理：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/vmm/src/vstate.rs:

pub struct Vcpu {                       // Vcpu结构代表虚拟CPU                          
    …                                                                
    fd: VcpuFd,                         // fd是KVM内核模块为每个vCPU建立的文件句柄，通过该句柄可以向KVM发起vCPU相关的操作命令                    
    id: u8,                             // id是vCPU编号，从0开始            
    io_bus: devices::Bus,               // io_bus是端口总线，所有Legacy设备均挂在该总线下，CPU通过访问不同端口控制这些设备                          
    mmio_bus: Option&amp;lt;devices::Bus&amp;gt;,     // mmio_bus是mmio总线，所有mmio设备均挂在该总线下，CPU通过访问内存指令来控制这些设备，
                                        //     只不过mmio地址空间(0xD0000000~0xFFFFFFFF)与普通内存DRAM地址空间完全独立。这里Option
                                        //     类型是Rust标准库中定义的一种枚举类型，代表对象为空(None)或非空(Some)，目的在于避免
                                        //     使用C语言中的空指针从而引发各种系统错误。每个vCPU对象对应的mmio_bus在初始时为None，
                                        //     后续在vCPU线程进入Guest模式前被设置为正确的mmio总线对象                                      
    …                                                      
}                                                                               

impl Vcpu {                                    // Rust语言中可以为结构体实现各种方法，类似面向对象语言中类的概念
    …
    pub fn run(                                // Vcpu结构中的run方法为每个vCPU线程的主函数                                       
            &amp;amp;mut self,                                                                                             
            …                                                                               
        ) {                                                                                                        
        …                                                                                                                
        while self.run_emulation().is_ok() {}  // 死循环结构调用run_emulation方法，  如果该方法执行出错则退出循环，线程退出                                                       
        …                                                                                                   
    }
    …

    fn run_emulation(&amp;amp;mut self) -&amp;gt; Result&amp;lt;()&amp;gt; {                                 
        match self.fd.run() {                                     // 通过vCPU句柄调用KVM内核暴露的ioctl接口(KVM_RUN)进入内核态，
                                                                  //     借助硬件辅助虚拟化能力进入Guest模式。通常情况下，物理CPU
                                                                  //     开始执行虚拟机指令，只有出现虚拟机指令无法执行或执行异常
                                                                  //     时，物理CPU才会退出到KVM模块进行处理(例如EPT缺页异常)。
                                                                  //     如果KVM模块也无法处 理，会进一步返回到用户态vmm程序，则
                                                                  //     下一条语句才开始执行
            Ok(run) =&amp;gt; match run {                                // 如果执行到这里，说明出现了KVM内核也无法处理的退出事件。如果
                                                                  //     返回结果OK，则进一步判断退出事件类型
                VcpuExit::IoIn(addr, data) =&amp;gt; {                   // 该分支处理vCPU的端口读操作(IoIn)，addr代表端口地址，data代表将
                                                                  //     取的数据
                    self.io_bus.read(u64::from(addr), data);      // 将端口读操作转发到端口总线io_bus上，其内部根据端口地址搜索对
                                                                  //     应端口设备并调用设备的read接口      
                    …                             
                    Ok(())                                        // run_emulation返回处理成功，处层死循环将再次进入Guest模式
                }                                                               
                VcpuExit::IoOut(addr, data) =&amp;gt; {                  // 该分支处理vCPU端口写操作(IoOut)
                    …                                
                    self.io_bus.write(u64::from(addr), data);                   
                    …                            
                    Ok(())                                                      
                }                                                               
                VcpuExit::MmioRead(addr, data) =&amp;gt; {               // 该分支处理vCPU MMIO地址读操作(MmioRead)       
                    if let Some(ref mmio_bus) = self.mmio_bus {   // 如果vCPU可访问的mmio总线存在，            
                        mmio_bus.read(addr, data);                // 则将读操作转到到mmio总线上，其内部根据mmio地址搜索对应的mmio设备
                                                                  //         并调用设备的read接口 
                        …                      
                    }                                                           
                    Ok(())                                                      
                }                                                               
                VcpuExit::MmioWrite(addr, data) =&amp;gt; {              // 该分支处理vCPU MMIO地址写操作(MmioWrite)        
                    if let Some(ref mmio_bus) = self.mmio_bus {                 
                        …                                                       
                        mmio_bus.write(addr, data);                              
                        …                      
                    }                                                           
                    Ok(())                                                      
                }                                                                
                VcpuExit::Hlt =&amp;gt; {                                // 该分支处理Hlt指令，vCPU线程退出                         
                    info!(&quot;Received KVM_EXIT_HLT signal&quot;);                       
                    Err(Error::VcpuUnhandledKvmExit)                            
                }                                                               
                VcpuExit::Shutdown =&amp;gt; {                           // 该分支处理shutdown命令，vCPU线程退出
                    info!(&quot;Received KVM_EXIT_SHUTDOWN signal&quot;);                 
                    Err(Error::VcpuUnhandledKvmExit)                            
                }  
                …
            }
            …
        }
    }                             
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  通过上述代码可以看出，CPU与内存的虚拟化功能基本由硬件实现，而软件主要配合硬件完成对各种退出事件的处理：KVM内核模块实现了对EPT表缺页异常的处理；firecracker实现了对端口读写及mmio空间读写操作的处理。&lt;/p&gt;

&lt;h3 id=&quot;初始化流程&quot;&gt;初始化流程&lt;/h3&gt;

&lt;p&gt;  尽管虚拟CPU和内存在运行过程中无须firecracker有过多干涉，但是它们的初始化动作是完全由friecracker实现的，因此我们需要了解firecracker是如何实现CPU和内存初始化的。&lt;/p&gt;

&lt;h4 id=&quot;一简要kvm使用例程&quot;&gt;&lt;strong&gt;一、简要KVM使用例程&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  在我们正式分析firecracker的初始化代码之前，我们有必要先了解一下KVM模块的使用方法，因为firecracker是基于KVM模块构建的。Rust语言环境下有一个名叫kvm-ioctls的库，它实现了对KVM内核ioctl系统调用的封装，我们可以基于这个库实现一个简单的KVM虚拟机程序：启动一个单核，普通内存地址范围0x1000~0x5000的虚拟机，虚拟机进入Guest模式后执行一段简单的端口操作与MMIO空间操作指令后立刻停机。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;
fn main() {
    …
    let kvm = Kvm::new().unwrap();      // 第一步：创建一个kvm对象，对应字符设备/dev/kvm

    let vm = kvm.create_vm().unwrap();  // 第二步：通过kvm对象创建一个虚拟机对象vm
                                        // 第三步：初始化虚拟机普通内存
    let mem_size = 0x4000;              //      设置普通内存大小为0x4000                                                  
    let guest_addr: u64 = 0x1000;       //      设置普通内存起始地址为0x1000，意味在0x1000~0x5000之外均为MMIO地址空间 
    let load_addr: *mut u8 = unsafe {   //      通过mmap系统调用映射一段大小为0x4000的区间，虚拟起始地址记录到load_addr中 
        libc::mmap(                                                         
            null_mut(),                                                     
            mem_size,                                                       
            libc::PROT_READ | libc::PROT_WRITE,                             
            libc::MAP_ANONYMOUS | libc::MAP_SHARED
                | libc::MAP_NORESERVE,   
            -1,                                                             
            0,                                                               
        ) as *mut u8                                                        
    };                                                                      

    let slot = 0;                                  //     设置区间号为零，并将之前映射的区间信息传递给KVM        
    let mem_region = kvm_userspace_memory_region { //     该对象包含所有需要传递给KVM的信息                       
        slot,                                      //     当前区间编号，即0
        guest_phys_addr: guest_addr,               //     虚拟机起始物理地址，即0x1000        
        memory_size: mem_size as u64,              //     虚拟机普通内存区间大小，即0x4000        
        userspace_addr: load_addr as u64,          //     普通内存区间映射到主机的虚拟地址           
        flags: KVM_MEM_LOG_DIRTY_PAGES,            //     区间标志，通知KVM对该区间进行脏页跟踪                    
    };                                                                         
    unsafe { vm.set_user_memory_region(mem_region).unwrap() };    // 通过虚拟机对象vm将普通内存信息传递给KVM

    let x86_code = [                                              // 设置虚拟机内将执行的指令    
        0xba, 0xf8, 0x03, /* mov $0x3f8, %dx */                   //     端口寄存器dx设为0x3f8，对应串口设备
        0x00, 0xd8, /* add %bl, %al */                            //     将bl寄存器值 加到al寄存器中
        0x04, b'0', /* add $'0', %al */                           //     将字符'0'的值加到al寄存器中
        0xee, /* out %al, %dx */                                  //     向端口输出al寄存器的值
        0xec, /* in %dx, %al */                                   //     从端口读入值到al寄存器
        0xc6, 0x06, 0x00, 0x80, 0x00,                                                  
            /* movl $0, (0x8000); This generates a MMIO Write.*/  //     将零写到0x8000地址，位于MMIO地址空间
        0x8a, 0x16, 0x00, 0x80,
            /* movl (0x8000), %dl; This generates a MMIO Read.*/  //     读取0x8000地址值到dl寄存器
        0xf4, /* hlt */                                           //     执行停机指令
    ];    

    unsafe {                                                      // 将上述指令内容写入到虚拟机普通内存区间中
        let mut slice = slice::from_raw_parts_mut(load_addr, mem_size);     
        slice.write(&amp;amp;x86_code).unwrap();                                    
    }

    let vcpu_fd = vm.create_vcpu(0).unwrap();                     // 第四步：通过虚拟机对象创建一个vCPU对象
                                                                  // 第五步：初始化vCPU对象中各个寄存器的值
    let mut vcpu_sregs = vcpu_fd.get_sregs().unwrap();            //     获取各个段寄存器的默认值
    vcpu_sregs.cs.base = 0;                                       //     将代码段选择子cs对应的基地址设为0
    vcpu_sregs.cs.selector = 0;                                   //     将代码段选择子cs设为0
    vcpu_fd.set_sregs(&amp;amp;vcpu_sregs).unwrap();                      //     将设置后的段寄存器值传递给KVM

    let mut vcpu_regs = vcpu_fd.get_regs().unwrap();              //     获取通用寄存器的默认值              
    vcpu_regs.rip = guest_addr;                                   //     将指令指针IP设为0x1000
    vcpu_regs.rax = 2;                                            //     将rax寄存器初始化为2 
    vcpu_regs.rbx = 3;                                            //     将rbx寄存器初始化为3；对照上述指令，最后串口将输出字符'5'
    vcpu_regs.rflags = 2;                                         //     将标志寄存器设为2，因为位1为保留位，值须为1
    vcpu_fd.set_regs(&amp;amp;vcpu_regs).unwrap();                        //     将设置后的通用寄存器值传递给KVM

    loop {                                                        // 第六步：通过vCPU对象以死循环方式不断进入Guest模式
        match vcpu_fd.run().expect(&quot;run failed&quot;) {                          
            VcpuExit::IoIn(addr, data) =&amp;gt; {                                 
                println!(                                                   
                    &quot;Received an I/O in exit. Address: {:#x}. Data: {:#x}&quot;, 
                    addr,                                                   
                    data[0],                                                 
                );                                                          
            }
            VcpuExit::IoOut(addr, data) =&amp;gt; {
                …
            }
            VcpuExit::MmioRead(addr, data) =&amp;gt; {
                …
            }
            VcpuExit::MmioWrite(addr, data) =&amp;gt; {
                …
            }
            VcpuExit::Hlt =&amp;gt; {
                …
            }
            r =&amp;gt; panic!(&quot;Unexpected exit reason: {:?}&quot;, r),
        } // end of match
    } // end of loop
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  通过上述例程，我们看到只需要简单的六大步，便可以通过KVM模块创建一个虚拟机。在掌握了KVM的基础原理后，我们再来看看firecracker中的内存和CPU初始化流程。&lt;/p&gt;

&lt;h4 id=&quot;二虚拟机内存初始化init_guest_memory&quot;&gt;&lt;strong&gt;二、虚拟机内存初始化init_guest_memory&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  firecracker对虚拟机内存的初始化动作在init_guest_memory函数中完成，代码原理如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/vmm/src/lib.rs

struct Vmm {                            // vmm全局对象，包含当前虚拟机的所有全局信息
    kvm: KvmContext,                    // kvm上下文，包含kvm对象
    vm_config: VmConfig,                // 虚拟机配置，如CPU数和内存大小等
    guest_memory: Option&amp;lt;GuestMemory&amp;gt;,  // 虚拟机内存对象，初始时为None
    vm: Vm,                             // 虚拟机对象vm
    …
}

impl Vmm {
    fn init_guest_memory(&amp;amp;mut self) -&amp;gt; std::result::Result&amp;lt;(), StartMicrovmError&amp;gt; {
        let mem_size = self                                             // 从虚拟机配置vm_config中获取内存大小并转化为字节单位                                                         
            .vm_config                                                              
            .mem_size_mib                                                           
            .ok_or(StartMicrovmError::GuestMemory(                                   
                memory_model::GuestMemoryError::MemoryNotInitialized,               
            ))?                                                                     
            &amp;lt;&amp;lt; 20;                                                                   
        let arch_mem_regions = arch::arch_memory_regions(mem_size);     // 根据不同体系架构，划分内存区间。以X86为例，虚拟机普通
                                                                        //     内存将分布在两个区间：0x0~0xD0000000和0xFFFFFFFF~X。
                                                                        //     地址区间0xD0000000~0xFFFFFFFF为MMIO空间。   
        self.guest_memory =                                                         
            Some(GuestMemory::new(&amp;amp;arch_mem_regions)                    // 通过mmap系统调用将各个区间映射到用户空间，参见KVM例程
            .map_err(StartMicrovmError::GuestMemory)?);
        self.vm                                                                     
            .memory_init(                                               // 通过vm对象将内存区间信息传递给KVM，参见KVM例程                                                 
                self.guest_memory                                                   
                    .clone()                                                         
                    .ok_or(StartMicrovmError::GuestMemory(                          
                        memory_model::GuestMemoryError::MemoryNotInitialized,   
                    ))?,                                                             
                &amp;amp;self.kvm,                                                          
            )                                                                       
            .map_err(StartMicrovmError::ConfigureVm)?;                              
        Ok(())                                                                      
    }
    …
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;三虚拟机cpu初始化create_vcpus和start_vcpus&quot;&gt;&lt;strong&gt;三、虚拟机CPU初始化create_vcpus和start_vcpus&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  firecracker通过create_vcpus创建虚拟CPU，并通过start_vcpus启动CPU，代码原理如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-nohighlight&quot;&gt;firecracker/vmm/src/lib.rs

struct Vmm {
    …
    kvm: KvmContext,                                // kvm上下文，包含kvm对象
    vcpus_handles: Vec&amp;lt;thread::JoinHandle&amp;lt;()&amp;gt;&amp;gt;,     // vCPU线程句柄数组，每个vCPU线程对应一个句柄
    vm: Vm,                                         // 虚拟机对象vm
    mmio_device_manager: Option&amp;lt;MMIODeviceManager&amp;gt;, // mmio设备管理器，包含mmio总线及其上的所有mmio设备
    legacy_device_manager: LegacyDeviceManager,     // legacy设备管理器，包含legacy总线及其上的所有legacy设备
    …
}

impl Vmm {
    …
    fn create_vcpus(                              // 创建所有的虚拟CPU                                                       
        &amp;amp;mut self,                                                              
        entry_addr: GuestAddress,                 // 参数entry_addr代表加载虚拟机内核的目的地址，
                                                  //      也是虚拟机进入Guest模式执行的第一条指令位置                                            
        request_ts: TimestampUs,                                                 
    ) -&amp;gt; std::result::Result&amp;lt;Vec&amp;lt;Vcpu&amp;gt;, StartMicrovmError&amp;gt; {                    
        let vcpu_count = self                                                      // 从虚拟机配置vm_config中读取虚拟CPU个数                                                  
            .vm_config                                                          
            .vcpu_count                                                         
            .ok_or(StartMicrovmError::VcpusNotConfigured)?;                     
        let mut vcpus = Vec::with_capacity(vcpu_count as usize);                   // 根据vCPU个数创建向量集vcpus           

        for cpu_id in 0..vcpu_count {                                              // 循环创建vcpu_count个vCPU                                           
            let io_bus = self.legacy_device_manager.io_bus.clone();                //     克隆legacy总线
            let mut vcpu = Vcpu::new(cpu_id, &amp;amp;self.vm, io_bus, request_ts.clone()) //     通过KVM创建一个vCPU
                .map_err(StartMicrovmError::Vcpu)?;                             
            vcpu.configure(&amp;amp;self.vm_config, entry_addr, &amp;amp;self.vm)                  //     配置vCPU寄存器信息，包括段寄存器、通用寄存器和系统寄存器
                                                                                   //           以及虚拟机内部页表。第一个vCPU(BSP)开始运行时即处于分
                                                                                   //           页模式下              
            .map_err(StartMicrovmError::VcpuConfigure)?;                           //  
            vcpus.push(vcpu);                                                      //      将vcpu添加到向量集中
        }                                                                        
        Ok(vcpus)                                                               
    }

    fn start_vcpus(&amp;amp;mut self, mut vcpus: Vec&amp;lt;Vcpu&amp;gt;)
            -&amp;gt; std::result::Result&amp;lt;(), StartMicrovmError&amp;gt; {                        // 启动所有的vCPU
        …                                                                                                     
        for cpu_id in (0..vcpu_count).rev() {                                      // 循环启动vCPU                                  
            …                                   
            let mut vcpu = vcpus.pop().unwrap();                                   //       依次取出vcpu                             

            if let Some(ref mmio_device_manager) = self.mmio_device_manager {      //       如果存在mmio总线，则克隆总线对象
                vcpu.set_mmio_bus(mmio_device_manager.bus.clone());             
            }                                                                   
            …                            
            self.vcpus_handles.push(                                            
                thread::Builder::new()                                             //       启动一个名为fc_vcpu的线程，执行vcpu的run函数，
                                                                                   //       参考运行原理代码分析                                    
                    .name(format!(&quot;fc_vcpu{}&quot;, cpu_id))                         
                    .spawn(move || {                                            
                        vcpu.run(…);
                    })                                                          
                    .map_err(StartMicrovmError::VcpuSpawn)?,                    
            );                                                                   
        }                                                                       
        …                                                                                                                
        Ok(())                                                                   
    }                                  
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  至此，firecracker虚拟机CPU与内存子系统已经分析完成，简单总结一下：虚拟机CPU和内存的功能基本上是由硬件和KVM模块实现的，firecracker主要对端口和MMIO操作进行了处理。在后续的MMIO设备和legacy设备分析中，我们将深入讨论端口及MMIO空间的处理流程。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-cpu-memory/&quot;&gt;【firecracker】CPU与内存&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 01 Sep 2019 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2019/09/firecracker-cpu-memory/</link>
        <guid isPermaLink="true">http://rootw.github.io/2019/09/firecracker-cpu-memory/</guid>
        
        <category>firecracker</category>
        
        
      </item>
    
      <item>
        <title>【firecracker】概述</title>
        <description>&lt;h3 id=&quot;ｗhat&quot;&gt;Ｗhat&lt;/h3&gt;

&lt;p&gt;  firecracker（中文名&lt;strong&gt;鞭炮&lt;/strong&gt;，寓意虚拟机的生命可以像鞭炮一样短暂，一闪即逝，但相同时刻却可以有成千上万个虚拟机快速闪现）是一种基于KVM的轻量虚拟化技术，相比普通虚拟机，firecracker虚拟机内存占用更少、启动速度更快；相比容器，firecracker则具有极强的安全隔离性。另外，firecracker采用全新的安全编程语言Rust实现，提供了语言级的内存安全与线程安全保障，使它天生具备了安全基因。&lt;/p&gt;

&lt;h3 id=&quot;why&quot;&gt;Why&lt;/h3&gt;

&lt;p&gt;  firecracker为了同时实现虚拟机的隔离性和容器的轻量性，也付出了一定的代价：由于裁剪了标准主板架构中的BIOS模块、PCI系统和ACPI模块，因此它不支持CPU和设备的热插拔；它是短生命周期的，就如同鞭炮，一闪即逝，因此不支持热迁移等长周期特性；虚拟机内部操作系统内核定制，不支持通用操作系统。所以firecracker目前瞄准的应用场景主要是作为serverless平台的运行时底座，为serverless函数提供轻量、安全的执行环境。&lt;/p&gt;

&lt;h3 id=&quot;how-to-use&quot;&gt;How to Use&lt;/h3&gt;

&lt;p&gt;  以X86平台为例，我们可以通过如下命令启动一个firecracker虚拟机：&lt;/p&gt;

&lt;p&gt;  1、启动firecracker进程&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;firecracker –api-sock /tmp/firecracker.socket&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;  2、配置vmlinux&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;curl –unix-socket /tmp/firecracker.socket -i -X PUT ‘http://localhost/boot-source’ -H ‘Accept: application/json’ -H ‘Content-Type: application/json’ -d ‘{“kernel_image_path”: “/root/hello-vmlinux.bin”, “boot_args”: “console=ttyS0 reboot=k panic=1 pci=off”}’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;  3、配置rootfs&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;curl –unix-socket /tmp/firecracker.socket -i -X PUT ‘http://localhost/drives/rootfs’ -H ‘Accept: application/json’ -H ‘Content-Type: application/json’ -d ‘{“drive_id”: “rootfs”, “path_on_host”: “/root/hello-rootfs.ext4”, “is_root_device”: true, “is_read_only”: false}’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;  4、配置虚拟机规格&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;curl –unix-socket /tmp/firecracker.socket -i -X PUT ‘http://localhost/machine-config’ -H ‘Accept: application/json’ -H ‘Content-Type: application/json’ -d ‘{“vcpu_count”: 2, “mem_size_mib”: 1024, “ht_enabled”: false}’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;  5、运行虚拟机&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;curl –unix-socket /tmp/firecracker.socket -i -X PUT ‘http://localhost/actions’ -H ‘Accept: application/json’ -H ‘Content-Type: application/json’ -d ‘{“action_type”: “InstanceStart”}’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;how-to-implement&quot;&gt;How to Implement&lt;/h3&gt;

&lt;h4 id=&quot;系统架构&quot;&gt;&lt;strong&gt;系统架构&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  从整体架构上看，firecracker与普通KVM虚拟化非常相似：物理主机上直接运行Host OS系统，其内核中部署KVM模块；KVM内核模块为用户态虚拟化程序(firecracker)提供硬件辅助的核心部件(CPU、MMU、本地中断控制器与时钟系统等)虚拟化能力；firecracker模拟的机器只实现了运行应用所必需的组件，其内部运行的Guest OS系统是一个经过裁剪优化的运行时环境，可以支持绝大多数客户应用程序的执行。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/architecture.jpg&quot; height=&quot;552&quot; width=&quot;867&quot; /&gt;  
&lt;/div&gt;

&lt;h4 id=&quot;设备模型与线程模型&quot;&gt;&lt;strong&gt;设备模型与线程模型&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  正如上节架构分析中所述，firecracker虚拟机仅包含了运行客户应用所必需的组件，是一种非常精简的设备模型，如下图所示仅包含 CPU、内存、时钟系统、中断系统、IO设备(virtio-blk/virtio-net)与输入输出串口。CPU与内存是核心运算和控制系统，客户应用对外呈现的绝大多数功能由它们提供；时钟系统为系统提供计时功能和定时通知功能，其中计时功能为内核和客户应用提供时间概念，定时通知功能可实现定时器功能并可作为内核调度机制的触发条件；中断系统为各类外设提供了一种向CPU报告事件发生的通用机制；IO设备为系统提供了基础存储或网络服务，使系统具备了“记忆”和“通信”能力；串口设备为虚拟机和系统管理员之间提供一种交互手段，使得虚拟机可以响应管理员下发的各种管理命令。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/machine_model.jpg&quot; height=&quot;342&quot; width=&quot;549&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  从线程模型上分析，firecracker和KVM上的qemu程序几乎一样(下图显示了一个2核firecracker虚拟机运行时生成的4个线程)：由虚拟CPU线程（图中fc_vcpu0和fc_vcpu1）实现虚拟机CPU和内存功能的模拟；由IO线程(图中fc_vmm)实现对各类IO设备的模拟(即响应虚拟机CPU发出的IO请求)；不同的是，firecracker有一个独立的API_Server线程(图中firecracker)，它基于http协议接收用户的命令并将命令传递给IO线程处理。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;                                                             
    &lt;img src=&quot;/images/posts/firecracker/thread_model.jpg&quot; height=&quot;88&quot; width=&quot;576&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  下面我们将以X86虚拟机为例通过一系列博文逐个分析firecracker各个子系统运行原理与初始化流程。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-cpu-memory/&quot;&gt;CPU与内存&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-interrupt/&quot;&gt;时钟与中断&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-virtio/&quot;&gt;virtio-mmio设备&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-legacy/&quot;&gt;legacy设备&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://rootw.github.io/2019/09/firecracker-startvm/&quot;&gt;系统启动与Epoll事件循环&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2019/08/firecracker-all/&quot;&gt;【firecracker】概述&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 15 Aug 2019 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2019/08/firecracker-all/</link>
        <guid isPermaLink="true">http://rootw.github.io/2019/08/firecracker-all/</guid>
        
        <category>firecracker</category>
        
        
      </item>
    
      <item>
        <title>【SPDK】七、vhost客户端连接请求处理</title>
        <description>&lt;p&gt;  vhost客户端连接后，将遵循vhost协议进行一系统复杂的消息传递与处理过程，最终服务端将生成一个可处理IO环中请求并返回响应的处理线程。本篇博文将分析其中最为重要两类消息的处理原理：内存映射消息和IO环信息传递消息。最后将一起来看一下vhost通用消息处理完成后，vhost-blk设备是如何完成最后的初始化动作的(其它类型的vhost设备大家可以自行阅读代码分析)。&lt;/p&gt;

&lt;h3 id=&quot;vhost内存映射&quot;&gt;vhost内存映射&lt;/h3&gt;

&lt;p&gt;  vhost的reactor线程在处理IO请求时，需要访问虚拟机的内存空间。我们知道，虚拟机可见的内存是由qemu进程分配的，通过KVM内核模块将内存映射关系记录到EPT页表中(CPU硬件提供的地址转换功能)，以此实现从GPA(Guest Physical Address)到HPA(Host Physical Address)的转换。同时qemu分配的这部分内存会映射到qemu虚拟地址空间中(Qemu Virtual Adress)，以便qemu进程中IO线程可以访问虚拟机内存。映射关系如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/posts/spdk/memory.jpg&quot; height=&quot;400&quot; width=&quot;550&quot; /&gt;  
&lt;/div&gt;

&lt;p&gt;  SPDK中vhost进程将取代qemu IO线程对IO进行处理，因此它也需要将虚拟机可见地址映射到自身的虚拟地址空间中(Vhost Virtual Address)，并记录VVA到HPA的映射关系，便于将HPA发送给物理存储控制器进行DMA操作。&lt;/p&gt;

&lt;p&gt;  vhost进程映射虚拟机地址的基本原理就是通过大页内存的mmap系统调用：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;qemu进程通过大页文件(/dev/hugepages/xxx)为虚拟机申请内存，然后将大页文件句柄传递给vhost进程；&lt;/li&gt;
  &lt;li&gt;vhost进程接收句柄后，会识别到qemu创建的大页文件(/dev/hugepages/xxx)，然后调用mmap系统调用将该大页文件映射到自身虚拟地址空间中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  下面我们结合代码，再来深入理解一下内存映射过程。首先qemu连接vhost进程后，会通过发送VHOST_USER_SET_MEM_TABLE消息传递qemu内部的内存映射信息，vhost对该消息的处理过程如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/rte_vhost/vhost_user.c:

static int
vhost_user_set_mem_table(struct virtio_net *dev, struct VhostUserMsg *pmsg)
{
    uint32_t i;

    memcpy(&amp;amp;dev-&amp;gt;mem_table, &amp;amp;pmsg-&amp;gt;payload.memory, sizeof(dev-&amp;gt;mem_table));
    memcpy(dev-&amp;gt;mem_table_fds, pmsg-&amp;gt;fds, sizeof(dev-&amp;gt;mem_table_fds));
    dev-&amp;gt;has_new_mem_table = 1;
    
    ...
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  从上述代码，我们可以看到这里仅是简单地将socket消息中内容复制到dev对象中。注意一点，这里的dev代表客户端对象；对象类型名为virtio_net是由于这部分代码完全借用自DPDK导致，并不是说客户端是一个virtio_net对象。&lt;/p&gt;

&lt;p&gt;  后续在进行gpa地址转换前，后续通过vhost_setup_mem_table完成内存映射：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/rte_vhost/vhost_user.c:

static int
vhost_setup_mem_table(struct virtio_net *dev)
{
    struct VhostUserMemory memory = dev-&amp;gt;mem_table;
    struct rte_vhost_mem_region *reg;
    void *mmap_addr;
    uint64_t mmap_size;
    uint64_t mmap_offset;
    uint64_t alignment;
    uint32_t i;
    int fd;

    ...
    dev-&amp;gt;mem = rte_zmalloc(&quot;vhost-mem-table&quot;, sizeof(struct rte_vhost_memory) +
            sizeof(struct rte_vhost_mem_region) * memory.nregions, 0);
    dev-&amp;gt;mem-&amp;gt;nregions = memory.nregions;

    for (i = 0; i &amp;lt; memory.nregions; i++) {
        fd  = dev-&amp;gt;mem_table_fds[i]; /* 取出大页文件句柄，注，这里是经过内核处理后的句柄，不是qemu中的原始句柄号 */
        reg = &amp;amp;dev-&amp;gt;mem-&amp;gt;regions[i];

        reg-&amp;gt;guest_phys_addr = memory.regions[i].guest_phys_addr; /* 虚拟机物理内存地址，gpa*/
        reg-&amp;gt;guest_user_addr = memory.regions[i].userspace_addr;  /* qemu中的虚拟地址，qva*/
        reg-&amp;gt;size            = memory.regions[i].memory_size;     /* 内存段大小 */
        reg-&amp;gt;fd              = fd;

        mmap_offset = memory.regions[i].mmap_offset; /* 映射段内偏移，通常为零 */
        mmap_size   = reg-&amp;gt;size + mmap_offset;       /* 映射段大小 */

        ...

        /* 将大页文件重新映射到当前进程中 */
        mmap_addr = mmap(NULL, mmap_size, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, fd, 0);

        reg-&amp;gt;mmap_addr = mmap_addr;
        reg-&amp;gt;mmap_size = mmap_size;
        reg-&amp;gt;host_user_addr = (uint64_t)(uintptr_t)mmap_addr + mmap_offset; /* vhost虚拟地址，vva */

        ...
    }

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;vhost-io环信息传递&quot;&gt;vhost IO环信息传递&lt;/h3&gt;

&lt;p&gt;  vhost内存映射完成后，便可进行IO环信息的传递，处理完成后使得vhost进程可以访问IO环中信息。&lt;/p&gt;

&lt;p&gt;  这里注意一点，vhost在处理IO环相关消息时，首先会通过vhost_user_check_and_alloc_queue_pair来创建IO环相关对象。IO环相关的消息主要有VHOST_USER_SET_VRING_NUM、VHOST_USER_SET_VRING_ADDR、VHOST_USER_SET_VRING_BASE、VHOST_USER_SET_VRING_KICK、VHOST_USER_SET_VRING_CALL，这里我们重点分析一下VHOST_USER_SET_VRING_ADDR消息的处理：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/rte_vhost/vhost_user.c:

static int
vhost_user_set_vring_addr(struct virtio_net *dev, VhostUserMsg *msg)
{
    struct vhost_virtqueue *vq;
    uint64_t len;

    /* 如果还未完成vhost内存的映射，则先进行内存映射，可参考前文分析 */
    if (dev-&amp;gt;has_new_mem_table) {
        vhost_setup_mem_table(dev);
        dev-&amp;gt;has_new_mem_table = 0;
    }
    ...

    /* 根据消息中的索引找到对应的vq对象 */
    vq = dev-&amp;gt;virtqueue[msg-&amp;gt;payload.addr.index];

    /* The addresses are converted from QEMU virtual to Vhost virtual. */
    len = sizeof(struct vring_desc) * vq-&amp;gt;size;
    /* 将消息中包含的desc数组的qva地址转换成vva地址，便于vhost线程后续访问IO环中desc数组中内容 */
    vq-&amp;gt;desc = (struct vring_desc *)(uintptr_t)qva_to_vva(dev, msg-&amp;gt;payload.addr.desc_user_addr, &amp;amp;len);

    dev = numa_realloc(dev, msg-&amp;gt;payload.addr.index);
    vq = dev-&amp;gt;virtqueue[msg-&amp;gt;payload.addr.index];

    /* 同理将avail数组的qva地址转换成vva地址 */
    len = sizeof(struct vring_avail) + sizeof(uint16_t) * vq-&amp;gt;size;
    vq-&amp;gt;avail = (struct vring_avail *)(uintptr_t)qva_to_vva(dev, msg-&amp;gt;payload.addr.avail_user_addr, &amp;amp;len);
    
    /* 同理将used数组的qva地址转换成vva地址 */
    len = sizeof(struct vring_used) + sizeof(struct vring_used_elem) * vq-&amp;gt;size;
    vq-&amp;gt;used = (struct vring_used *)(uintptr_t)qva_to_vva(dev, msg-&amp;gt;payload.addr.used_user_addr, &amp;amp;len);

    ...
    return 0;
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;vhost-blk回调处理&quot;&gt;vhost-blk回调处理&lt;/h3&gt;

&lt;p&gt;  vhost设备完成内存映射及IO环信息传递动作后，就进行不同vhost设备特有的初始化动作：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/rte_vhost/vhost_user.c:

int
vhost_user_msg_handler(int vid, int fd)
{

    /* 从socket句柄中读取消息 */
    ret = read_vhost_message(fd, &amp;amp;msg);
    ...

    /* 如果消息中涉及IO环则先创建IO环对象 */
    ret = vhost_user_check_and_alloc_queue_pair(dev, &amp;amp;msg);

    /* 根据不同的消息类型进行处理 */
    switch (msg.request) {
    case VHOST_USER_GET_CONFIG:
    ...
    }

    if (!(dev-&amp;gt;flags &amp;amp; VIRTIO_DEV_RUNNING) &amp;amp;&amp;amp; virtio_is_ready(dev)) {
        dev-&amp;gt;flags |= VIRTIO_DEV_READY;

        if (!(dev-&amp;gt;flags &amp;amp; VIRTIO_DEV_RUNNING)) {

            /* 通过notify_ops回调设备相关的初始化函数 */
            if (dev-&amp;gt;notify_ops-&amp;gt;new_device(dev-&amp;gt;vid) == 0)
                dev-&amp;gt;flags |= VIRTIO_DEV_RUNNING;
        }
    }

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  g_spdk_vhost_ops的new_device函数指向start_device，这里仍是vhost设备通用的初始化逻辑：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/vhost.c:

static int
start_device(int vid)
{
    struct spdk_vhost_dev *vdev;
    int rc = -1;
    uint16_t i;

    /* 根据客户端vid找到对应的vhost_dev设备 */
    vdev = spdk_vhost_dev_find_by_vid(vid);

    /* 将客户端对象(virtio_net)中记录的IO环信息同步一份到vhost_dev中，后续IO处理时主要操作vhost_dev对象 */
    vdev-&amp;gt;max_queues = 0;
    memset(vdev-&amp;gt;virtqueue, 0, sizeof(vdev-&amp;gt;virtqueue));
    for (i = 0; i &amp;lt; SPDK_VHOST_MAX_VQUEUES; i++) {
        if (rte_vhost_get_vhost_vring(vid, i, &amp;amp;vdev-&amp;gt;virtqueue[i].vring)) {
            continue;
        }

        if (vdev-&amp;gt;virtqueue[i].vring.desc == NULL ||
                vdev-&amp;gt;virtqueue[i].vring.size == 0) {
            continue;
        }

        /* Disable notifications. */
        if (rte_vhost_enable_guest_notification(vid, i, 0) != 0) {
            SPDK_ERRLOG(&quot;vhost device %d: Failed to disable guest notification on queue %&quot;PRIu16&quot;\n&quot;, vid, i);
            goto out;
        }

        vdev-&amp;gt;max_queues = i + 1;
    }

    /* 同理，将客户端对象中的内存映射表同步一份到vhost_dev中 */
    if (rte_vhost_get_mem_table(vid, &amp;amp;vdev-&amp;gt;mem) != 0) {
        
    }

    /* 为vhost_dev对象分配一个运行核 */
    vdev-&amp;gt;lcore = spdk_vhost_allocate_reactor(vdev-&amp;gt;cpumask);

    /* 记录该vdev对象内存表中虚拟地址到物理地址的映射关系，后续操作物理DMA时可用 */
    spdk_vhost_dev_mem_register(vdev);

    /* 向vhost_dev对象的运行核发送一个事件，使该核上的reactor线程可以执行backend的start_device函数 */
    rc = spdk_vhost_event_send(vdev, vdev-&amp;gt;backend-&amp;gt;start_device, 3, &quot;start device&quot;);
    ...

    return rc;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  vhost_dev的运行核上的reactor线程会执行backend的start_device，即spdk_vhost_blk_start：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/vhost_blk.c:

static int
spdk_vhost_blk_start(struct spdk_vhost_dev *vdev, void *event_ctx)
{
    struct spdk_vhost_blk_dev *bvdev;
    int i, rc = 0;

    bvdev = to_blk_dev(vdev);
    ...

    /* 为vhost设备中的每个队列分配task数组，task与队列中元素个数相同，一一对应 */
    rc = alloc_task_pool(bvdev);
    ...

    if (bvdev-&amp;gt;bdev) {
        /* 为vhost_blk对应申请IO Channel，此时已确定执行线程上下文 */
        bvdev-&amp;gt;bdev_io_channel = spdk_bdev_get_io_channel(bvdev-&amp;gt;bdev_desc);
        ...
    }

    /* 在当前reactor线程中添加一个poller，用来处理IO环中的所有请求 */
    bvdev-&amp;gt;requestq_poller = spdk_poller_register(bvdev-&amp;gt;bdev ? vdev_worker : no_bdev_vdev_worker, bvdev, 0);
    ...
    return rc;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  至此，SPDK中vhost进程的初始化流程已介绍完毕，过程非常漫长，大家可以在对数据面的处理流程有一定的熟悉之后再来阅读分析这部分代码，这样可以理解得更深刻。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2018/05/SPDK-vhost-msg-handle/&quot;&gt;【SPDK】七、vhost客户端连接请求处理&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 22 May 2018 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2018/05/SPDK-vhost-msg-handle/</link>
        <guid isPermaLink="true">http://rootw.github.io/2018/05/SPDK-vhost-msg-handle/</guid>
        
        <category>SPDK</category>
        
        
      </item>
    
      <item>
        <title>【SPDK】六、vhost子系统</title>
        <description>&lt;p&gt;  vhost子系统在SPDK中属于应用层或叫协议层，为虚拟机提供vhost-blk、vhost-scsi和vhost-nvme三种虚拟设备。这里我们以vhost-blk为分析对象，来讨论vhost子系统基本原理。&lt;/p&gt;

&lt;h3 id=&quot;vhost子系统初始化&quot;&gt;vhost子系统初始化&lt;/h3&gt;

&lt;p&gt;  vhost子系统的描述如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/event/subsystems/vhost/vhost.c:

static struct spdk_subsystem g_spdk_subsystem_vhost = {
    .name = &quot;vhost&quot;,
    .init = spdk_vhost_subsystem_init,
    .fini = spdk_vhost_subsystem_fini,
    .config = NULL,
    .write_config_json = spdk_vhost_config_json,
};

static void
spdk_vhost_subsystem_init(void)
{
    int rc = 0;

    rc = spdk_vhost_init();

    spdk_subsystem_init_next(rc);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;  vhost子系统初始化时，会依次偿试对vhost-scsi、vhost-blk和vhost-nvme进行初始化，如果配置文件中配置了对应类型的设备，那就会完成对应设备的创建并初始化监听socket等待qemu客户端进行连接。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/vhost.c:

int
spdk_vhost_init(void)
{
    int ret;

    ...

    ret = spdk_vhost_scsi_controller_construct();
    if (ret != 0) {
        SPDK_ERRLOG(&quot;Cannot construct vhost controllers\n&quot;);
        return -1;
    }

    ret = spdk_vhost_blk_controller_construct();
    if (ret != 0) {
        SPDK_ERRLOG(&quot;Cannot construct vhost block controllers\n&quot;);
        return -1;
    }

    ret = spdk_vhost_nvme_controller_construct();
    if (ret != 0) {
        SPDK_ERRLOG(&quot;Cannot construct vhost NVMe controllers\n&quot;);
        return -1;
    }

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;vhost-blk初始化&quot;&gt;vhost-blk初始化&lt;/h3&gt;

&lt;p&gt;  vhost-blk初始化时主要完成了两部分工作：一是vhost设备通用部分，即建立监听socket并拉起监听线程等待客户端连接；另一方面是vhost-blk特有的初始化动作，即打开bdev设备并建立联系：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/vhost_blk.c:

int
spdk_vhost_blk_construct(const char *name, const char *cpumask, const char *dev_name, bool readonly)
{
    struct spdk_vhost_blk_dev *bvdev = NULL;
    struct spdk_bdev *bdev;
    int ret = 0;

    spdk_vhost_lock();

    /* 首先通过bdev名称查找对应的bdev对象；bdev子系统在vhost子系统之前先完成初始化，正常情况下这里能找到对应的bdev */
    bdev = spdk_bdev_get_by_name(dev_name);
    ...

    bvdev = spdk_dma_zmalloc(sizeof(*bvdev), SPDK_CACHE_LINE_SIZE, NULL);
    ...

    /* 打开对应的bdev，并将句柄记录到bvdev-&amp;gt;bdev_desc中 */
    ret = spdk_bdev_open(bdev, true, bdev_remove_cb, bvdev, &amp;amp;bvdev-&amp;gt;bdev_desc);
    ...

    bvdev-&amp;gt;bdev = bdev;
    bvdev-&amp;gt;readonly = readonly;

    /* 完成vhost设备通用部分功能的初始化，并将该vhost设备的backend操作集合设为vhost_blk_device_backend；
        说明：不同的vhost类型实现了不同的backend，以完成不同类型特定的一些操作过程。我们在后续分析客户端连接
        操作时会深入分析backend的实现 */
    ret = spdk_vhost_dev_register(&amp;amp;bvdev-&amp;gt;vdev, name, cpumask, &amp;amp;vhost_blk_device_backend);
    ...

    spdk_vhost_unlock();
    return ret;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  vhost设备初始化主要提供了一个可供客户端(如qemu)连接的socket，并遵循vhost协议实现连接服务，这部分功能也是DPDK中已实现的功能，SPDK直接借用了相关代码：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/vhost/vhost.c:

int
spdk_vhost_dev_register(struct spdk_vhost_dev *vdev, const char *name, const char *mask_str,
                                            const struct spdk_vhost_dev_backend *backend)
{
    char path[PATH_MAX];
    struct stat file_stat;
    struct spdk_cpuset *cpumask;
    int rc;


    /* 将配置文件中读取的mask_str转换成位图记录到cpumask中，代表该vhost设备可以绑定的CPU核范围 */
    cpumask = spdk_cpuset_alloc();
    ...
    if (spdk_vhost_parse_core_mask(mask_str, cpumask) != 0) {
    ...
    }
    ...

    /* 生成socket文件路径名，规则是设备路径名(vhost命令启动时-S参数指定)加上vhost对象名称，
        例如 “/var/tmp/vhost.2” */
    if (snprintf(path, sizeof(path), &quot;%s%s&quot;, dev_dirname, name) &amp;gt;= (int)sizeof(path)) {
        ...
    }
    ...

    /* 生成socket监听句柄 */
    if (rte_vhost_driver_register(path, 0) != 0) {
        ...
    }
    if (rte_vhost_driver_set_features(path, backend-&amp;gt;virtio_features) ||
            rte_vhost_driver_disable_features(path, backend-&amp;gt;disabled_features)) {
        ...
    }

    /* 注册socket连接建立后的消息处理notify_op回调 */
    if (rte_vhost_driver_callback_register(path, &amp;amp;g_spdk_vhost_ops) != 0) {
        ...
    }

    /* 拉起一个监听线程，开始等待客户连接请求 */
    if (spdk_call_unaffinitized(_start_rte_driver, path) == NULL) {
        ...
    }

    vdev-&amp;gt;name = strdup(name);
    vdev-&amp;gt;path = strdup(path);
    vdev-&amp;gt;id = ctrlr_num++;
    vdev-&amp;gt;vid = -1; /* 代表客户端连接对象，在客户端连接过程中生成 */
    vdev-&amp;gt;lcore = -1; /* 代表当前vhost设备绑定到哪个核上运行，也是在客户端连接后请求处理过程中生成 */
    vdev-&amp;gt;cpumask = cpumask;
    vdev-&amp;gt;registered = true;
    vdev-&amp;gt;backend = backend;

    ...

    TAILQ_INSERT_TAIL(&amp;amp;g_spdk_vhost_devices, vdev, tailq);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  _start_rte_driver会拉起一个监听线程执行fdset_event_dispatch函数，该函数等待客户端的连接请求。当qemu向socket发起连接请求时，监听线程收到该请求并调用vhost_user_server_new_connection建立一个新的连接，然后在新的连接上等待客户端发消息。收到消息时，监听线程会调用vhost_user_read_cb函数处理消息。消息的处理代表了vhost协议的基本原理，我们将在后续独立的博文介绍。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2018/05/SPDK-subsys-vhost/&quot;&gt;【SPDK】六、vhost子系统&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 22 May 2018 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2018/05/SPDK-subsys-vhost/</link>
        <guid isPermaLink="true">http://rootw.github.io/2018/05/SPDK-subsys-vhost/</guid>
        
        <category>SPDK</category>
        
        
      </item>
    
      <item>
        <title>【SPDK】五、bdev子系统</title>
        <description>&lt;p&gt;  SPDK从功能角度将各个独立的部分划分为“&lt;strong&gt;子系统&lt;/strong&gt;“。例如对各种后端存储的访问属于bdev子系统，又例如对虚拟机呈现各种设备属于vhost子系统。不同场景下，各种工具可以通过组合不同的子系统来实现各种不同的功能。例如虚拟化场景下，vhost主要集成了bdev、vhost、scsi等子系统。这些子系统存在一定依赖关系，例如vhost子系统依赖bdev，这就需要将被依赖的子系统先初始化完成，才能执行其它子系统的初始化。&lt;/p&gt;

&lt;p&gt;  本篇博文我们先整体介绍一下SPDK子系统的初始化流程，然后再深入分析一下bdev子系统。vhost子系统我们将在独立的博文中展开分析。&lt;/p&gt;

&lt;h3 id=&quot;spdk子系统&quot;&gt;SPDK子系统&lt;/h3&gt;

&lt;p&gt;  通过前文的分析，我们知道主线程在执行_spdk_reactor_run时，首先处理的事件便是verify事件，该事件处理函数为spdk_subsystem_verify：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/event/subsystem.c:

static void
spdk_subsystem_verify(void *arg1, void *arg2)
{
    struct spdk_subsystem_depend *dep;

    /* 检查当前应用中所有需要的子系统及其依赖系统是否均已成功注册 */
    /* Verify that all dependency name and depends_on subsystems are registered */
    TAILQ_FOREACH(dep, &amp;amp;g_subsystems_deps, tailq) {
        if (!spdk_subsystem_find(&amp;amp;g_subsystems, dep-&amp;gt;name)) {
            SPDK_ERRLOG(&quot;subsystem %s is missing\n&quot;, dep-&amp;gt;name);
            spdk_app_stop(-1);
            return;
        }
        if (!spdk_subsystem_find(&amp;amp;g_subsystems, dep-&amp;gt;depends_on)) {
            SPDK_ERRLOG(&quot;subsystem %s dependency %s is missing\n&quot;,
                dep-&amp;gt;name, dep-&amp;gt;depends_on);
            spdk_app_stop(-1);
            return;
        }
    }

    /* 按依赖关系对所有子系统进行排序 */
    subsystem_sort();

    /* 依据排序依次执行各个子系统的init函数 */
    spdk_subsystem_init_next(0);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;bdev子系统&quot;&gt;bdev子系统&lt;/h3&gt;

&lt;p&gt;  bdev和vhost是虚拟化场景下两个最为主要的子系统，且vhost依赖bdev，因此我们先来分析一下bdev子系统。&lt;/p&gt;

&lt;p&gt;  我们可以看到bdev子系统的初始化函数为spdk_bdev_subsystem_initialize：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/event/subsystems/bdev/bdev.c:

static struct spdk_subsystem g_spdk_subsystem_bdev = {
    .name = &quot;bdev&quot;,
    .init = spdk_bdev_subsystem_initialize,
    .fini = spdk_bdev_subsystem_finish,
    .config = spdk_bdev_config_text,
    .write_config_json = _spdk_bdev_subsystem_config_json,
};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  bdev子系统针对不同的后端存储设备实现了不同的“&lt;strong&gt;模块&lt;/strong&gt;”，例如nvme模块主要实现了用户态对nvme设备的访问操作，virtio实现了用户态对virtio设备的访问操作，又例如malloc模块通过内存实现了一个模拟的块设备。因此bdev子系统在初始化时主要针对配置文件中已经配置的后端存储模块进行初始化操作。&lt;/p&gt;

&lt;p&gt;  另外，bdev借助IO Channel的概念也实现了系统级的management_channel和模块级的module_channel。我们知道IO Channel是一个线程相关的概念，management_channel和module_channel也是如此：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;management_channel是线程唯一的一个对象，不同线程具备不同的的management_channel，同一个线程只有一个。目前management_channel中实现了一个线程内部独立的内存池，用来缓存bdev_io对象；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;module_channel是线程内部属于同一个模块的bdev所共享的一个对象，用来记录同一线程中属于同一模块的所有对象。例如同一个线程如果操作两个nvme的bdev对象且这两个bdev属于不同的nvme控制器，那么虽然这两个bdev对应不同的NVMe IO Channel，但是它们属于同一个module_channel。目前module_channel只含有一个模块级的引用计数和内存不足时的bdev io临时队列(当有内存空间时，实现IO重发)。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  每个模块都会提供一个module_init函数，当bdev子系统初始化时会依次调用这些初始化函数。下面我们以NVMe和virtio两个模块为例，来简要看下模块的初始化逻辑。&lt;/p&gt;

&lt;h4 id=&quot;1-nvme模块初始化&quot;&gt;&lt;strong&gt;1. nvme模块初始化&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  nvme模块描述如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/bdev/nvme/bdev_nvme.c:

static struct spdk_bdev_module nvme_if = {
    .name = &quot;nvme&quot;,
    .module_init = bdev_nvme_library_init,
    .module_fini = bdev_nvme_library_fini,
    .config_text = bdev_nvme_get_spdk_running_config,
    .config_json = bdev_nvme_config_json,
    .get_ctx_size = bdev_nvme_get_ctx_size,

    };
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  这里我们可以看到nvme模块的初始化函数为bdev_nvme_library_init，另外bdev_nvme_get_ctx_size返回的context大小为nvme_bdev_io的大小。bdev子系统会以所有模块最大的context大小来创建bdev_io内存池，以此确保为所有模块申请bdev_io时都能获得足够的扩展内存(nvme_bdev_io即是对bdev_io的扩展)。&lt;/p&gt;

&lt;p&gt;  bdev_nvme_library_init函数从SPDK的配置文件中读取“Nvme”字段开始的相关信息，并通过这些信息创建一个NVMe控制器并获取其下的namespace，最后将namespace表示成一个bdev对象。这里我们打开看一下识别到对应NVMe控制器后的回调处理逻辑：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
static void
attach_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
            struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_ctrlr_opts *opts)
{
    struct nvme_ctrlr *nvme_ctrlr;
    struct nvme_probe_ctx *ctx = cb_ctx;
    char *name = NULL;
    size_t i;

    /* 首先根据DPDK中PCI驱动框架识别到的NVMe控制器信息来创建一个nvme_ctrlr对象 */
    if (ctx) {
        for (i = 0; i &amp;lt; ctx-&amp;gt;count; i++) {
            if (spdk_nvme_transport_id_compare(trid, &amp;amp;ctx-&amp;gt;trids[i]) == 0) {
                name = strdup(ctx-&amp;gt;names[i]);
                break;
            }
        }
    } else {
        name = spdk_sprintf_alloc(&quot;HotInNvme%d&quot;, g_hot_insert_nvme_controller_index++);
    }

    nvme_ctrlr = calloc(1, sizeof(*nvme_ctrlr));
    ...
    nvme_ctrlr-&amp;gt;adminq_timer_poller = NULL;
    nvme_ctrlr-&amp;gt;ctrlr = ctrlr;
    nvme_ctrlr-&amp;gt;ref = 0;
    nvme_ctrlr-&amp;gt;trid = *trid;
    nvme_ctrlr-&amp;gt;name = name;

    /* 将该nvme控制器对象添加为一个io device；每个io device可申请独立的IO Channel；
        bdev_nvme_create_cb负责在IO Channel对象创建时初始化底层驱动相关对象，这里
        即是获取一个新的queue pair */
    spdk_io_device_register(ctrlr, bdev_nvme_create_cb, bdev_nvme_destroy_cb,
                                                sizeof(struct nvme_io_channel));

    /* 此处开始枚举nvme控制器下的所有namespace，并将其建为bdev对象。注意一点，此时并不会为
        bdev申请IO channel，它是vhost子系统初始时，完成线程绑定后才创建的 */
    if (nvme_ctrlr_create_bdevs(nvme_ctrlr) != 0) {
        ...
    }

    nvme_ctrlr-&amp;gt;adminq_timer_poller = spdk_poller_register(bdev_nvme_poll_adminq, ctrlr,
                                                    g_nvme_adminq_poll_timeout_us);

    TAILQ_INSERT_TAIL(&amp;amp;g_nvme_ctrlrs, nvme_ctrlr, tailq);

    ...
}

/* 注意：bdev初始化时并不调用该函数 */
static int
bdev_nvme_create_cb(void *io_device, void *ctx_buf)
{
    struct spdk_nvme_ctrlr *ctrlr = io_device;
    struct nvme_io_channel *ch = ctx_buf;

    /* 分配一个nvme queue pair作为该IO Channel的实际对象 */
    ch-&amp;gt;qpair = spdk_nvme_ctrlr_alloc_io_qpair(ctrlr, NULL, 0);
    ...
    /* 向reactor注册一个poller，轮循新分配queue pair中已完成的响应信息 */
    ch-&amp;gt;poller = spdk_poller_register(bdev_nvme_poll, ch, 0);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  类似地，我们再看一下virtio模块的初始化。&lt;/p&gt;

&lt;h4 id=&quot;2-virtio模块初始化&quot;&gt;&lt;strong&gt;2. virtio模块初始化&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;  virtio虽说起源于qemu-kvm虚拟化，但是它也是一种可用物理硬件实现的协议规范。因此SPDK也把它当做一种后端存储类型加以实现。当然，如果SPDK的vhost进程是运行在虚拟机中(而虚拟机virtio设备作为后端存储)，virtio模块就是一个必不可少的驱动模块了。&lt;/p&gt;

&lt;p&gt;  我们以virtio-blk设备为例，来看一下其初始化过程：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/bdev/virtio/bdev_virtio_blk.c:

static struct spdk_bdev_module virtio_blk_if = {
    .name = &quot;virtio_blk&quot;,
    .module_init = bdev_virtio_initialize,
    .get_ctx_size = bdev_virtio_blk_get_ctx_size,
};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;  bdev_virtio_initialize通过配置文件获取相关配置信息，并同样借助DPDK的用户态PCI设备管理框架识别到该设备后，调用virtio_pci_blk_dev_create来创建一个virtio_blk对象：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/bdev/virtio/bdev_virtio_blk.c:

static struct virtio_blk_dev *
virtio_pci_blk_dev_create(const char *name, struct virtio_pci_ctx *pci_ctx)
{
    static int pci_dev_counter = 0;
    struct virtio_blk_dev *bvdev;
    struct virtio_dev *vdev;
    char *default_name = NULL;
    uint16_t num_queues;
    int rc;

    /* 分配一个virtio_blk_dev对象 */
    bvdev = calloc(1, sizeof(*bvdev));
    ...
    vdev = &amp;amp;bvdev-&amp;gt;vdev;

    /* 为该virtio对象绑定用户态操作接口，注，该操作接口实现了virtio 1.0规范 */
    rc = virtio_pci_dev_init(vdev, name, pci_ctx);
    ...

    /* 重置设备状态 */
    rc = virtio_dev_reset(vdev, VIRTIO_BLK_DEV_SUPPORTED_FEATURES);
    ...

    /* 获取设备支持的最大队列数。如果支持多队列，从设备的配置寄存器中聊取；否则为1 */
    /* TODO: add a way to limit usable virtqueues */
    if (virtio_dev_has_feature(vdev, VIRTIO_BLK_F_MQ)) {
        virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, num_queues),
            &amp;amp;num_queues, sizeof(num_queues));
    } else {
        num_queues = 1;
    }

    /* 初始化队列并创建bdev对象 */
    rc = virtio_blk_dev_init(bvdev, num_queues);
    ...

    return bvdev;
}

static int
virtio_blk_dev_init(struct virtio_blk_dev *bvdev, uint16_t max_queues)
{
    struct virtio_dev *vdev = &amp;amp;bvdev-&amp;gt;vdev;
    struct spdk_bdev *bdev = &amp;amp;bvdev-&amp;gt;bdev;
    uint64_t capacity, num_blocks;
    uint32_t block_size;
    uint16_t host_max_queues;
    int rc;

    /* 获取当前设备的块大小，默认为512字节 */
    if (virtio_dev_has_feature(vdev, VIRTIO_BLK_F_BLK_SIZE)) {
        virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, blk_size),
            &amp;amp;block_size, sizeof(block_size));
    } else {
        block_size = 512;
    }

    /* 获取设备容量 */
    virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, capacity),
        &amp;amp;capacity, sizeof(capacity));

    /* `capacity` is a number of 512-byte sectors. */
    num_blocks = capacity * 512 / block_size;

    /* 获取最大队列数 */
    if (virtio_dev_has_feature(vdev, VIRTIO_BLK_F_MQ)) {
            virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, num_queues),
        &amp;amp;host_max_queues, sizeof(host_max_queues));
    } else {
        host_max_queues = 1;
    }

    if (virtio_dev_has_feature(vdev, VIRTIO_BLK_F_RO)) {
        bvdev-&amp;gt;readonly = true;
    }

    /* bdev is tied with the virtio device; we can reuse the name */
    bdev-&amp;gt;name = vdev-&amp;gt;name;

    /* 按max_queues分配队列，并启动设备 */
    rc = virtio_dev_start(vdev, max_queues, 0);
    ...

    /* 为bdev对象赋值 */
    bdev-&amp;gt;product_name = &quot;VirtioBlk Disk&quot;;
    bdev-&amp;gt;write_cache = 0;
    bdev-&amp;gt;blocklen = block_size;
    bdev-&amp;gt;blockcnt = num_blocks;

    bdev-&amp;gt;ctxt = bvdev;
    bdev-&amp;gt;fn_table = &amp;amp;virtio_fn_table;
    bdev-&amp;gt;module = &amp;amp;virtio_blk_if;

    /* 将virtio_blk_dev添加为一个io device；其IO Channel创建回调bdev_virtio_blk_ch_create_cb会申请一个
        virtio的IO环作为该IO Channel的实际对象 */
    spdk_io_device_register(bvdev, bdev_virtio_blk_ch_create_cb,
            bdev_virtio_blk_ch_destroy_cb,
            sizeof(struct bdev_virtio_blk_io_channel));

    /* 注册该bdev对象，便于后续查找 */
    rc = spdk_bdev_register(bdev);
    ...

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2018/05/SPDK-subsys-bdev/&quot;&gt;【SPDK】五、bdev子系统&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 21 May 2018 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2018/05/SPDK-subsys-bdev/</link>
        <guid isPermaLink="true">http://rootw.github.io/2018/05/SPDK-subsys-bdev/</guid>
        
        <category>SPDK</category>
        
        
      </item>
    
      <item>
        <title>【SPDK】四、reactor线程</title>
        <description>&lt;p&gt;  reactor线程是SPDK中负责实际业务处理逻辑的单元，它们在vhsot服务启动时创建，直到服务停止。目前还不支持reactor线程的动态增减。&lt;/p&gt;

&lt;h3 id=&quot;reactor线程总流程&quot;&gt;reactor线程总流程&lt;/h3&gt;

&lt;p&gt;  我们顺着vhost进程的代码执行顺序来看看总体流程：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/app/vhost/vhost.c:

int
main(int argc, char *argv[])
{
    struct spdk_app_opts opts = {};
    int rc;

    /* 首先进行参数解析，解析后的结果保存于opts中 */

    vhost_app_opts_init(&amp;amp;opts);

    if ((rc = spdk_app_parse_args(argc, argv, &amp;amp;opts, &quot;f:S:&quot;,
        vhost_parse_arg, vhost_usage)) !=
        SPDK_APP_PARSE_ARGS_SUCCESS) {
        exit(rc);
    }

    ...

    /* 接着根据配置文件指明的物理核启动reactors线程(主线程最终也成为一个reactor)。
        这些reactors线程会执行轮循函数，直到外部将服务状态置为退出 */

    /* Blocks until the application is exiting */
    rc = spdk_app_start(&amp;amp;opts, vhost_started, NULL, NULL);

    /* 所有reactor线程退出后，进行资源清理 */
    spdk_app_fini();

    return rc;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  上述整体流程中最为重要的便是spdk_app_start函数，该函数内部调用了DPDK关于系统CPU、内存、PCI设备管理等通用性服务代码，这里我们尽可能以理解其功能为主而不做深入的代码分析：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/event/app.c:

int
spdk_app_start(struct spdk_app_opts *opts, spdk_event_fn start_fn,
void *arg1, void *arg2)
{
    struct spdk_conf	*config = NULL;
    int			rc;
    struct spdk_event	*app_start_event;

    ...

    /* 将配置文件中的内容导入到config对象中 */
    config = spdk_app_setup_conf(opts-&amp;gt;config_file);
    ...
    spdk_app_read_config_file_global_params(opts);

    ...

    /* 调用DPDK系统服务：
        (1)通过内核sysfs获取物理CPU信息，并通过配置文件指定的运行核，在各个核上启动服务线程；
        各服务线程启动后因为在等待主线程给它们发送需要执行的任务而处于睡眠状态；
        (2)基于大页内存创建内存池以供其它模块使用；
        (3)初始化PCI设备枚举服务，可以实现类似内核的设备发现及驱动初始化流程。SPDK基于此并借
        助内核uio或vfio驱动实现全用户态的PCI驱动 */
     /* 完成DPDK的初始化后，SPDK会建立一张由vva(vhost virtual address)到pa(physical address)
        的内存映射表g_vtophys_map。每当有新的内存映射到vhost中时，都需要调用spdk_mem_register在该
        表中注册新的映射关系。设计该表的原因是当SPDK向物理设备发送DMA请求时，需要向设备提供pa而非vva */
    if (spdk_app_setup_env(opts) &amp;lt; 0) {
        ...
    }

    /* 这里为reactors分配相应的内存 */
    /*
     * If mask not specified on command line or in configuration file,
     *  reactor_mask will be 0x1 which will enable core 0 to run one
     *  reactor.
     */
    if ((rc = spdk_reactors_init(opts-&amp;gt;max_delay_us)) != 0) {
        ...
    }

    ...

    /* 设置一些全局变量 */
    memset(&amp;amp;g_spdk_app, 0, sizeof(g_spdk_app));
    g_spdk_app.config = config;
    g_spdk_app.shm_id = opts-&amp;gt;shm_id;
    g_spdk_app.shutdown_cb = opts-&amp;gt;shutdown_cb;
    g_spdk_app.rc = 0;
    g_init_lcore = spdk_env_get_current_core();
    g_app_start_fn = start_fn;
    g_app_start_arg1 = arg1;
    g_app_start_arg2 = arg2;
    app_start_event = spdk_event_allocate(g_init_lcore, start_rpc, (void *)opts-&amp;gt;rpc_addr, NULL);

    /* 初始化SPDK的各个子系统，如bdev、vhost均为子系统。但这里需注意一点，此处仅是产生了一个初始化事件，事件的处理要在
        reactor线程正式进入轮循函数后才开始 */
    spdk_subsystem_init(app_start_event);

    /* 从此处开始，各个线程(包括主线程)开始执行_spdk_reactor_run，线程名也正式变更为reactor_X；
        直到所有线程均退出_spdk_reactor_run后，主线程才会返回 */
    /* This blocks until spdk_app_stop is called */
    spdk_reactors_start();

    return g_spdk_app.rc;
    ...    
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  再看一下spdk_reactors_start：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/event/reactor.c:

void
spdk_reactors_start(void)
{
    struct spdk_reactor *reactor;
    uint32_t i, current_core;
    int rc;

    g_reactor_state = SPDK_REACTOR_STATE_RUNNING;
    g_spdk_app_core_mask = spdk_cpuset_alloc();

    /* 针对主线程之外的其它核上的线程，通过发送通知使它们开始执行_spdk_reactor_run */
    current_core = spdk_env_get_current_core();
    SPDK_ENV_FOREACH_CORE(i) {
        if (i != current_core) {
            reactor = spdk_reactor_get(i);
            rc = spdk_env_thread_launch_pinned(reactor-&amp;gt;lcore, _spdk_reactor_run, reactor);
            ...
        }
        spdk_cpuset_set_cpu(g_spdk_app_core_mask, i, true);
    }

    /* 主线程也会执行_spdk_reactor_run */
    /* Start the master reactor */
    reactor = spdk_reactor_get(current_core);
    _spdk_reactor_run(reactor);

    /* 主线程退出后会等待其它核上的线程均退出 */
    spdk_env_thread_wait_all();

    /* 执行到此处，说明vhost服务进程即将退出 */
    g_reactor_state = SPDK_REACTOR_STATE_SHUTDOWN;
    spdk_cpuset_free(g_spdk_app_core_mask);
    g_spdk_app_core_mask = NULL;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;轮循函数_spdk_reactor_run&quot;&gt;轮循函数_spdk_reactor_run&lt;/h3&gt;

&lt;p&gt;  通过对vhost代码流程的分析，我们看到vhost中所有线程最终都会调用_spdk_reactor_run，该函数是一个死循环，由此实现轮循逻辑：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spdk/lib/event/reactor.c:

static int
_spdk_reactor_run(void *arg)
{
    struct spdk_reactor	*reactor = arg;
    struct spdk_poller	*poller;
    uint32_t		event_count;
    uint64_t		idle_started, now;
    uint64_t		spin_cycles, sleep_cycles;
    uint32_t		sleep_us;
    uint32_t		timer_poll_count;
    char			thread_name[32];

    /* 重新命名线程名，reactor_[核号] */
    snprintf(thread_name, sizeof(thread_name), &quot;reactor_%u&quot;, reactor-&amp;gt;lcore);

    /* 创建SPDK线程对象：
        (1)线程间通过_spdk_reactor_send_msg发送消息，本质是向接收方的event队列中添加事件；
        (2)线程通过_spdk_reactor_start_poller和_spdk_reactor_stop_poller启动和停止poller；
        (3)IO Channel等线程相关对象也会记录到线程对象中 */
    if (spdk_allocate_thread(_spdk_reactor_send_msg,
            _spdk_reactor_start_poller,
            _spdk_reactor_stop_poller,
            reactor, thread_name) == NULL) {
        return -1;
    }
    
    /* spin_cycles代表最短轮循时间 */
    spin_cycles = SPDK_REACTOR_SPIN_TIME_USEC * spdk_get_ticks_hz() / SPDK_SEC_TO_USEC;
    /* sleep_cycles代表最长睡眠时间 */
    sleep_cycles = reactor-&amp;gt;max_delay_us * spdk_get_ticks_hz() / SPDK_SEC_TO_USEC;
    idle_started = 0;
    timer_poll_count = 0;

    /* 轮循的死循环正式开始 */
    while (1) {
        bool took_action = false;

        /* 首先，每个reactor线程通过DPDK的无锁队列实现了一个事件队列；这里从事件队列中取出事件并调用事件
            的处理函数。例如，vhost的子系统的初始化即是在spdk_subsystem_init中产生了一个verify事件并
            添加到主线程reactor的事件队列中，该事件处理函数为spdk_subsystem_verify */
        event_count = _spdk_event_queue_run_batch(reactor);
        if (event_count &amp;gt; 0) {
            took_action = true;
        }

        /* 接着，每个reactor线程从active_pollers链表头部取出一个poller并调用其fn函数。poller代表一次
            具体的处理动作，例如处理某个vhost_blk设备的所有IO环中的请求，又或者处理后端NVMe某个queue 
            pair中的所有响应 */
        poller = TAILQ_FIRST(&amp;amp;reactor-&amp;gt;active_pollers);
        if (poller) {
            TAILQ_REMOVE(&amp;amp;reactor-&amp;gt;active_pollers, poller, tailq);
            poller-&amp;gt;state = SPDK_POLLER_STATE_RUNNING;
            poller-&amp;gt;fn(poller-&amp;gt;arg);
            if (poller-&amp;gt;state == SPDK_POLLER_STATE_UNREGISTERED) {
                free(poller);
            } else {
                poller-&amp;gt;state = SPDK_POLLER_STATE_WAITING;
                TAILQ_INSERT_TAIL(&amp;amp;reactor-&amp;gt;active_pollers, poller, tailq);
            }
            took_action = true;
        }

        /* 最后，reactor线程还实现了定时器逻辑，这里判断是否有定时器到期；如果确有定时器到期则执行其回调并将
            其放到定时器队列尾部 */
        if (timer_poll_count &amp;gt;= SPDK_TIMER_POLL_ITERATIONS) {
            poller = TAILQ_FIRST(&amp;amp;reactor-&amp;gt;timer_pollers);
            if (poller) {
                now = spdk_get_ticks();

                if (now &amp;gt;= poller-&amp;gt;next_run_tick) {
                    TAILQ_REMOVE(&amp;amp;reactor-&amp;gt;timer_pollers, poller, tailq);
                    poller-&amp;gt;state = SPDK_POLLER_STATE_RUNNING;
                    poller-&amp;gt;fn(poller-&amp;gt;arg);
                    if (poller-&amp;gt;state == SPDK_POLLER_STATE_UNREGISTERED) {
                        free(poller);
                    } else {
                        poller-&amp;gt;state = SPDK_POLLER_STATE_WAITING;
                        _spdk_poller_insert_timer(reactor, poller, now);
                    }
                    took_action = true;
                }
            }
            timer_poll_count = 0;
        } else {
            timer_poll_count++;
        }

        /* 下面的逻辑主要用来决定轮循线程是否可以睡眠一会 */

        if (took_action) {
            /* We were busy this loop iteration. Reset the idle timer. */
            idle_started = 0;
        } else if (idle_started == 0) {
            /* We were previously busy, but this loop we took no actions. */
            idle_started = spdk_get_ticks();
        }

        /* Determine if the thread can sleep */
        if (sleep_cycles &amp;amp;&amp;amp; idle_started) {
            now = spdk_get_ticks();
            if (now &amp;gt;= (idle_started + spin_cycles)) { /* 保证轮循线程最少已执行了spin_cycles */
                sleep_us = reactor-&amp;gt;max_delay_us;

                poller = TAILQ_FIRST(&amp;amp;reactor-&amp;gt;timer_pollers);
                if (poller) {
                    /* There are timers registered, so don't sleep beyond
                     * when the next timer should fire */
                    if (poller-&amp;gt;next_run_tick &amp;lt; (now + sleep_cycles)) {
                        if (poller-&amp;gt;next_run_tick &amp;lt;= now) {
                            sleep_us = 0;
                        } else {
                            sleep_us = ((poller-&amp;gt;next_run_tick - now) *
                                SPDK_SEC_TO_USEC) / spdk_get_ticks_hz();
                        }
                    }
                }

                if (sleep_us &amp;gt; 0) {
                    usleep(sleep_us);
                }

                /* After sleeping, always poll for timers */
                timer_poll_count = SPDK_TIMER_POLL_ITERATIONS;
            }
        }

        if (g_reactor_state != SPDK_REACTOR_STATE_RUNNING) {
            break;
        }
    } /* 死循环结束 */

    ...
    spdk_free_thread();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;  至此，reactor线程整体执行逻辑已分析完成，后续我们将以verify_event为线索开始分析各个子系统的初始化过程。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
转载请注明：&lt;a href=&quot;https://rootw.github.io&quot;&gt;吴斌的博客&lt;/a&gt; » &lt;a href=&quot;https://rootw.github.io/2018/05/SPDK-reactors-init/&quot;&gt;【SPDK】四、reactor线程&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 21 May 2018 00:00:00 +0800</pubDate>
        <link>http://rootw.github.io/2018/05/SPDK-reactors-init/</link>
        <guid isPermaLink="true">http://rootw.github.io/2018/05/SPDK-reactors-init/</guid>
        
        <category>SPDK</category>
        
        
      </item>
    
  </channel>
</rss>
