---
layout: post
title: 内存管理之一：地址映射
date: 2017-08-08 
tags: 自顶向下分析计算机系统
---

&emsp;&emsp;地址映射是CPU核心和MMU共同完成的内存管理功能之一，本节将对此展开深入讨论。计算子系统相关内容目录[点此进入](https://rootw.github.io/2017/02/计算子系统/)。

### 什么是地址映射？为什么需要它？

&emsp;&emsp;正如在[计算机系统](https://rootw.github.io/2017/02/计算机/)整体介绍中所说明的一样，MMU在CPU核心的配合下(通过页异常触发)，实现了线性地址到物理地址的动态映射，为正在CPU上运行的应用程序提供了一个独立的连续内存空间(线性地址空间，或称虚拟内存空间)，屏蔽了地址分配、内存分配和内存回收等一系列复杂的系统行为，不仅提升了内存资源的利用效率，而且大大降低了应用开发难度，使程序猿可以更聚焦业务逻辑。

### 如何实现？

#### **1.线性地址**

&emsp;&emsp;x86_64架构下Linux中每个应用程序可见的线性地址空间如下(注：分段机制在64位模式下已不产生实际作用)：

<div align="center">
<img src="/images/posts/i440fx/memory1_1.jpg" height="200" width="500">  
</div> 

&emsp;&emsp;该架构支持48位线性地址(高16位仅做符号扩展，不参与地址转换)到40位物理地址(最多52位，由CPU实现决定)的映射。48位线性空间共256T，分为两个128T区间，分别分布在完整的64位空间的两端。其中，低128T为用户空间，映射用户程序代码、数据、堆栈和共享库，物理内存随着程序的运行由内核动态分配。而高128T则为内核空间：direct mapping区映射整个物理内存空间，便于内核访问所有物理内存；vmalloc space区间为内核调用vmalloc时使用的线性空间，物理内存动态分配且物理上不保证连续；virtual memory map是内核标识内存页信息的数组，供内存管理功能使用；kernel text & module区存放内核和模块的代码及数据。此外，也可以参考内核代码的说明：

```
linux/Documentation/x86/x86_64/mm.txt:

0000000000000000 - 00007fffffffffff (=47 bits) user space, different per mm
hole caused by [48:63] sign extension
ffff800000000000 - ffff80ffffffffff (=40 bits) guard hole
ffff880000000000 - ffffc7ffffffffff (=64 TB) direct mapping of all phys. memory
ffffc80000000000 - ffffc8ffffffffff (=40 bits) hole
ffffc90000000000 - ffffe8ffffffffff (=45 bits) vmalloc/ioremap space
ffffe90000000000 - ffffe9ffffffffff (=40 bits) hole
ffffea0000000000 - ffffeaffffffffff (=40 bits) virtual memory map (1TB)
... unused hole ...
ffffff0000000000 - ffffff7fffffffff (=39 bits) %esp fixup stacks
... unused hole ...
ffffffff80000000 - ffffffffa0000000 (=512 MB)  kernel text mapping, from phys 0
ffffffffa0000000 - ffffffffff5fffff (=1525 MB) module mapping space
ffffffffff600000 - ffffffffffdfffff (=8 MB) vsyscalls
ffffffffffe00000 - ffffffffffffffff (=2 MB) unused hole

```

#### **2.地址转换**

&emsp;&emsp;MMU的线性地址转换是通过页表进行的，具体过程如下图所示：

xxx

&emsp;&emsp;其实最简单明了的方法是通过一个一维数组来记录映射关系:下标代表线性地址，数组元素内容代表物理地址。可是如此一来，用来表示映射关系的内存空间比被表示的物理空间还要大，显然这不是一个可行的方案。

&emsp;&emsp;工程师们采用了分段分级的思路来表示这种映射关系：先把线性空间以4K大小为单位进行划分(页)，然后再以大段连续空间进行转换，在每个大段空间内部再次划分成小段进行转换，直到段大小变为4K页大小。用以表示和段空间映射关系的结构称为页表，其大小也是一个页面。由于采用了分段的方法，页表空间大大减小；同时未映射的空间不必分配页表，这也进一步降低了页表占用空间。

&emsp;&emsp;x86_64架构下Linux用了四级页表来表示一个映射关系，依次为PGD、PUD、PMD、PT。每级页表4K大小，内部元素大小为8字节，高位指向了下一级页表的物理地址，低位表示页表属性(是否存在、读写权限、是否脏等等)。顶层页表PGD的物理地址存放在CPU的CR3寄存器中，供MMU访问。48位线性地址也相应地分成了五段：前四段，每段长9位，用来索引对应页表的元素；最后一段长12位，用来在页面中索引物理地址。各级页表的详细内容参考下表：

xxx

#### **3.页异常处理**

&emsp;&emsp;一个进程初始运行时，对应的页表项大多都是空的。一旦MMU在地址转换过程中出现缺页或者读写权限问题时，MMU会触发页异常，打断CPU当前正在执行的程序，转而进行页异常处理(缺页会分配新页)。当页异常处理完毕后，CPU会重新执行引发缺页的指令，此时MMU便可正常完成地址转换。

&emsp;&emsp;下面，我们进一步深入分析整个页异常处理过程，关键流程如下图所示：

<div align="center">
<img src="/images/posts/i440fx/memory1_2.jpg" height="600" width="500">  
</div> 


&emsp;&emsp;CPU收到页异常后，首先进行的是上下文切换的硬件过程，该过程主要完成栈的切换(被中断时CPU处于用户态)、关键寄存器的保存和执行函数的切换(转入页异常处理函数)。有关中断和异常处理的详细分析请参考Xxx。

&emsp;&emsp;CPU被页异常中断后最先执行的是一段汇编代码xxx，完成了其他上下文寄存器的保存，并进入核心处理逻辑do_page_fault。

&emsp;&emsp;在理解MMU的工作原理之后，我想大家对缺页异常的核心处理逻辑应该很快能想明白，无非就是分配页、填充页内容、修改页表。然而，回顾一下前面线性地址章节描绘的地址空间分配图，我们会发现其中有代码、有数据、有堆和栈，不同类型的区段的对于页异常的处理逻辑是有区别的，例如代码段的页内容来自可执行文件，是只读类型的；数据段初始内容也来自可执行文件，但后续的修改不影响可执行执行文件；堆和栈的内容不来自任何文件，只在当前进程内部可见。Linux内核以虚拟内存段(vma)的方式来表达不同程序区间，不同段可以具有不同的读写权限和属性；不在任何内存段的地址则认为是非法地址。有关内存段的数据结构如下：
xxx

&emsp;&emsp;所有vma会以链表形式统一到mm_struct中，该结构每个进程拥有一个，被进程控制块使用，描述了每个进程的有效内存区段和地址映射关系：
xxx

&emsp;&emsp;我们回到do_page_fault函数，它通过读取CPU的CR2寄存器可以获知发生页异常的线性地址，并在当前进程对应的mm_struct中查找该线性地址对应的vma虚拟地址内存段，最后根据vma的属性来进一步处理页异常。当然，如果找不到线性地址对应的vma，内核就会认为发生了一次非法内存访问(让程序猿闻风丧胆的segfault由此产生)。详细的代码注解如下：

XXX

(页异常处理属于进程上下文，不是中断上下文，可睡眠。)

&emsp;&emsp;handle_mm_fault函数基于当前进程的mm_struct、异常地址所在vma和异常处理控制标志flags进行进一步异常处理。我们知道，页表共有四级，这里依次对各级页表进行处理：PGD是在进程创建的时候就分配好的，不需要动态分配；从PUD到PT，如果页表不存在会动态分配页并使页表指向新分配的页。页表处理完成后，进入handle_pte_fault处理最后的物理页。handle_mm_fault代码注解如下(这里暂不考虑大页等复杂特性)：

xxx(说明__va如何实现从物理到线性地址的转换，点出direct mapping的作用)

&emsp;&emsp;题外话，页表操作的同步。通常情况下，一个确定的映射关系mm_struct只被一个进程引用，同一进程在确定时刻只会运行在一个核上，因此该进程的页异常处理也只在一个核上发生，此时不存在对进程页表做并发操作的可能。然而，如果一个进程有多个线程，那么这些线程将引用相同的mm_struct(代码段、数据段、堆空间完全相同，栈空间各不相同)，此时对mm_struct所涉及的各级页表操作时就需要考虑同步问题。

&emsp;&emsp;一种简单的方法是在开始页表操作前，对mm_struct先上一把大锁，待各级页表均操作完毕后再解锁。但存在的问题是页表操作过程中会涉及页分配，这是一个极其复杂的过程，可能还会睡眠，这样一来有可能出现成功加到锁的线程进入睡眠态后导致其他线程缺页却加不到锁的情况。即便不同线程访问的是不同内存段，但是却有可能出现因为一个线程的页异常处理不及时导致所有线程无法正常处理页异常的情况。

&emsp;&emsp;linux内核针对此种问题采用了最小化加锁范围的方法。每次操作页表前，如果页表项不存在则先分配页，然后加mm_struct锁。加锁成功后，如果发现页表项已经被赋值，说明有其他CPU先于当前CPU完成了页表分配，则释放先前分配页并解锁；如果未被赋值，则将分配页赋值给页表项，最后解锁。这种方法虽然会导致一些多余的页分配和释放动作，但加锁区间和持锁时间大大缩短，系统整体并发性大大提升。此外，对于最后一级PT页表的操作比前几级页表复杂性要高得多，因此内核对PT页表使用了一把独立的锁，进一步提升系统并行效率。代码注解如下：
XXX

&emsp;&emsp;handle_pte_fault函数根据PT页表中异常地址对应的页表项进行不同处理：如果页表项PRESENT位未被置位，代表物理页不存在，需要进行缺页处理；否则，代表访问权限不够，需要调用do_wp_page进行写保护处理。在缺页的情况下，如果页表项不为零，说明前期把物理页交换到磁盘上了，而页表项纪录了交换页所在的磁盘位置信息，那么此时需要通过do_swap_page将交换页取回内存(内存交换将单独起一篇博文分析)；页表项为零则根据vma是否有文件对应进行不同处理，文件映射由do_linear_fault处理，匿名映射由do_anonymous_page处理。代码注解如下：
xxx

&emsp;&emsp;do_linear_fault函数处理线性文件映射内存段的缺页问题。对于读缺页，通过查找文件缓存页后直接采用缓存页作为映射页；对于写缺页，先查找文件缓存页，如果为共享内存段则直接采用缓存页映射，如果为私有内存段则分配新页、拷贝缓存页内容后再映射新页。代码注解如下：
xxx

&emsp;&emsp;do_anonymous_page函数处理匿名映射内存段的缺页问题。由于匿名映射没有对应文件，这里直接分配新页进行映射。代码注解如下：
xxx

&emsp;&emsp;do_wp_page函数处理写保护，即针对没有写权限的映射页触发了写请求。这里的处理思路和匿名页处理有些类似，也是分配新页后拷贝原有页的内容，之后解除原有页的映射之后再映射新页。代码注解如下：
xxx

&emsp;&emsp;至此，MMU和CPU的内存地址映射功能已经整体分析完毕。CPU在页异常过程中多次涉及内存页分配，而内存分配又牵扯到内存回收和交换，这些都内存管理中不可缺少的部分，后续将对这些部分进行深入分析。


<br>
转载请注明：[吴斌的博客](https://rootw.github.io) » [计算机](https://rootw.github.io/2017/08/地址映射/) 
