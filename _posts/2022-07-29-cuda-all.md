---
layout: post
title: CUDA概述
date: 2022-07-29
tags: CUDA
---

### 定义(what)

&emsp;&emsp;CUDA(Compute Unified Device Architecture)，中文叫统一计算设备架构，它是NVIDIA公司基于自身异构计算设备(GPU)提出的一种统一串行计算(CPU完成)和并行计算(GPU完成)的可编程异构融合计算系统。GPU相比CPU而言，面对SIMD并行计算模式有成百上千倍的计算性能提升，且有着更低的功耗优势。因此GUDA也一种是执行串并行混合复杂任务的理想计算系统。

#### **串行计算**

&emsp;&emsp;对于一般性计算任务，总是可以分解成小的计算片段依次执行，这就是通常说的串行计算，如下图所示：

<div align="center">                                                             
    <img src="/images/posts/cuda/serial.png" height="180" width="600">  
</div>

#### **并行计算**

&emsp;&emsp;对于复杂计算任务，并不是所有计算片段都有严格的数据依赖并需要按顺序执行，这里的数据依赖是指后面的计算片段的计算输入依赖前面的计算片段的输出。因此复杂计算中总是可以分解为几个大的串行计算区间，但是在某些区间内部存在可以并行执行的部分，如下图所示：

<div align="center">                                                             
    <img src="/images/posts/cuda/parallel.png" height="440" width="600">  
</div>

&emsp;&emsp;并行计算又可以分为任务并行和数据并行两种类型：任务并行是指多个无关任务可以在多个计算核上同时执行；而数据并行是指将大块数据的不同部分分散到不同的计算核上进行并行计算，以提升大块数据的计算性能。CUDA架构适合解决数据并行类问题。

#### **费林计算架构分类**

&emsp;&emsp;无论串行计算还是并行计算，都需要相应的硬件计算架构来实现，而根据计算任务的指令和数据在多个计算核的流动和分散方式，计算架构可以分为：单指令多数据(SIMD)、多指令多数据(MIMD)、单指令单数据(SISD)、多指令单数据(MISD)四种模式。CUDA融合了SIMD、MIMD、多线程、指令级并行，因此也被称为SIMT架构，即单指令多线程架构。

<div align="center">                                                             
    <img src="/images/posts/cuda/flynn.png" height="200" width="600">  
</div>

#### **串行计算与并行计算融合统一**

&emsp;&emsp;CPU适合执行带有复杂控制逻辑的串行计算任务，GPU适合执行控制逻辑简单但数据并行度较高的并行计算任务。如果能对复杂任务在GPU和GPU间进行合理执行分配，任务执行将获得最佳性能和功耗优势：

<div align="center">                                                             
    <img src="/images/posts/cuda/unified.png" height="298" width="600">  
</div>

&emsp;&emsp;

### 价值(why)

&emsp;&emsp;CUDA对于线性代数运算(如矩阵、向量等)有数量级的性能提升，可应用于HPC(High Performance Computing)或AI类任务，如计算生物学和化学、流体力学模拟、CT 图像再现、地震分析以及深度学习模型训练与推理等等。

### 实现原理(how)

<br>
转载请注明：[吴斌的博客](https://rootw.github.io) » [CUDA概述](https://rootw.github.io/2022/07/cuda-all/) 
